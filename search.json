[{"path":"https://arthurleroy.github.io/MagmaClustR/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2021 Arthur Leroy Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Arthur Leroy. Author, maintainer. Pierre Pathé. Contributor. Pierre Latouche. Author.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Leroy , Latouche P (2022). MagmaClustR: Clustering Prediction using Multi-Task Gaussian Processes Common Mean. https://github.com/ArthurLeroy/MagmaClustR, https://arthurleroy.github.io/MagmaClustR/.","code":"@Manual{,   title = {MagmaClustR: Clustering and Prediction using Multi-Task Gaussian Processes with Common Mean},   author = {Arthur Leroy and Pierre Latouche},   year = {2022},   note = {https://github.com/ArthurLeroy/MagmaClustR, https://arthurleroy.github.io/MagmaClustR/}, }"},{"path":"https://arthurleroy.github.io/MagmaClustR/index.html","id":"magmaclustr-","dir":"","previous_headings":"","what":"Clustering and Prediction using Multi-Task Gaussian Processes with\n    Common Mean","title":"Clustering and Prediction using Multi-Task Gaussian Processes with\n    Common Mean","text":"MagmaClustR package implements two main algorithms, called Magma (Leroy et al., 2022) MagmaClust (Leroy et al., 2020), using multi-task Gaussian processes (GP) model perform predictions supervised learning problems. Applications involving functional data, multiple time series, particularly well-handled. Theses approaches leverage learning cluster-specific mean processes, common across similar tasks, provide enhanced prediction performances (even far data points) linear computational cost (number tasks). MagmaClust generalisation Magma tasks simultaneously clustered groups, associated specific mean process. User-oriented functions package decomposed training, prediction plotting functions. basic features standard GPs also implemented. Leroy, ., Latouche, P., Guedj, B., Gey, S. MAGMA: inference prediction using multi-task Gaussian processes common mean. Mach Learn 111, 1821–1849 (2022). https://doi.org/10.1007/s10994-022-06172-1 Leroy, ., Latouche, P., Guedj, B., & Gey, S. Cluster-Specific Predictions Multi-Task Gaussian Processes. arXiv preprint (2020). https://arxiv.org/abs/2011.07866","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Clustering and Prediction using Multi-Task Gaussian Processes with\n    Common Mean","text":"can install released version MagmaClustR CRAN : development version GitHub :","code":"install.packages(\"MagmaClustR\") # install.packages(\"devtools\") devtools::install_github(\"ArthurLeroy/MagmaClustR\")"},{"path":"https://arthurleroy.github.io/MagmaClustR/index.html","id":"example-magma","dir":"","previous_headings":"","what":"Example: Magma","title":"Clustering and Prediction using Multi-Task Gaussian Processes with\n    Common Mean","text":"basic example simulate dataset adequate format, train Magma model use perform predictions.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/index.html","id":"data-generation","dir":"","previous_headings":"Example: Magma","what":"Data generation","title":"Clustering and Prediction using Multi-Task Gaussian Processes with\n    Common Mean","text":"","code":"library(MagmaClustR) ## Simulate a dataset with 11 individuals, each observed at 10 input locations set.seed(2) data_magma <- simu_db(M = 11, N = 10, common_input = FALSE) ## Split individuals into training and prediction sets, and define test points magma_train <- data_magma %>% subset(ID %in% 1:10) magma_pred <- data_magma %>% subset(ID == 11) %>% head(5) magma_test <- data_magma %>% subset(ID == 11) %>% tail(5)  data_magma #> # A tibble: 110 x 3 #>    ID    Output Input #>    <chr>  <dbl> <dbl> #>  1 1       1.52  1.9  #>  2 1      -5.76  3.3  #>  3 1      -3.78  3.35 #>  4 1       7.23  5.25 #>  5 1      14.9   6.2  #>  6 1       7.48  7.4  #>  7 1       7.21  8.15 #>  8 1      11.5   8.2  #>  9 1      13.1   8.9  #> 10 1       8.72  9.5  #> # ... with 100 more rows"},{"path":"https://arthurleroy.github.io/MagmaClustR/index.html","id":"training-and-prediction-with-magma","dir":"","previous_headings":"Example: Magma","what":"Training and prediction with Magma","title":"Clustering and Prediction using Multi-Task Gaussian Processes with\n    Common Mean","text":"Note grid_inputs argument optional. merely allows users control grid values prediction performed.","code":"model <- train_magma(data = magma_train) #> The 'prior_mean' argument has not been specified. The hyper_prior mean function is thus set to be 0 everywhere. #>   #> The 'ini_hp_0' argument has not been specified. Random values of hyper-parameters for the mean process are used as initialisation. #>   #> Called from: train_magma(data = magma_train) #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#238: if (\"ID\" %in% names(hp_0)) { #>     hp_0 = hp_0[names(hp_0) != \"ID\"] #> } #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#243: if (kern_i %>% is.function()) { #>     if (ini_hp_i %>% is.null()) { #>         stop(\"When using a custom kernel function the 'ini_hp_i' argument is \",  #>             \"mandatory, in order to provide the name of the hyper-parameters. \",  #>             \"You can use the function 'hp()' to easily generate a tibble of random\",  #>             \" hyper-parameters with the desired format for initialisation.\") #>     } #> } else { #>     if (ini_hp_i %>% is.null()) { #>         hp_i <- hp(kern_i, list_ID = list_ID, common_hp = common_hp,  #>             noise = TRUE) #>         cat(\"The 'ini_hp_i' argument has not been specified. Random values of\",  #>             \"hyper-parameters for the individal processes are used as\",  #>             \"initialisation.\\n \\n\") #>     } #>     else if (!(\"ID\" %in% names(ini_hp_i))) { #>         hp_i <- tibble::tibble(ID = list_ID, dplyr::bind_rows(ini_hp_i)) #>     } #>     else if (!(all(as.character(ini_hp_i$ID) %in% as.character(list_ID)) &  #>         all(as.character(list_ID) %in% as.character(ini_hp_i$ID)))) { #>         stop(\"The 'ID' column in 'ini_hp_i' is different from the 'ID' of the \",  #>             \"'data'.\") #>     } #>     else { #>         hp_i <- ini_hp_i #>     } #> } #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#253: if (ini_hp_i %>% is.null()) { #>     hp_i <- hp(kern_i, list_ID = list_ID, common_hp = common_hp,  #>         noise = TRUE) #>     cat(\"The 'ini_hp_i' argument has not been specified. Random values of\",  #>         \"hyper-parameters for the individal processes are used as\",  #>         \"initialisation.\\n \\n\") #> } else if (!(\"ID\" %in% names(ini_hp_i))) { #>     hp_i <- tibble::tibble(ID = list_ID, dplyr::bind_rows(ini_hp_i)) #> } else if (!(all(as.character(ini_hp_i$ID) %in% as.character(list_ID)) &  #>     all(as.character(list_ID) %in% as.character(ini_hp_i$ID)))) { #>     stop(\"The 'ID' column in 'ini_hp_i' is different from the 'ID' of the \",  #>         \"'data'.\") #> } else { #>     hp_i <- ini_hp_i #> } #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#254: hp_i <- hp(kern_i, list_ID = list_ID, common_hp = common_hp,  #>     noise = TRUE) #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#255: cat(\"The 'ini_hp_i' argument has not been specified. Random values of\",  #>     \"hyper-parameters for the individal processes are used as\",  #>     \"initialisation.\\n \\n\") #> The 'ini_hp_i' argument has not been specified. Random values of hyper-parameters for the individal processes are used as initialisation. #>   #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#278: if (!(\"noise\" %in% names(hp_i))) { #>     if (common_hp) { #>         hp_i <- hp_i %>% dplyr::mutate(hp(NULL, noise = T)) #>     } #>     else { #>         hp_i <- hp_i %>% dplyr::left_join(hp(NULL, list_ID = hp_i$ID,  #>             noise = T), by = \"ID\") #>     } #> } #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#288: hp_i_ini <- hp_i #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#289: hp_0_ini <- hp_0 #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#291: cv <- FALSE #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#292: logL_monitoring <- -Inf #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#293: seq_loglikelihood <- c() #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#296: for (i in 1:n_iter_max) { #>     t_i_1 <- Sys.time() #>     post <- e_step(db = data, m_0 = m_0, kern_0 = kern_0, kern_i = kern_i,  #>         hp_0 = hp_0, hp_i = hp_i, pen_diag = pen_diag) #>     if (fast_approx) { #>         seq_loglikelihood <- logL_monitoring(hp_0 = hp_0, hp_i = hp_i,  #>             db = data, m_0 = m_0, kern_0 = kern_0, kern_i = kern_i,  #>             post_mean = post$mean, post_cov = post$cov, pen_diag = pen_diag) #>         cv <- FALSE #>         break #>     } #>     new_hp <- m_step(db = data, m_0 = m_0, kern_0 = kern_0, kern_i = kern_i,  #>         old_hp_0 = hp_0, old_hp_i = hp_i, post_mean = post$mean,  #>         post_cov = post$cov, common_hp = common_hp, pen_diag = pen_diag) #>     new_hp_0 <- new_hp$hp_0 #>     new_hp_i <- new_hp$hp_i #>     if (any(is.na(new_hp_0)) | any(is.na(new_hp_i))) { #>         warning(paste0(\"The M-step encountered an error at iteration : \",  #>             i)) #>         warning(\"Training has stopped and hyper-parameters values from the \",  #>             \"last valid iteration are returned.\") #>         break #>     } #>     new_logL_monitoring <- logL_monitoring(hp_0 = new_hp_0, hp_i = new_hp_i,  #>         db = data, m_0 = m_0, kern_0 = kern_0, kern_i = kern_i,  #>         post_mean = post$mean, post_cov = post$cov, pen_diag = pen_diag) #>     diff_logL <- new_logL_monitoring - logL_monitoring #>     if (diff_logL %>% is.nan()) { #>         diff_logL <- -Inf #>     } #>     if (diff_logL < 0) { #>         warning(\"The likelihood descreased. Possible numerical issues.\") #>     } #>     hp_0 <- new_hp_0 #>     hp_i <- new_hp_i #>     logL_monitoring <- new_logL_monitoring #>     seq_loglikelihood <- c(seq_loglikelihood, logL_monitoring) #>     eps <- diff_logL/abs(logL_monitoring) #>     if (eps %>% is.nan()) { #>         eps <- 1 #>     } #>     t_i_2 <- Sys.time() #>     paste0(\"EM algorithm, step \", i, \": \", difftime(t_i_2, t_i_1,  #>         units = \"secs\") %>% round(2), \" seconds \\n \\n\") %>% cat() #>     paste0(\"Value of the likelihood: \", logL_monitoring %>% round(5),  #>         \" --- Convergence ratio = \", eps %>% round(5), \"\\n \\n\") %>%  #>         cat() #>     if (abs(eps) < cv_threshold) { #>         cat(\"The EM algorithm successfully converged, training is completed.\",  #>             \"\\n \\n\") #>         cv <- TRUE #>         break #>     } #> } #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#299: t_i_1 <- Sys.time() #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#302: post <- e_step(db = data, m_0 = m_0, kern_0 = kern_0, kern_i = kern_i,  #>     hp_0 = hp_0, hp_i = hp_i, pen_diag = pen_diag) #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#313: if (fast_approx) { #>     seq_loglikelihood <- logL_monitoring(hp_0 = hp_0, hp_i = hp_i,  #>         db = data, m_0 = m_0, kern_0 = kern_0, kern_i = kern_i,  #>         post_mean = post$mean, post_cov = post$cov, pen_diag = pen_diag) #>     cv <- FALSE #>     break #> } #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#332: new_hp <- m_step(db = data, m_0 = m_0, kern_0 = kern_0, kern_i = kern_i,  #>     old_hp_0 = hp_0, old_hp_i = hp_i, post_mean = post$mean,  #>     post_cov = post$cov, common_hp = common_hp, pen_diag = pen_diag) #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#344: new_hp_0 <- new_hp$hp_0 #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#345: new_hp_i <- new_hp$hp_i #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#348: if (any(is.na(new_hp_0)) | any(is.na(new_hp_i))) { #>     warning(paste0(\"The M-step encountered an error at iteration : \",  #>         i)) #>     warning(\"Training has stopped and hyper-parameters values from the \",  #>         \"last valid iteration are returned.\") #>     break #> } #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#358: new_logL_monitoring <- logL_monitoring(hp_0 = new_hp_0, hp_i = new_hp_i,  #>     db = data, m_0 = m_0, kern_0 = kern_0, kern_i = kern_i, post_mean = post$mean,  #>     post_cov = post$cov, pen_diag = pen_diag) #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#370: diff_logL <- new_logL_monitoring - logL_monitoring #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#371: if (diff_logL %>% is.nan()) { #>     diff_logL <- -Inf #> } #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#375: if (diff_logL < 0) { #>     warning(\"The likelihood descreased. Possible numerical issues.\") #> } #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#380: hp_0 <- new_hp_0 #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#381: hp_i <- new_hp_i #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#382: logL_monitoring <- new_logL_monitoring #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#385: seq_loglikelihood <- c(seq_loglikelihood, logL_monitoring) #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#388: eps <- diff_logL/abs(logL_monitoring) #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#389: if (eps %>% is.nan()) { #>     eps <- 1 #> } #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#394: t_i_2 <- Sys.time() #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#395: paste0(\"EM algorithm, step \", i, \": \", difftime(t_i_2, t_i_1,  #>     units = \"secs\") %>% round(2), \" seconds \\n \\n\") %>% cat() #> EM algorithm, step 1: 15.86 seconds  #>   #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#402: paste0(\"Value of the likelihood: \", logL_monitoring %>% round(5),  #>     \" --- Convergence ratio = \", eps %>% round(5), \"\\n \\n\") %>%  #>     cat() #> Value of the likelihood: -379.55987 --- Convergence ratio = Inf #>   #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#412: if (abs(eps) < cv_threshold) { #>     cat(\"The EM algorithm successfully converged, training is completed.\",  #>         \"\\n \\n\") #>     cv <- TRUE #>     break #> } #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#299: t_i_1 <- Sys.time() #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#302: post <- e_step(db = data, m_0 = m_0, kern_0 = kern_0, kern_i = kern_i,  #>     hp_0 = hp_0, hp_i = hp_i, pen_diag = pen_diag) #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#313: if (fast_approx) { #>     seq_loglikelihood <- logL_monitoring(hp_0 = hp_0, hp_i = hp_i,  #>         db = data, m_0 = m_0, kern_0 = kern_0, kern_i = kern_i,  #>         post_mean = post$mean, post_cov = post$cov, pen_diag = pen_diag) #>     cv <- FALSE #>     break #> } #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#332: new_hp <- m_step(db = data, m_0 = m_0, kern_0 = kern_0, kern_i = kern_i,  #>     old_hp_0 = hp_0, old_hp_i = hp_i, post_mean = post$mean,  #>     post_cov = post$cov, common_hp = common_hp, pen_diag = pen_diag) #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#344: new_hp_0 <- new_hp$hp_0 #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#345: new_hp_i <- new_hp$hp_i #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#348: if (any(is.na(new_hp_0)) | any(is.na(new_hp_i))) { #>     warning(paste0(\"The M-step encountered an error at iteration : \",  #>         i)) #>     warning(\"Training has stopped and hyper-parameters values from the \",  #>         \"last valid iteration are returned.\") #>     break #> } #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#358: new_logL_monitoring <- logL_monitoring(hp_0 = new_hp_0, hp_i = new_hp_i,  #>     db = data, m_0 = m_0, kern_0 = kern_0, kern_i = kern_i, post_mean = post$mean,  #>     post_cov = post$cov, pen_diag = pen_diag) #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#370: diff_logL <- new_logL_monitoring - logL_monitoring #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#371: if (diff_logL %>% is.nan()) { #>     diff_logL <- -Inf #> } #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#375: if (diff_logL < 0) { #>     warning(\"The likelihood descreased. Possible numerical issues.\") #> } #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#380: hp_0 <- new_hp_0 #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#381: hp_i <- new_hp_i #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#382: logL_monitoring <- new_logL_monitoring #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#385: seq_loglikelihood <- c(seq_loglikelihood, logL_monitoring) #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#388: eps <- diff_logL/abs(logL_monitoring) #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#389: if (eps %>% is.nan()) { #>     eps <- 1 #> } #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#394: t_i_2 <- Sys.time() #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#395: paste0(\"EM algorithm, step \", i, \": \", difftime(t_i_2, t_i_1,  #>     units = \"secs\") %>% round(2), \" seconds \\n \\n\") %>% cat() #> EM algorithm, step 2: 7.87 seconds  #>   #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#402: paste0(\"Value of the likelihood: \", logL_monitoring %>% round(5),  #>     \" --- Convergence ratio = \", eps %>% round(5), \"\\n \\n\") %>%  #>     cat() #> Value of the likelihood: -374.3461 --- Convergence ratio = 0.01393 #>   #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#412: if (abs(eps) < cv_threshold) { #>     cat(\"The EM algorithm successfully converged, training is completed.\",  #>         \"\\n \\n\") #>     cv <- TRUE #>     break #> } #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#299: t_i_1 <- Sys.time() #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#302: post <- e_step(db = data, m_0 = m_0, kern_0 = kern_0, kern_i = kern_i,  #>     hp_0 = hp_0, hp_i = hp_i, pen_diag = pen_diag) #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#313: if (fast_approx) { #>     seq_loglikelihood <- logL_monitoring(hp_0 = hp_0, hp_i = hp_i,  #>         db = data, m_0 = m_0, kern_0 = kern_0, kern_i = kern_i,  #>         post_mean = post$mean, post_cov = post$cov, pen_diag = pen_diag) #>     cv <- FALSE #>     break #> } #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#332: new_hp <- m_step(db = data, m_0 = m_0, kern_0 = kern_0, kern_i = kern_i,  #>     old_hp_0 = hp_0, old_hp_i = hp_i, post_mean = post$mean,  #>     post_cov = post$cov, common_hp = common_hp, pen_diag = pen_diag) #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#344: new_hp_0 <- new_hp$hp_0 #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#345: new_hp_i <- new_hp$hp_i #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#348: if (any(is.na(new_hp_0)) | any(is.na(new_hp_i))) { #>     warning(paste0(\"The M-step encountered an error at iteration : \",  #>         i)) #>     warning(\"Training has stopped and hyper-parameters values from the \",  #>         \"last valid iteration are returned.\") #>     break #> } #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#358: new_logL_monitoring <- logL_monitoring(hp_0 = new_hp_0, hp_i = new_hp_i,  #>     db = data, m_0 = m_0, kern_0 = kern_0, kern_i = kern_i, post_mean = post$mean,  #>     post_cov = post$cov, pen_diag = pen_diag) #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#370: diff_logL <- new_logL_monitoring - logL_monitoring #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#371: if (diff_logL %>% is.nan()) { #>     diff_logL <- -Inf #> } #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#375: if (diff_logL < 0) { #>     warning(\"The likelihood descreased. Possible numerical issues.\") #> } #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#380: hp_0 <- new_hp_0 #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#381: hp_i <- new_hp_i #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#382: logL_monitoring <- new_logL_monitoring #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#385: seq_loglikelihood <- c(seq_loglikelihood, logL_monitoring) #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#388: eps <- diff_logL/abs(logL_monitoring) #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#389: if (eps %>% is.nan()) { #>     eps <- 1 #> } #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#394: t_i_2 <- Sys.time() #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#395: paste0(\"EM algorithm, step \", i, \": \", difftime(t_i_2, t_i_1,  #>     units = \"secs\") %>% round(2), \" seconds \\n \\n\") %>% cat() #> EM algorithm, step 3: 10.97 seconds  #>   #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#402: paste0(\"Value of the likelihood: \", logL_monitoring %>% round(5),  #>     \" --- Convergence ratio = \", eps %>% round(5), \"\\n \\n\") %>%  #>     cat() #> Value of the likelihood: -374.17964 --- Convergence ratio = 0.00044 #>   #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#412: if (abs(eps) < cv_threshold) { #>     cat(\"The EM algorithm successfully converged, training is completed.\",  #>         \"\\n \\n\") #>     cv <- TRUE #>     break #> } #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#413: cat(\"The EM algorithm successfully converged, training is completed.\",  #>     \"\\n \\n\") #> The EM algorithm successfully converged, training is completed.  #>   #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#417: cv <- TRUE #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#418: break #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#422: if (!cv & (i == n_iter_max)) { #>     warning(\"The EM algorithm has reached the maximum number of iterations \",  #>         \"before convergence, training might be sub-optimal \\n \\n\") #> } #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#430: if (!is.null(grid_inputs)) { #>     cat(\"Start evaluating hyper-posterior distribution of the mean process\",  #>         \"on the provided grid of inputs... \\n \\n\") #>     post <- hyperposterior(data = data, hp_0 = hp_0, hp_i = hp_i,  #>         kern_0 = kern_0, kern_i = kern_i, prior_mean = prior_mean,  #>         grid_inputs = grid_inputs, pen_diag = pen_diag) #>     cat(\"Done!\\n \\n\") #> } else { #>     post$pred <- tibble::tibble(Input = post$mean %>% dplyr::pull(.data$Input),  #>         Mean = post$mean %>% dplyr::pull(.data$Output), Var = post$cov %>%  #>             diag() %>% as.vector()) #> } #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#449: post$pred <- tibble::tibble(Input = post$mean %>% dplyr::pull(.data$Input),  #>     Mean = post$mean %>% dplyr::pull(.data$Output), Var = post$cov %>%  #>         diag() %>% as.vector()) #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#457: fct_args <- list(data = data, prior_mean = prior_mean, ini_hp_0 = hp_0_ini,  #>     ini_hp_i = hp_i_ini, kern_0 = kern_0, kern_i = kern_i, common_hp = common_hp,  #>     grid_inputs = grid_inputs, pen_diag = pen_diag, n_iter_max = n_iter_max,  #>     cv_threshold = cv_threshold) #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#471: t_2 <- Sys.time() #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#473: list(hp_0 = hp_0, hp_i = hp_i, hyperpost = post, ini_args = fct_args,  #>     seq_loglikelihood = seq_loglikelihood, converged = cv, training_time = difftime(t_2,  #>         t_1, units = \"secs\")) %>% return()  pred  <- pred_magma(data = magma_pred,                     trained_model = model,                      grid_inputs = seq(0,10, 0.01)) #> The hyper-posterior distribution of the mean process provided in 'hyperpost' argument isn't evaluated on the expected inputs. #>   #>  Start evaluating the hyper-posterior on the correct inputs... #>   #> The 'prior_mean' argument has not been specified. The hyper-prior mean function is thus set to be 0 everywhere. #>   #> Done! #>"},{"path":"https://arthurleroy.github.io/MagmaClustR/index.html","id":"display-the-resulting-predictions","dir":"","previous_headings":"Example: Magma","what":"Display the resulting predictions","title":"Clustering and Prediction using Multi-Task Gaussian Processes with\n    Common Mean","text":"Several arguments available specific plotting function offer additional control display results. instance, GP prediction can represented heatmap probabilities:  Additionally, also possible create animated representations using functions generate GIFs. instance, , true testing points represented red dots can observe prediction evolves add data points prediction dataset.  Note grid_inputs argument optional. merely allows users control grid values prediction performed.","code":"plot_gp(pred_gp = pred,         data = magma_pred,         data_train = magma_train,         prior_mean = model$hyperpost$mean,         heatmap = TRUE) pred_gif  <- pred_gif(data = magma_pred,                       trained_model = model,                       grid_inputs = seq(0, 10, 0.01)) #>  => 1 => 2 => 3 => 4 => 5  plot_gif(pred_gp = pred_gif,         data = magma_pred,         data_train = magma_train,         prior_mean = model$hyperpost$mean) +    ggplot2::geom_point(data = magma_test,                        ggplot2::aes(x = Input, y = Output),                        color = 'red')"},{"path":"https://arthurleroy.github.io/MagmaClustR/index.html","id":"example-magmaclust","dir":"","previous_headings":"","what":"Example: MagmaClust","title":"Clustering and Prediction using Multi-Task Gaussian Processes with\n    Common Mean","text":"basic example simulate dataset adequate format, train MagmaClust model use perform simultaneous clustering predictions.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/index.html","id":"data-generation-1","dir":"","previous_headings":"Example: MagmaClust","what":"Data generation","title":"Clustering and Prediction using Multi-Task Gaussian Processes with\n    Common Mean","text":"","code":"## Simulate a dataset containing 3 clusters of 4 individuals, each observed at 10 input locations set.seed(2)  data_magmaclust <- simu_db(M = 4, N = 10, K = 3)  ## Split individuals into training and prediction sets, and define test points list_ID = unique(data_magmaclust$ID) magmaclust_train <- data_magmaclust %>% subset(ID %in% list_ID[1:11]) magmaclust_pred <- data_magmaclust %>% subset(ID == list_ID[12]) %>% head(5) magmaclust_test <- data_magmaclust %>% subset(ID == list_ID[12]) %>% tail(5)  data_magmaclust #> # A tibble: 120 x 3 #>    ID         Output Input #>    <chr>       <dbl> <dbl> #>  1 ID1-Clust1 -11.1   0.25 #>  2 ID1-Clust1  -7.64  0.8  #>  3 ID1-Clust1  -4.91  2    #>  4 ID1-Clust1 -13.2   4.2  #>  5 ID1-Clust1 -14.3   4.6  #>  6 ID1-Clust1 -13.0   6.2  #>  7 ID1-Clust1 -14.1   6.75 #>  8 ID1-Clust1 -20.3   7.95 #>  9 ID1-Clust1 -14.5   8.85 #> 10 ID1-Clust1 -12.2   9.85 #> # ... with 110 more rows"},{"path":"https://arthurleroy.github.io/MagmaClustR/index.html","id":"training-and-prediction-with-magmaclust","dir":"","previous_headings":"Example: MagmaClust","what":"Training and prediction with MagmaClust","title":"Clustering and Prediction using Multi-Task Gaussian Processes with\n    Common Mean","text":"","code":"model_clust <- train_magmaclust(data = magmaclust_train) #> The number of cluster argument has not been specified. There will be 3 cluster by default.  #>   #> The 'ini_hp_i' argument has not been specified. Random values of hyper-parameters for the individual processes are used as initialisation. #>   #> The 'ini_hp_k' argument has not been specified. Random values of hyper-parameters for the mean processes are used as initialisation. #>   #> The 'prior_mean' argument has not been specified. The hyper_prior mean function is thus set to be 0 everywhere. #>   #> VEM algorithm, step 1: 62.31 seconds  #>   #> Value of the elbo: -403.8673 --- Convergence ratio = Inf #>   #> VEM algorithm, step 2: 32.01 seconds  #>   #> Value of the elbo: -383.34763 --- Convergence ratio = 0.05353 #>   #> VEM algorithm, step 3: 19.11 seconds  #>   #> Value of the elbo: -383.08831 --- Convergence ratio = 0.00068 #>   #> The EM algorithm successfully converged, training is completed.  #>   pred_clust  <- pred_magmaclust(data = magmaclust_pred,                     trained_model = model_clust,                     grid_inputs = seq(0, 10, 0.01),                      plot = FALSE) #> The hyper-posterior distribution of the mean process provided in 'hyperpost' argument isn't evaluated on the expected inputs. Start evaluating the hyper-posterior on the correct inputs... #>   #> The 'prior_mean_k' argument has not been specified. The hyper-prior  mean functions are thus set to be 0 everywhere. #>   #> Done! #>"},{"path":"https://arthurleroy.github.io/MagmaClustR/index.html","id":"display-the-resulting-predictions-1","dir":"","previous_headings":"Example: MagmaClust","what":"Display the resulting predictions","title":"Clustering and Prediction using Multi-Task Gaussian Processes with\n    Common Mean","text":", specific plotting function provided. MagmaClust, advise use heatmap representation priority, mixture GPs may unimodal general (thus prevents definition Credible Interval).","code":"## Allocate individuals to their most probable cluster to colour them by clusters afterwards data_train_with_clust = data_allocate_cluster(model_clust)  plot_magmaclust(pred = pred_clust,                 cluster = \"all\",                 data = magmaclust_pred,                 data_train = data_train_with_clust,                 col_clust = TRUE,                 prior_mean = model_clust$hyperpost$mean,                 y_grid = seq(0, 60, 0.5),                 heatmap = TRUE)"},{"path":"https://arthurleroy.github.io/MagmaClustR/index.html","id":"example-in-2-dimensions","dir":"","previous_headings":"","what":"Example: in 2-dimensions","title":"Clustering and Prediction using Multi-Task Gaussian Processes with\n    Common Mean","text":"Although unidimensional-input problems easier visualise, Magma MagmaClust can also applied many covariates desired model.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/index.html","id":"data-generation-2","dir":"","previous_headings":"Example: in 2-dimensions","what":"Data generation","title":"Clustering and Prediction using Multi-Task Gaussian Processes with\n    Common Mean","text":"","code":"library(MagmaClustR) ## Dataset with 11 individuals, 10 reference input locations and a covariate set.seed(2)  data_dim2 <- simu_db(M = 11, N = 10, covariate = TRUE)  ## Split individuals into training and prediction sets, and define test points dim2_train <- data_dim2 %>% subset(ID %in% 1:10) dim2_pred <- data_dim2 %>% subset(ID == 11) %>% head(5) dim2_test <- data_dim2 %>% subset(ID == 11) %>% tail(5)  data_dim2 #> # A tibble: 110 x 4 #>    ID    Output Input Covariate #>    <chr>  <dbl> <dbl>     <dbl> #>  1 1     -11.1   0.25     -2    #>  2 1      -7.64  0.8       1.94 #>  3 1      -4.91  2         4.64 #>  4 1     -13.2   4.2      -3.7  #>  5 1     -14.3   4.6      -4.24 #>  6 1     -13.0   6.2       0.68 #>  7 1     -14.1   6.75      0.55 #>  8 1     -20.3   7.95     -4.38 #>  9 1     -14.5   8.85      1.74 #> 10 1     -12.2   9.85      4.14 #> # ... with 100 more rows"},{"path":"https://arthurleroy.github.io/MagmaClustR/index.html","id":"training-and-prediction-with-magma-1","dir":"","previous_headings":"Example: in 2-dimensions","what":"Training and prediction with Magma","title":"Clustering and Prediction using Multi-Task Gaussian Processes with\n    Common Mean","text":"","code":"model_dim2 <- train_magma(data = dim2_train) #> The 'prior_mean' argument has not been specified. The hyper_prior mean function is thus set to be 0 everywhere. #>   #> The 'ini_hp_0' argument has not been specified. Random values of hyper-parameters for the mean process are used as initialisation. #>   #> Called from: train_magma(data = dim2_train) #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#238: if (\"ID\" %in% names(hp_0)) { #>     hp_0 = hp_0[names(hp_0) != \"ID\"] #> } #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#243: if (kern_i %>% is.function()) { #>     if (ini_hp_i %>% is.null()) { #>         stop(\"When using a custom kernel function the 'ini_hp_i' argument is \",  #>             \"mandatory, in order to provide the name of the hyper-parameters. \",  #>             \"You can use the function 'hp()' to easily generate a tibble of random\",  #>             \" hyper-parameters with the desired format for initialisation.\") #>     } #> } else { #>     if (ini_hp_i %>% is.null()) { #>         hp_i <- hp(kern_i, list_ID = list_ID, common_hp = common_hp,  #>             noise = TRUE) #>         cat(\"The 'ini_hp_i' argument has not been specified. Random values of\",  #>             \"hyper-parameters for the individal processes are used as\",  #>             \"initialisation.\\n \\n\") #>     } #>     else if (!(\"ID\" %in% names(ini_hp_i))) { #>         hp_i <- tibble::tibble(ID = list_ID, dplyr::bind_rows(ini_hp_i)) #>     } #>     else if (!(all(as.character(ini_hp_i$ID) %in% as.character(list_ID)) &  #>         all(as.character(list_ID) %in% as.character(ini_hp_i$ID)))) { #>         stop(\"The 'ID' column in 'ini_hp_i' is different from the 'ID' of the \",  #>             \"'data'.\") #>     } #>     else { #>         hp_i <- ini_hp_i #>     } #> } #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#253: if (ini_hp_i %>% is.null()) { #>     hp_i <- hp(kern_i, list_ID = list_ID, common_hp = common_hp,  #>         noise = TRUE) #>     cat(\"The 'ini_hp_i' argument has not been specified. Random values of\",  #>         \"hyper-parameters for the individal processes are used as\",  #>         \"initialisation.\\n \\n\") #> } else if (!(\"ID\" %in% names(ini_hp_i))) { #>     hp_i <- tibble::tibble(ID = list_ID, dplyr::bind_rows(ini_hp_i)) #> } else if (!(all(as.character(ini_hp_i$ID) %in% as.character(list_ID)) &  #>     all(as.character(list_ID) %in% as.character(ini_hp_i$ID)))) { #>     stop(\"The 'ID' column in 'ini_hp_i' is different from the 'ID' of the \",  #>         \"'data'.\") #> } else { #>     hp_i <- ini_hp_i #> } #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#254: hp_i <- hp(kern_i, list_ID = list_ID, common_hp = common_hp,  #>     noise = TRUE) #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#255: cat(\"The 'ini_hp_i' argument has not been specified. Random values of\",  #>     \"hyper-parameters for the individal processes are used as\",  #>     \"initialisation.\\n \\n\") #> The 'ini_hp_i' argument has not been specified. Random values of hyper-parameters for the individal processes are used as initialisation. #>   #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#278: if (!(\"noise\" %in% names(hp_i))) { #>     if (common_hp) { #>         hp_i <- hp_i %>% dplyr::mutate(hp(NULL, noise = T)) #>     } #>     else { #>         hp_i <- hp_i %>% dplyr::left_join(hp(NULL, list_ID = hp_i$ID,  #>             noise = T), by = \"ID\") #>     } #> } #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#288: hp_i_ini <- hp_i #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#289: hp_0_ini <- hp_0 #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#291: cv <- FALSE #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#292: logL_monitoring <- -Inf #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#293: seq_loglikelihood <- c() #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#296: for (i in 1:n_iter_max) { #>     t_i_1 <- Sys.time() #>     post <- e_step(db = data, m_0 = m_0, kern_0 = kern_0, kern_i = kern_i,  #>         hp_0 = hp_0, hp_i = hp_i, pen_diag = pen_diag) #>     if (fast_approx) { #>         seq_loglikelihood <- logL_monitoring(hp_0 = hp_0, hp_i = hp_i,  #>             db = data, m_0 = m_0, kern_0 = kern_0, kern_i = kern_i,  #>             post_mean = post$mean, post_cov = post$cov, pen_diag = pen_diag) #>         cv <- FALSE #>         break #>     } #>     new_hp <- m_step(db = data, m_0 = m_0, kern_0 = kern_0, kern_i = kern_i,  #>         old_hp_0 = hp_0, old_hp_i = hp_i, post_mean = post$mean,  #>         post_cov = post$cov, common_hp = common_hp, pen_diag = pen_diag) #>     new_hp_0 <- new_hp$hp_0 #>     new_hp_i <- new_hp$hp_i #>     if (any(is.na(new_hp_0)) | any(is.na(new_hp_i))) { #>         warning(paste0(\"The M-step encountered an error at iteration : \",  #>             i)) #>         warning(\"Training has stopped and hyper-parameters values from the \",  #>             \"last valid iteration are returned.\") #>         break #>     } #>     new_logL_monitoring <- logL_monitoring(hp_0 = new_hp_0, hp_i = new_hp_i,  #>         db = data, m_0 = m_0, kern_0 = kern_0, kern_i = kern_i,  #>         post_mean = post$mean, post_cov = post$cov, pen_diag = pen_diag) #>     diff_logL <- new_logL_monitoring - logL_monitoring #>     if (diff_logL %>% is.nan()) { #>         diff_logL <- -Inf #>     } #>     if (diff_logL < 0) { #>         warning(\"The likelihood descreased. Possible numerical issues.\") #>     } #>     hp_0 <- new_hp_0 #>     hp_i <- new_hp_i #>     logL_monitoring <- new_logL_monitoring #>     seq_loglikelihood <- c(seq_loglikelihood, logL_monitoring) #>     eps <- diff_logL/abs(logL_monitoring) #>     if (eps %>% is.nan()) { #>         eps <- 1 #>     } #>     t_i_2 <- Sys.time() #>     paste0(\"EM algorithm, step \", i, \": \", difftime(t_i_2, t_i_1,  #>         units = \"secs\") %>% round(2), \" seconds \\n \\n\") %>% cat() #>     paste0(\"Value of the likelihood: \", logL_monitoring %>% round(5),  #>         \" --- Convergence ratio = \", eps %>% round(5), \"\\n \\n\") %>%  #>         cat() #>     if (abs(eps) < cv_threshold) { #>         cat(\"The EM algorithm successfully converged, training is completed.\",  #>             \"\\n \\n\") #>         cv <- TRUE #>         break #>     } #> } #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#299: t_i_1 <- Sys.time() #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#302: post <- e_step(db = data, m_0 = m_0, kern_0 = kern_0, kern_i = kern_i,  #>     hp_0 = hp_0, hp_i = hp_i, pen_diag = pen_diag) #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#313: if (fast_approx) { #>     seq_loglikelihood <- logL_monitoring(hp_0 = hp_0, hp_i = hp_i,  #>         db = data, m_0 = m_0, kern_0 = kern_0, kern_i = kern_i,  #>         post_mean = post$mean, post_cov = post$cov, pen_diag = pen_diag) #>     cv <- FALSE #>     break #> } #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#332: new_hp <- m_step(db = data, m_0 = m_0, kern_0 = kern_0, kern_i = kern_i,  #>     old_hp_0 = hp_0, old_hp_i = hp_i, post_mean = post$mean,  #>     post_cov = post$cov, common_hp = common_hp, pen_diag = pen_diag) #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#344: new_hp_0 <- new_hp$hp_0 #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#345: new_hp_i <- new_hp$hp_i #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#348: if (any(is.na(new_hp_0)) | any(is.na(new_hp_i))) { #>     warning(paste0(\"The M-step encountered an error at iteration : \",  #>         i)) #>     warning(\"Training has stopped and hyper-parameters values from the \",  #>         \"last valid iteration are returned.\") #>     break #> } #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#358: new_logL_monitoring <- logL_monitoring(hp_0 = new_hp_0, hp_i = new_hp_i,  #>     db = data, m_0 = m_0, kern_0 = kern_0, kern_i = kern_i, post_mean = post$mean,  #>     post_cov = post$cov, pen_diag = pen_diag) #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#370: diff_logL <- new_logL_monitoring - logL_monitoring #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#371: if (diff_logL %>% is.nan()) { #>     diff_logL <- -Inf #> } #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#375: if (diff_logL < 0) { #>     warning(\"The likelihood descreased. Possible numerical issues.\") #> } #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#380: hp_0 <- new_hp_0 #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#381: hp_i <- new_hp_i #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#382: logL_monitoring <- new_logL_monitoring #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#385: seq_loglikelihood <- c(seq_loglikelihood, logL_monitoring) #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#388: eps <- diff_logL/abs(logL_monitoring) #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#389: if (eps %>% is.nan()) { #>     eps <- 1 #> } #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#394: t_i_2 <- Sys.time() #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#395: paste0(\"EM algorithm, step \", i, \": \", difftime(t_i_2, t_i_1,  #>     units = \"secs\") %>% round(2), \" seconds \\n \\n\") %>% cat() #> EM algorithm, step 1: 12.45 seconds  #>   #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#402: paste0(\"Value of the likelihood: \", logL_monitoring %>% round(5),  #>     \" --- Convergence ratio = \", eps %>% round(5), \"\\n \\n\") %>%  #>     cat() #> Value of the likelihood: -242.84823 --- Convergence ratio = Inf #>   #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#412: if (abs(eps) < cv_threshold) { #>     cat(\"The EM algorithm successfully converged, training is completed.\",  #>         \"\\n \\n\") #>     cv <- TRUE #>     break #> } #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#299: t_i_1 <- Sys.time() #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#302: post <- e_step(db = data, m_0 = m_0, kern_0 = kern_0, kern_i = kern_i,  #>     hp_0 = hp_0, hp_i = hp_i, pen_diag = pen_diag) #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#313: if (fast_approx) { #>     seq_loglikelihood <- logL_monitoring(hp_0 = hp_0, hp_i = hp_i,  #>         db = data, m_0 = m_0, kern_0 = kern_0, kern_i = kern_i,  #>         post_mean = post$mean, post_cov = post$cov, pen_diag = pen_diag) #>     cv <- FALSE #>     break #> } #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#332: new_hp <- m_step(db = data, m_0 = m_0, kern_0 = kern_0, kern_i = kern_i,  #>     old_hp_0 = hp_0, old_hp_i = hp_i, post_mean = post$mean,  #>     post_cov = post$cov, common_hp = common_hp, pen_diag = pen_diag) #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#344: new_hp_0 <- new_hp$hp_0 #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#345: new_hp_i <- new_hp$hp_i #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#348: if (any(is.na(new_hp_0)) | any(is.na(new_hp_i))) { #>     warning(paste0(\"The M-step encountered an error at iteration : \",  #>         i)) #>     warning(\"Training has stopped and hyper-parameters values from the \",  #>         \"last valid iteration are returned.\") #>     break #> } #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#358: new_logL_monitoring <- logL_monitoring(hp_0 = new_hp_0, hp_i = new_hp_i,  #>     db = data, m_0 = m_0, kern_0 = kern_0, kern_i = kern_i, post_mean = post$mean,  #>     post_cov = post$cov, pen_diag = pen_diag) #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#370: diff_logL <- new_logL_monitoring - logL_monitoring #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#371: if (diff_logL %>% is.nan()) { #>     diff_logL <- -Inf #> } #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#375: if (diff_logL < 0) { #>     warning(\"The likelihood descreased. Possible numerical issues.\") #> } #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#380: hp_0 <- new_hp_0 #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#381: hp_i <- new_hp_i #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#382: logL_monitoring <- new_logL_monitoring #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#385: seq_loglikelihood <- c(seq_loglikelihood, logL_monitoring) #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#388: eps <- diff_logL/abs(logL_monitoring) #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#389: if (eps %>% is.nan()) { #>     eps <- 1 #> } #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#394: t_i_2 <- Sys.time() #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#395: paste0(\"EM algorithm, step \", i, \": \", difftime(t_i_2, t_i_1,  #>     units = \"secs\") %>% round(2), \" seconds \\n \\n\") %>% cat() #> EM algorithm, step 2: 15.13 seconds  #>   #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#402: paste0(\"Value of the likelihood: \", logL_monitoring %>% round(5),  #>     \" --- Convergence ratio = \", eps %>% round(5), \"\\n \\n\") %>%  #>     cat() #> Value of the likelihood: -231.94883 --- Convergence ratio = 0.04699 #>   #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#412: if (abs(eps) < cv_threshold) { #>     cat(\"The EM algorithm successfully converged, training is completed.\",  #>         \"\\n \\n\") #>     cv <- TRUE #>     break #> } #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#299: t_i_1 <- Sys.time() #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#302: post <- e_step(db = data, m_0 = m_0, kern_0 = kern_0, kern_i = kern_i,  #>     hp_0 = hp_0, hp_i = hp_i, pen_diag = pen_diag) #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#313: if (fast_approx) { #>     seq_loglikelihood <- logL_monitoring(hp_0 = hp_0, hp_i = hp_i,  #>         db = data, m_0 = m_0, kern_0 = kern_0, kern_i = kern_i,  #>         post_mean = post$mean, post_cov = post$cov, pen_diag = pen_diag) #>     cv <- FALSE #>     break #> } #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#332: new_hp <- m_step(db = data, m_0 = m_0, kern_0 = kern_0, kern_i = kern_i,  #>     old_hp_0 = hp_0, old_hp_i = hp_i, post_mean = post$mean,  #>     post_cov = post$cov, common_hp = common_hp, pen_diag = pen_diag) #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#344: new_hp_0 <- new_hp$hp_0 #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#345: new_hp_i <- new_hp$hp_i #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#348: if (any(is.na(new_hp_0)) | any(is.na(new_hp_i))) { #>     warning(paste0(\"The M-step encountered an error at iteration : \",  #>         i)) #>     warning(\"Training has stopped and hyper-parameters values from the \",  #>         \"last valid iteration are returned.\") #>     break #> } #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#358: new_logL_monitoring <- logL_monitoring(hp_0 = new_hp_0, hp_i = new_hp_i,  #>     db = data, m_0 = m_0, kern_0 = kern_0, kern_i = kern_i, post_mean = post$mean,  #>     post_cov = post$cov, pen_diag = pen_diag) #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#370: diff_logL <- new_logL_monitoring - logL_monitoring #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#371: if (diff_logL %>% is.nan()) { #>     diff_logL <- -Inf #> } #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#375: if (diff_logL < 0) { #>     warning(\"The likelihood descreased. Possible numerical issues.\") #> } #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#380: hp_0 <- new_hp_0 #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#381: hp_i <- new_hp_i #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#382: logL_monitoring <- new_logL_monitoring #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#385: seq_loglikelihood <- c(seq_loglikelihood, logL_monitoring) #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#388: eps <- diff_logL/abs(logL_monitoring) #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#389: if (eps %>% is.nan()) { #>     eps <- 1 #> } #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#394: t_i_2 <- Sys.time() #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#395: paste0(\"EM algorithm, step \", i, \": \", difftime(t_i_2, t_i_1,  #>     units = \"secs\") %>% round(2), \" seconds \\n \\n\") %>% cat() #> EM algorithm, step 3: 12.61 seconds  #>   #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#402: paste0(\"Value of the likelihood: \", logL_monitoring %>% round(5),  #>     \" --- Convergence ratio = \", eps %>% round(5), \"\\n \\n\") %>%  #>     cat() #> Value of the likelihood: -231.6273 --- Convergence ratio = 0.00139 #>   #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#412: if (abs(eps) < cv_threshold) { #>     cat(\"The EM algorithm successfully converged, training is completed.\",  #>         \"\\n \\n\") #>     cv <- TRUE #>     break #> } #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#299: t_i_1 <- Sys.time() #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#302: post <- e_step(db = data, m_0 = m_0, kern_0 = kern_0, kern_i = kern_i,  #>     hp_0 = hp_0, hp_i = hp_i, pen_diag = pen_diag) #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#313: if (fast_approx) { #>     seq_loglikelihood <- logL_monitoring(hp_0 = hp_0, hp_i = hp_i,  #>         db = data, m_0 = m_0, kern_0 = kern_0, kern_i = kern_i,  #>         post_mean = post$mean, post_cov = post$cov, pen_diag = pen_diag) #>     cv <- FALSE #>     break #> } #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#332: new_hp <- m_step(db = data, m_0 = m_0, kern_0 = kern_0, kern_i = kern_i,  #>     old_hp_0 = hp_0, old_hp_i = hp_i, post_mean = post$mean,  #>     post_cov = post$cov, common_hp = common_hp, pen_diag = pen_diag) #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#344: new_hp_0 <- new_hp$hp_0 #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#345: new_hp_i <- new_hp$hp_i #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#348: if (any(is.na(new_hp_0)) | any(is.na(new_hp_i))) { #>     warning(paste0(\"The M-step encountered an error at iteration : \",  #>         i)) #>     warning(\"Training has stopped and hyper-parameters values from the \",  #>         \"last valid iteration are returned.\") #>     break #> } #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#358: new_logL_monitoring <- logL_monitoring(hp_0 = new_hp_0, hp_i = new_hp_i,  #>     db = data, m_0 = m_0, kern_0 = kern_0, kern_i = kern_i, post_mean = post$mean,  #>     post_cov = post$cov, pen_diag = pen_diag) #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#370: diff_logL <- new_logL_monitoring - logL_monitoring #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#371: if (diff_logL %>% is.nan()) { #>     diff_logL <- -Inf #> } #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#375: if (diff_logL < 0) { #>     warning(\"The likelihood descreased. Possible numerical issues.\") #> } #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#380: hp_0 <- new_hp_0 #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#381: hp_i <- new_hp_i #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#382: logL_monitoring <- new_logL_monitoring #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#385: seq_loglikelihood <- c(seq_loglikelihood, logL_monitoring) #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#388: eps <- diff_logL/abs(logL_monitoring) #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#389: if (eps %>% is.nan()) { #>     eps <- 1 #> } #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#394: t_i_2 <- Sys.time() #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#395: paste0(\"EM algorithm, step \", i, \": \", difftime(t_i_2, t_i_1,  #>     units = \"secs\") %>% round(2), \" seconds \\n \\n\") %>% cat() #> EM algorithm, step 4: 8.69 seconds  #>   #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#402: paste0(\"Value of the likelihood: \", logL_monitoring %>% round(5),  #>     \" --- Convergence ratio = \", eps %>% round(5), \"\\n \\n\") %>%  #>     cat() #> Value of the likelihood: -231.61445 --- Convergence ratio = 6e-05 #>   #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#412: if (abs(eps) < cv_threshold) { #>     cat(\"The EM algorithm successfully converged, training is completed.\",  #>         \"\\n \\n\") #>     cv <- TRUE #>     break #> } #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#413: cat(\"The EM algorithm successfully converged, training is completed.\",  #>     \"\\n \\n\") #> The EM algorithm successfully converged, training is completed.  #>   #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#417: cv <- TRUE #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#418: break #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#422: if (!cv & (i == n_iter_max)) { #>     warning(\"The EM algorithm has reached the maximum number of iterations \",  #>         \"before convergence, training might be sub-optimal \\n \\n\") #> } #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#430: if (!is.null(grid_inputs)) { #>     cat(\"Start evaluating hyper-posterior distribution of the mean process\",  #>         \"on the provided grid of inputs... \\n \\n\") #>     post <- hyperposterior(data = data, hp_0 = hp_0, hp_i = hp_i,  #>         kern_0 = kern_0, kern_i = kern_i, prior_mean = prior_mean,  #>         grid_inputs = grid_inputs, pen_diag = pen_diag) #>     cat(\"Done!\\n \\n\") #> } else { #>     post$pred <- tibble::tibble(Input = post$mean %>% dplyr::pull(.data$Input),  #>         Mean = post$mean %>% dplyr::pull(.data$Output), Var = post$cov %>%  #>             diag() %>% as.vector()) #> } #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#449: post$pred <- tibble::tibble(Input = post$mean %>% dplyr::pull(.data$Input),  #>     Mean = post$mean %>% dplyr::pull(.data$Output), Var = post$cov %>%  #>         diag() %>% as.vector()) #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#457: fct_args <- list(data = data, prior_mean = prior_mean, ini_hp_0 = hp_0_ini,  #>     ini_hp_i = hp_i_ini, kern_0 = kern_0, kern_i = kern_i, common_hp = common_hp,  #>     grid_inputs = grid_inputs, pen_diag = pen_diag, n_iter_max = n_iter_max,  #>     cv_threshold = cv_threshold) #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#471: t_2 <- Sys.time() #> debug at C:/Users/user/Mon Drive/Travail/GitHub/MagmaClustR/R/training.R#473: list(hp_0 = hp_0, hp_i = hp_i, hyperpost = post, ini_args = fct_args,  #>     seq_loglikelihood = seq_loglikelihood, converged = cv, training_time = difftime(t_2,  #>         t_1, units = \"secs\")) %>% return()  pred_dim2  <- pred_magma(data = dim2_pred,                          trained_model = model_dim2) #> The hyper-posterior distribution of the mean process provided in 'hyperpost' argument isn't evaluated on the expected inputs. #>   #>  Start evaluating the hyper-posterior on the correct inputs... #>   #> The 'prior_mean' argument has not been specified. The hyper-prior mean function is thus set to be 0 everywhere. #>   #> Done! #>"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/MagmaClustR.html","id":null,"dir":"Reference","previous_headings":"","what":"MagmaClustR : Clustering and Prediction using Multi-Task Gaussian Processes — MagmaClustR","title":"MagmaClustR : Clustering and Prediction using Multi-Task Gaussian Processes — MagmaClustR","text":"MagmaClustR package implements two main algorithms, called Magma MagmaClust, using multi-task GPs model perform predictions supervised learning problems. Theses approaches leverage learning cluster-specific mean processes, common across similar tasks, provide enhanced prediction performances (even far data) linear computational cost (number tasks). MagmaClust generalisation Magma tasks simultaneously clustered groups, associated specific mean process. User-oriented functions package decomposed training, prediction plotting functions. basic features standard GPs also implemented.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/MagmaClustR.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"MagmaClustR : Clustering and Prediction using Multi-Task Gaussian Processes — MagmaClustR","text":"quick introduction MagmaClustR, please refer README https://github.com/ArthurLeroy/MagmaClustR","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/MagmaClustR.html","id":"author-s-","dir":"Reference","previous_headings":"","what":"Author(s)","title":"MagmaClustR : Clustering and Prediction using Multi-Task Gaussian Processes — MagmaClustR","text":"Arthur Leroy, Pierre Pathe Pierre Latouche  Maintainer: Arthur Leroy - arthur.leroy.pro@gmail.com","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/MagmaClustR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"MagmaClustR : Clustering and Prediction using Multi-Task Gaussian Processes — MagmaClustR","text":"Arthur Leroy, Pierre Latouche, Benjamin Guedj, Servane Gey.  MAGMA: Inference Prediction Multi-Task Gaussian Processes. Machine Learning, 2022, https://link.springer.com/article/10.1007/s10994-022-06172-1 Arthur Leroy, Pierre Latouche, Benjamin Guedj, Servane Gey.  Cluster-Specific Predictions Multi-Task Gaussian Processes. PREPRINT, Nov. 2020, https://arxiv.org/abs/2011.07866","code":""},{"path":[]},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/MagmaClustR.html","id":"simulate-a-dataset-train-and-predict-with-magma-","dir":"Reference","previous_headings":"","what":"Simulate a dataset, train and predict with Magma","title":"MagmaClustR : Clustering and Prediction using Multi-Task Gaussian Processes — MagmaClustR","text":"set.seed(42)  data_magma <- simu_db(M = 11, N = 10, K = 1)  magma_train <- data_magma %>% subset(ID %% 1:10)  magma_test <- data_magma %>% subset(ID == 11) %>% head(5) magma_model <- train_magma(data = magma_train)  magma_pred  <- pred_magma(data = magma_test, trained_model = magma_model, grid_inputs = seq(0, 10, 0.01))","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/MagmaClustR.html","id":"simulate-a-dataset-train-and-predict-with-magmaclust-","dir":"Reference","previous_headings":"","what":"Simulate a dataset, train and predict with MagmaClust","title":"MagmaClustR : Clustering and Prediction using Multi-Task Gaussian Processes — MagmaClustR","text":"set.seed(42)  data_magmaclust <- simu_db(M = 4, N = 10, K = 3)  list_ID = unique(data_magmaclust$ID)  magmaclust_train <- data_magmaclust %>% subset(ID %% list_ID[1:11])  magmaclust_test <- data_magmaclust %>% subset(ID == list_ID[12]) %>% head(5) magmaclust_model <- train_magmaclust(data = magmaclust_train)  magmaclust_pred  <- pred_magmaclust(data = magmaclust_test,  trained_model = magmaclust_model, grid_inputs = seq(0, 10, 0.01))","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/data_allocate_cluster.html","id":null,"dir":"Reference","previous_headings":"","what":"Allocate training data into the most probable cluster — data_allocate_cluster","title":"Allocate training data into the most probable cluster — data_allocate_cluster","text":"Allocate training data probable cluster","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/data_allocate_cluster.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Allocate training data into the most probable cluster — data_allocate_cluster","text":"","code":"data_allocate_cluster(trained_model)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/data_allocate_cluster.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Allocate training data into the most probable cluster — data_allocate_cluster","text":"trained_model list, containing  information coming MagmaClust model, previously trained using train_magmaclust function.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/data_allocate_cluster.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Allocate training data into the most probable cluster — data_allocate_cluster","text":"original dataset used train MagmaClust model, additional 'Cluster' associated 'Proba' columns, indicating probable cluster individual/task end training procedure.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/data_allocate_cluster.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Allocate training data into the most probable cluster — data_allocate_cluster","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/dmnorm.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the Multivariate Gaussian likelihood — dmnorm","title":"Compute the Multivariate Gaussian likelihood — dmnorm","text":"Modification function dmvnorm() package mvtnorm, providing implementation Multivariate Gaussian likelihood. version uses inverse covariance function argument instead traditional covariance.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/dmnorm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the Multivariate Gaussian likelihood — dmnorm","text":"","code":"dmnorm(x, mu, inv_Sigma, log = FALSE)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/dmnorm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the Multivariate Gaussian likelihood — dmnorm","text":"x vector, containing values likelihood evaluated . mu vector matrix, specifying mean parameter. inv_Sigma matrix, specifying inverse covariance parameter. log logical value, indicating whether return log-likelihood.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/dmnorm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the Multivariate Gaussian likelihood — dmnorm","text":"number, corresponding Multivariate Gaussian log-likelihood.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/dmnorm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute the Multivariate Gaussian likelihood — dmnorm","text":"","code":"MagmaClustR:::dmnorm(c(1, 2), c(0, 0), cbind(c(1, 0), c(0, 1)), TRUE) #> [1] -4.337877"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/draw.html","id":null,"dir":"Reference","previous_headings":"","what":"Draw a number — draw","title":"Draw a number — draw","text":"Draw uniformly number within specified interval","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/draw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Draw a number — draw","text":"","code":"draw(int)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/draw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Draw a number — draw","text":"int interval values want draw uniformly .","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/draw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Draw a number — draw","text":"2-decimals-rounded random number","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/draw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Draw a number — draw","text":"","code":"MagmaClustR:::draw(c(1, 2)) #> [1] 1.96"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/e_step.html","id":null,"dir":"Reference","previous_headings":"","what":"E-Step of the EM algorithm — e_step","title":"E-Step of the EM algorithm — e_step","text":"Expectation step EM algorithm compute parameters hyper-posterior Gaussian distribution mean process Magma.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/e_step.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"E-Step of the EM algorithm — e_step","text":"","code":"e_step(db, m_0, kern_0, kern_i, hp_0, hp_i, pen_diag)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/e_step.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"E-Step of the EM algorithm — e_step","text":"db tibble data frame. Columns required: ID, Input, Output. Additional columns covariates can specified. m_0 vector, corresponding prior mean mean GP. kern_0 kernel function, associated mean GP. kern_i kernel function, associated individual GPs. hp_0 named vector, tibble data frame hyper-parameters associated kern_0. hp_i tibble data frame hyper-parameters associated kern_i. pen_diag number. jitter term, added diagonal prevent numerical issues inverting nearly singular matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/e_step.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"E-Step of the EM algorithm — e_step","text":"named list, containing elements mean, tibble containing Input associated Output hyper-posterior's mean parameter, cov, hyper-posterior's covariance matrix.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/e_step.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"E-Step of the EM algorithm — e_step","text":"","code":"db <- simu_db(N = 10) m_0 <- rep(0, 10) hp_0 <- hp() hp_i <- hp(\"SE\", list_ID = unique(db$ID)) MagmaClustR:::e_step(db, m_0, \"SE\", \"SE\", hp_0, hp_i, 0.001) #> $mean #> # A tibble: 10 × 2 #>    Input  Output #>    <dbl>   <dbl> #>  1  0.55   8.64  #>  2  4.75  -6.46  #>  3  5.35  -8.77  #>  4  5.45  -7.18  #>  5  7.05  -2.43  #>  6  7.45  -0.388 #>  7  8.4   -2.94  #>  8  8.5   -1.29  #>  9  8.7   -2.90  #> 10  9.8  -10.3   #>  #> $cov #>              0.55       4.75       5.35       5.45       7.05        7.45 #> 0.55  0.439516792 0.09998382 0.06209226 0.05657725 0.00133883 -0.00441681 #> 4.75  0.099983823 0.40184355 0.38884340 0.38473903 0.27201864  0.23571206 #> 5.35  0.062092263 0.38884340 0.39497047 0.39391518 0.31967750  0.28790182 #> 5.45  0.056577254 0.38473903 0.39391518 0.39360993 0.32672836  0.29604532 #> 7.05  0.001338830 0.27201864 0.31967750 0.32672836 0.38779528  0.38415630 #> 7.45 -0.004416810 0.23571206 0.28790182 0.29604532 0.38415630  0.38892073 #> 8.4  -0.009408266 0.14929321 0.20310487 0.21229296 0.34462793  0.36691689 #> 8.5  -0.009382975 0.14068946 0.19397069 0.20313947 0.33818567  0.36203000 #> 8.7  -0.009091953 0.12399210 0.17585525 0.18491811 0.32421546  0.35095036 #> 9.8  -0.004351772 0.04818623 0.08579303 0.09292211 0.22883435  0.26509822 #>               8.4          8.5          8.7          9.8 #> 0.55 -0.009408266 -0.009382975 -0.009091953 -0.004351772 #> 4.75  0.149293212  0.140689464  0.123992101  0.048186228 #> 5.35  0.203104868  0.193970689  0.175855249  0.085793030 #> 5.45  0.212292961  0.203139470  0.184918107  0.092922112 #> 7.05  0.344627926  0.338185674  0.324215462  0.228834345 #> 7.45  0.366916887  0.362030002  0.350950363  0.265098217 #> 8.4   0.391045811  0.390874270  0.389208454  0.344710606 #> 8.5   0.390874270  0.391453887  0.390848765  0.352117809 #> 8.7   0.389208454  0.390848765  0.392782509  0.366173636 #> 9.8   0.344710606  0.352117809  0.366173636  0.414163456 #>   db_async <- simu_db(N = 10, common_input = FALSE) m_0_async <- rep(0, db_async$Input %>% unique() %>% length()) MagmaClustR:::e_step(db_async, m_0_async, \"SE\", \"SE\", hp_0, hp_i, 0.001) #> $mean #> # A tibble: 81 × 2 #>    Input Output #>    <dbl>  <dbl> #>  1  0.1    9.53 #>  2  0.3    9.95 #>  3  0.45  10.7  #>  4  0.55  10.1  #>  5  0.6    8.79 #>  6  0.7   10.8  #>  7  0.75   9.73 #>  8  0.85   9.43 #>  9  1      8.98 #> 10  1.05   8.24 #> # … with 71 more rows #>  #> $cov #>               0.1          0.3          0.45          0.55          0.6 #> 0.1   0.437411102  0.431842823  0.4263840776  0.4214447563  0.419869534 #> 0.3   0.431842823  0.431539616  0.4276385725  0.4241612221  0.423522892 #> 0.45  0.426384078  0.427638573  0.4275501964  0.4243500644  0.424433364 #> 0.55  0.421444756  0.424161222  0.4243500644  0.4237458731  0.423291689 #> 0.6   0.419869534  0.423522892  0.4244333643  0.4232916888  0.424473638 #> 0.7   0.414426703  0.419645804  0.4215586077  0.4214495404  0.422497806 #> 0.75  0.411371435  0.417388279  0.4199830356  0.4202505171  0.421274046 #> 0.85  0.405438322  0.412841615  0.4164890719  0.4175425610  0.418865343 #> 1     0.394911661  0.404336919  0.4096042852  0.4120183583  0.413655617 #> 1.05  0.391282809  0.401439364  0.4072620009  0.4099581246  0.411865924 #> 1.3   0.371819092  0.384883704  0.3930240538  0.3975600280  0.400081359 #> 1.35  0.367384589  0.381029572  0.3896155815  0.3945297826  0.397160021 #> 1.4   0.363404626  0.377526762  0.3865185345  0.3917064523  0.394482855 #> 1.8   0.326964228  0.344383912  0.3561805257  0.3637720156  0.367228730 #> 1.85  0.322268312  0.340053607  0.3520678880  0.3599333915  0.363361233 #> 2     0.307403245  0.326027447  0.3388226558  0.3472932407  0.351042225 #> 2.05  0.302739084  0.321528358  0.3345127426  0.3431437701  0.346948344 #> 2.15  0.292961236  0.312198755  0.3256025068  0.3345850658  0.338523190 #> 2.35  0.273366768  0.293247378  0.3073022545  0.3168447190  0.321005249 #> 2.5   0.258472144  0.278634172  0.2930335005  0.3028722739  0.307174218 #> 2.6   0.248400674  0.268692575  0.2832812671  0.2932676425  0.297668756 #> 2.7   0.238461166  0.258776853  0.2734678952  0.2835548974  0.288014629 #> 2.9   0.219605627  0.239868088  0.2546929511  0.2648938981  0.269474754 #> 2.95  0.215392756  0.235472698  0.2502072815  0.2603339145  0.264922432 #> 3     0.210235723  0.230318805  0.2450974938  0.2552072002  0.259869251 #> 3.05  0.205493140  0.225454932  0.2401925237  0.2502941813  0.254958980 #> 3.2   0.191605059  0.211189621  0.2257660813  0.2357811066  0.240443368 #> 3.35  0.178010058  0.197129915  0.2114762850  0.2213527425  0.225994127 #> 3.5   0.164510192  0.183101752  0.1971689354  0.2068395767  0.211466148 #> 3.55  0.160472475  0.178819889  0.1927358045  0.2023383436  0.206913833 #> 3.65  0.152228109  0.170160977  0.1838347691  0.1932329651  0.197801134 #> 3.7   0.147652288  0.165387050  0.1789566716  0.1882983082  0.192855905 #> 3.8   0.139682141  0.156943734  0.1702195364  0.1793448889  0.183837960 #> 3.9   0.131657850  0.148413405  0.1613573033  0.1702640996  0.174689415 #> 4.05  0.120185883  0.136194315  0.1486554175  0.1572431313  0.161552302 #> 4.1   0.116763415  0.132394202  0.1445838722  0.1530060307  0.157233278 #> 4.15  0.112605863  0.128103085  0.1402274184  0.1485922925  0.152824450 #> 4.2   0.108901317  0.124134067  0.1360783233  0.1443330169  0.148510359 #> 4.4   0.094604328  0.108775631  0.1199968529  0.1277750479  0.131757562 #> 4.55  0.084523622  0.097872530  0.1085205922  0.1159258828  0.119740306 #> 4.6   0.081501178  0.094612021  0.1050876887  0.1123745597  0.116139497 #> 4.85  0.066019252  0.077781996  0.0872974741  0.0939516932  0.097429411 #> 4.9   0.063153496  0.074676507  0.0840177895  0.0905407415  0.093977263 #> 4.95  0.060189573  0.071500181  0.0806917760  0.0871193045  0.090501008 #> 5     0.057361331  0.068345774  0.0772994779  0.0835778236  0.086873795 #> 5.05  0.054768275  0.065497949  0.0742303819  0.0803780498  0.083613392 #> 5.3   0.042021775  0.051483367  0.0593084627  0.0648173070  0.067762828 #> 5.4   0.037252532  0.046240903  0.0537088730  0.0589773500  0.061803342 #> 5.6   0.028430489  0.036517047  0.0433159748  0.0481080729  0.050728020 #> 5.65  0.026753272  0.034528971  0.0410811319  0.0457118163  0.048239202 #> 5.75  0.022790971  0.030124786  0.0363524866  0.0407451562  0.043171103 #> 6.1   0.010932595  0.016744543  0.0217916433  0.0253664490  0.027397247 #> 6.15  0.009810752  0.015396878  0.0202548863  0.0236991026  0.025661730 #> 6.2   0.008258084  0.013642593  0.0183632705  0.0216985229  0.023612667 #> 6.4   0.003330229  0.007905646  0.0119783548  0.0148643270  0.016557733 #> 6.6  -0.000938314  0.002886134  0.0063534304  0.0088243958  0.010297331 #> 6.65 -0.001839766  0.001802567  0.0051237792  0.0074951888  0.008913033 #> 6.9  -0.005644203 -0.002907320 -0.0003276872  0.0015420291  0.002685968 #> 6.95 -0.006298613 -0.003722307 -0.0012767136  0.0005023776  0.001594595 #> 7.1  -0.007958020 -0.005830461 -0.0037564663 -0.0022316170 -0.001277521 #> 7.15 -0.008397513 -0.006418421 -0.0044698673 -0.0030299173 -0.002123853 #> 7.3  -0.009623172 -0.008064158 -0.0064727639 -0.0052692059 -0.004505035 #> 7.7  -0.011471453 -0.010810279 -0.0100008703 -0.0093200272 -0.008876468 #> 7.8  -0.011479714 -0.011040111 -0.0104413651 -0.0098921148 -0.009538165 #> 7.85 -0.011427533 -0.011099110 -0.0105895867 -0.0101037249 -0.009787880 #> 7.9  -0.011492029 -0.011238383 -0.0107971276 -0.0103562891 -0.010073725 #> 8    -0.011466422 -0.011364472 -0.0110640404 -0.0107167587 -0.010497383 #> 8.05 -0.011448027 -0.011406759 -0.0111632800 -0.0108544488 -0.010664385 #> 8.25 -0.010994571 -0.011225847 -0.0112340929 -0.0110973390 -0.011022035 #> 8.35 -0.010635676 -0.010984915 -0.0111011229 -0.0110403617 -0.011015200 #> 8.5  -0.010023071 -0.010505180 -0.0107473212 -0.0107846020 -0.010823854 #> 8.55 -0.009804111 -0.010345040 -0.0106462293 -0.0107147671 -0.010784361 #> 8.7  -0.009099046 -0.009733641 -0.0101220990 -0.0102625136 -0.010377870 #> 8.75 -0.008890265 -0.009537079 -0.0099437852 -0.0100926324 -0.010224138 #> 8.85 -0.008283326 -0.009000210 -0.0094713148 -0.0096734731 -0.009837887 #> 8.95 -0.007695091 -0.008457286 -0.0089746363 -0.0092119892 -0.009405699 #> 9.3  -0.005465109 -0.006358712 -0.0069966860 -0.0073388584 -0.007610051 #> 9.4  -0.004756156 -0.005679509 -0.0063444594 -0.0067118290 -0.007000557 #> 9.45 -0.004387410 -0.005321836 -0.0059967187 -0.0063747611 -0.006670899 #> 9.65 -0.003013774 -0.003988674 -0.0046993959 -0.0051132270 -0.005436686 #> 9.7  -0.002619516 -0.003604907 -0.0043245292 -0.0047487467 -0.005077627 #>                0.7          0.75          0.85            1         1.05 #> 0.1   0.4144267030  0.4113714354  0.4054383223  0.394911661  0.391282809 #> 0.3   0.4196458042  0.4173882791  0.4128416150  0.404336919  0.401439364 #> 0.45  0.4215586077  0.4199830356  0.4164890719  0.409604285  0.407262001 #> 0.55  0.4214495404  0.4202505171  0.4175425610  0.412018358  0.409958125 #> 0.6   0.4224978062  0.4212740455  0.4188653432  0.413655617  0.411865924 #> 0.7   0.4224804663  0.4209988340  0.4193321560  0.415281127  0.413866882 #> 0.75  0.4209988340  0.4216017510  0.4193325528  0.415900865  0.414681240 #> 0.85  0.4193321560  0.4193325528  0.4197523204  0.416467933  0.415603328 #> 1     0.4152811274  0.4159008649  0.4164679335  0.416657756  0.415696249 #> 1.05  0.4138668818  0.4146812400  0.4156033278  0.415696249  0.416564900 #> 1.3   0.4038072936  0.4055417290  0.4081980496  0.411255851  0.411847763 #> 1.35  0.4012304913  0.4031499769  0.4061546318  0.409655826  0.410549819 #> 1.4   0.3988524771  0.4009293629  0.4042426178  0.408362708  0.409292324 #> 1.8   0.3738470288  0.3771312063  0.3828367526  0.390814936  0.393057537 #> 1.85  0.3701634196  0.3735375837  0.3794508777  0.387754149  0.390102659 #> 2     0.3585440203  0.3623002620  0.3689907370  0.378604378  0.381359281 #> 2.05  0.3546220819  0.3584889372  0.3653672707  0.375324648  0.378190738 #> 2.15  0.3465695132  0.3506203784  0.3579369193  0.368593405  0.371690235 #> 2.35  0.3296732861  0.3340487019  0.3421062686  0.353980747  0.357492451 #> 2.5   0.3162073184  0.3207769892  0.3292910045  0.341917939  0.345696799 #> 2.6   0.3069133673  0.3115951170  0.3203785065  0.333444496  0.337392674 #> 2.7   0.2974126139  0.3021759698  0.3111734605  0.324598762  0.328685880 #> 2.9   0.2791102162  0.2839750589  0.2933377328  0.307326164  0.311656056 #> 2.95  0.2745354268  0.2794168590  0.2887674057  0.302778052  0.307139651 #> 3     0.2695360513  0.2744453555  0.2838644906  0.297959194  0.302400565 #> 3.05  0.2646447083  0.2695688986  0.2790358513  0.293247389  0.297712828 #> 3.2   0.2501303218  0.2550584327  0.2646138445  0.278990603  0.283556039 #> 3.35  0.2356309264  0.2405394467  0.2501225329  0.264568216  0.269214178 #> 3.5   0.2210164635  0.2258775784  0.2354325060  0.249870810  0.254544385 #> 3.55  0.2163942237  0.2212316498  0.2307566426  0.245174897  0.249856948 #> 3.65  0.2071672618  0.2119498225  0.2213955980  0.235706148  0.240390484 #> 3.7   0.2021983954  0.2069757056  0.2164234582  0.230778981  0.235472006 #> 3.8   0.1930178576  0.1977113641  0.2070345749  0.221179670  0.225850585 #> 3.9   0.1837058849  0.1883330753  0.1975187944  0.211520584  0.216163184 #> 4.05  0.1703163313  0.1748107039  0.1838041138  0.197538293  0.202126822 #> 4.1   0.1658427086  0.1702654769  0.1791129503  0.192669941  0.197194114 #> 4.15  0.1613944193  0.1658134407  0.1746553641  0.188200832  0.192736591 #> 4.2   0.1569992731  0.1613633823  0.1701244872  0.183568769  0.188073589 #> 4.4   0.1398402562  0.1440055889  0.1524138587  0.165381493  0.169755989 #> 4.55  0.1274900342  0.1314900057  0.1396037117  0.152172306  0.156418721 #> 4.6   0.1237820324  0.1277300047  0.1357398902  0.148152708  0.152365907 #> 4.85  0.1044938269  0.1081550315  0.1156310687  0.127298145  0.131282581 #> 4.9   0.1009295968  0.1045356651  0.1118997738  0.123398346  0.127342999 #> 4.95  0.0973590380  0.1009151089  0.1081987352  0.119575266  0.123475167 #> 5     0.0935813808  0.0970600735  0.1042093085  0.115383054  0.119219650 #> 5.05  0.0902000921  0.0936201645  0.1006263288  0.111672934  0.115454208 #> 5.3   0.0737416099  0.0768544222  0.0832912786  0.093434003  0.096940665 #> 5.4   0.0675585475  0.0705452449  0.0767512075  0.086551298  0.089948726 #> 5.6   0.0560169782  0.0587787998  0.0645375240  0.073652763  0.076835865 #> 5.65  0.0533566213  0.0560311876  0.0616163375  0.070472201  0.073569051 #> 5.75  0.0480600206  0.0506187876  0.0559814787  0.064478585  0.067463281 #> 6.1   0.0314654714  0.0336051367  0.0381297938  0.045368065  0.047934511 #> 6.15  0.0295905851  0.0316613506  0.0360349689  0.043052095  0.045540719 #> 6.2   0.0274329650  0.0294465840  0.0337235815  0.040548732  0.042983300 #> 6.4   0.0199010505  0.0216875360  0.0254794113  0.031583992  0.033770996 #> 6.6   0.0132152738  0.0147685351  0.0180997086  0.023499863  0.025445680 #> 6.65  0.0117235669  0.0132219968  0.0164410442  0.021670127  0.023554280 #> 6.9   0.0049572939  0.0061795406  0.0088257583  0.013192851  0.014772724 #> 6.95  0.0037710468  0.0049390596  0.0074784408  0.011681737  0.013204142 #> 7.1   0.0006141366  0.0016449213  0.0038860382  0.007639024  0.008998052 #> 7.15 -0.0003262853  0.0006565203  0.0027959599  0.006395891  0.007699995 #> 7.3  -0.0029750111 -0.0021289387 -0.0002791413  0.002885917  0.004029860 #> 7.7  -0.0079504159 -0.0074140190 -0.0062274591 -0.004073787 -0.003303119 #> 7.8  -0.0087713855 -0.0083171830 -0.0073141422 -0.005421262 -0.004746551 #> 7.85 -0.0090947786 -0.0086803021 -0.0077522310 -0.005991399 -0.005363015 #> 7.9  -0.0094407862 -0.0090516940 -0.0081890772 -0.006530214 -0.005939501 #> 8    -0.0099763957 -0.0096495142 -0.0089175177 -0.007465053 -0.006948819 #> 8.05 -0.0101951588 -0.0098930620 -0.0092188113 -0.007862000 -0.007379718 #> 8.25 -0.0107660956 -0.0105744492 -0.0101410897 -0.009174520 -0.008830216 #> 8.35 -0.0108548794 -0.0107119880 -0.0103861759 -0.009601051 -0.009318432 #> 8.5  -0.0107901121 -0.0107137865 -0.0105328375 -0.010012783 -0.009815097 #> 8.55 -0.0107958270 -0.0107419835 -0.0106127010 -0.010165225 -0.009995925 #> 8.7  -0.0104844349 -0.0104791320 -0.0104586424 -0.010219154 -0.010115907 #> 8.75 -0.0103507996 -0.0103558118 -0.0103599021 -0.010162759 -0.010076742 #> 8.85 -0.0100339971 -0.0100750042 -0.0101576779 -0.010112849 -0.010071811 #> 8.95 -0.0096549215 -0.0097235253 -0.0098673356 -0.009941693 -0.009938083 #> 9.3  -0.0080148644 -0.0081629884 -0.0084813976 -0.008926106 -0.009031019 #> 9.4  -0.0074429284 -0.0076125154 -0.0079718047 -0.008509791 -0.008640958 #> 9.45 -0.0071300330 -0.0073099840 -0.0076869802 -0.008269668 -0.008412783 #> 9.65 -0.0059535356 -0.0061667926 -0.0066058752 -0.007339417 -0.007524278 #> 9.7  -0.0056093293 -0.0058335922 -0.0062874081 -0.007061339 -0.007256563 #>               1.3          1.35           1.4           1.8          1.85 #> 0.1   0.371819092  0.3673845892  0.3634046264  3.269642e-01  0.3222683118 #> 0.3   0.384883704  0.3810295719  0.3775267618  3.443839e-01  0.3400536071 #> 0.45  0.393024054  0.3896155815  0.3865185345  3.561805e-01  0.3520678880 #> 0.55  0.397560028  0.3945297826  0.3917064523  3.637720e-01  0.3599333915 #> 0.6   0.400081359  0.3971600205  0.3944828550  3.672287e-01  0.3633612334 #> 0.7   0.403807294  0.4012304913  0.3988524771  3.738470e-01  0.3701634196 #> 0.75  0.405541729  0.4031499769  0.4009293629  3.771312e-01  0.3735375837 #> 0.85  0.408198050  0.4061546318  0.4042426178  3.828368e-01  0.3794508777 #> 1     0.411255851  0.4096558262  0.4083627077  3.908149e-01  0.3877541488 #> 1.05  0.411847763  0.4105498193  0.4092923238  3.930575e-01  0.3901026594 #> 1.3   0.413338781  0.4122805528  0.4120464540  4.023700e-01  0.4000326628 #> 1.35  0.412280553  0.4130795294  0.4118368435  4.037630e-01  0.4015300031 #> 1.4   0.412046454  0.4118368435  0.4124500972  4.049619e-01  0.4028917611 #> 1.8   0.402369953  0.4037630427  0.4049618681  4.101169e-01  0.4082636238 #> 1.85  0.400032663  0.4015300031  0.4028917611  4.082636e-01  0.4084098692 #> 2     0.393618679  0.3955856362  0.3974327200  4.068306e-01  0.4065228159 #> 2.05  0.391120908  0.3932416863  0.3952230392  4.058538e-01  0.4057548766 #> 2.15  0.385925984  0.3883215549  0.3905820851  4.035950e-01  0.4038087118 #> 2.35  0.374093868  0.3769923493  0.3797761194  3.973044e-01  0.3981419218 #> 2.5   0.363856608  0.3670903693  0.3702334267  3.908999e-01  0.3922057394 #> 2.6   0.356493868  0.3599336459  0.3632998782  3.859265e-01  0.3875487867 #> 2.7   0.348607737  0.3522293057  0.3557975825  3.802390e-01  0.3821440366 #> 2.9   0.332908147  0.3368386215  0.3407380141  3.682426e-01  0.3706459077 #> 2.95  0.328591516  0.3325700185  0.3365414656  3.647088e-01  0.3672632680 #> 3     0.324155732  0.3281624176  0.3322654295  3.610269e-01  0.3637019704 #> 3.05  0.319700365  0.3238103460  0.3279221809  3.574366e-01  0.3603132671 #> 3.2   0.306173800  0.3104416359  0.3147430779  3.461199e-01  0.3492863090 #> 3.35  0.292288610  0.2966875064  0.3011390222  3.340834e-01  0.3375266328 #> 3.5   0.277911799  0.2824001825  0.2869597740  3.211569e-01  0.3248631867 #> 3.55  0.273281766  0.2778169840  0.2823894623  3.170538e-01  0.3208453682 #> 3.65  0.263842698  0.2683846590  0.2730179181  3.081879e-01  0.3121183993 #> 3.7   0.259082190  0.2636662578  0.2683407984  3.039986e-01  0.3079611084 #> 3.8   0.249312907  0.2538938675  0.2585746171  2.945319e-01  0.2986352696 #> 3.9   0.239571076  0.2441629549  0.2488671111  2.852727e-01  0.2894988517 #> 4.05  0.225325334  0.2299109730  0.2346136916  2.714115e-01  0.2757425308 #> 4.1   0.220162216  0.2247165005  0.2293801972  2.660706e-01  0.2703949234 #> 4.15  0.215766175  0.2203401575  0.2250307325  2.620042e-01  0.2664036099 #> 4.2   0.211000420  0.2155668611  0.2202449828  2.572879e-01  0.2617131400 #> 4.4   0.192163830  0.1966663009  0.2012866221  2.383627e-01  0.2428725738 #> 4.55  0.178336306  0.1827750342  0.1873181889  2.242482e-01  0.2288001255 #> 4.6   0.174087457  0.1784840695  0.1830100035  2.197398e-01  0.2242751447 #> 4.85  0.152013229  0.1562509726  0.1606205993  1.966234e-01  0.2011439504 #> 4.9   0.147846106  0.1520306335  0.1563776001  1.920994e-01  0.1965946710 #> 4.95  0.143806651  0.1479742227  0.1522801831  1.879031e-01  0.1924201991 #> 5     0.139288386  0.1434084136  0.1476764531  1.830843e-01  0.1875605122 #> 5.05  0.135289432  0.1393702662  0.1435929724  1.787500e-01  0.1832335505 #> 5.3   0.115454523  0.1192982155  0.1232815225  1.568918e-01  0.1612544877 #> 5.4   0.107939647  0.1116848064  0.1155737586  1.485238e-01  0.1528272796 #> 5.6   0.093759863  0.0973041579  0.1009936064  1.325181e-01  0.1367039893 #> 5.65  0.090077556  0.0935435437  0.0971531066  1.281168e-01  0.1322405080 #> 5.75  0.083405885  0.0867626069  0.0902633492  1.204171e-01  0.1244620468 #> 6.1   0.061790923  0.0647423781  0.0678305274  9.488281e-02  0.0985986133 #> 6.15  0.059003707  0.0618787352  0.0648832899  9.130795e-02  0.0949653042 #> 6.2   0.056155134  0.0589709520  0.0619208918  8.789635e-02  0.0914917201 #> 6.4   0.045697693  0.0482658016  0.0509619782  7.495667e-02  0.0783239617 #> 6.6   0.036141379  0.0384624895  0.0409030377  6.286704e-02  0.0659851063 #> 6.65  0.033946735  0.0362070240  0.0385826450  6.003945e-02  0.0630894194 #> 6.9   0.023630584  0.0255812981  0.0276327756  4.650336e-02  0.0492150380 #> 6.95  0.021766277  0.0236565180  0.0256449791  4.400084e-02  0.0466451171 #> 7.1   0.016729764  0.0184493850  0.0202570653  3.712923e-02  0.0395707672 #> 7.15  0.015150216  0.0168118898  0.0185588879  3.493140e-02  0.0373056146 #> 7.3   0.010675676  0.0121704994  0.0137425171  2.866605e-02  0.0308344937 #> 7.7   0.001435276  0.0025251527  0.0036784866  1.501280e-02  0.0166609866 #> 7.8  -0.000509963  0.0004747555  0.0015195154  1.192736e-02  0.0134504130 #> 7.85 -0.001370092 -0.0004359689  0.0005536531  1.049800e-02  0.0119460557 #> 7.9  -0.002141829 -0.0012504466 -0.0003042981  9.250232e-03  0.0106425624 #> 8    -0.003551556 -0.0027469701 -0.0018900545  6.866107e-03  0.0081425908 #> 8.05 -0.004168695 -0.0034049070 -0.0025899783  5.783365e-03  0.0070046785 #> 8.25 -0.006375530 -0.0057758992 -0.0051299376  1.717748e-03  0.0027155625 #> 8.35 -0.007217680 -0.0066944199 -0.0061285972 -8.898214e-06  0.0008835914 #> 8.5  -0.008228907 -0.0078184188 -0.0073682887 -2.329388e-03 -0.0015839368 #> 8.55 -0.008554506 -0.0081753308 -0.0077576652 -3.010112e-03 -0.0023149950 #> 8.7  -0.009090242 -0.0088026692 -0.0084820364 -4.656308e-03 -0.0040925278 #> 8.75 -0.009145021 -0.0088802651 -0.0085825883 -4.993678e-03 -0.0044734371 #> 8.85 -0.009435816 -0.0092345363 -0.0090040624 -6.042355e-03 -0.0056057706 #> 8.95 -0.009542302 -0.0093942156 -0.0092198540 -6.798908e-03 -0.0064426336 #> 9.3  -0.009381331 -0.0093940903 -0.0093985559 -8.673357e-03 -0.0085651987 #> 9.4  -0.009181955 -0.0092352425 -0.0092860669 -8.998512e-03 -0.0089567484 #> 9.45 -0.009046303 -0.0091190818 -0.0091927264 -9.120817e-03 -0.0091120727 #> 9.65 -0.008471907 -0.0086108759 -0.0087629938 -9.429671e-03 -0.0095357969 #> 9.7  -0.008288817 -0.0084451751 -0.0086183437 -9.480723e-03 -0.0096182073 #>                  2         2.05          2.15          2.35          2.5 #> 0.1   0.3074032453  0.302739084  2.929612e-01  2.733668e-01  0.258472144 #> 0.3   0.3260274472  0.321528358  3.121988e-01  2.932474e-01  0.278634172 #> 0.45  0.3388226558  0.334512743  3.256025e-01  3.073023e-01  0.293033500 #> 0.55  0.3472932407  0.343143770  3.345851e-01  3.168447e-01  0.302872274 #> 0.6   0.3510422253  0.346948344  3.385232e-01  3.210052e-01  0.307174218 #> 0.7   0.3585440203  0.354622082  3.465695e-01  3.296733e-01  0.316207318 #> 0.75  0.3623002620  0.358488937  3.506204e-01  3.340487e-01  0.320776989 #> 0.85  0.3689907370  0.365367271  3.579369e-01  3.421063e-01  0.329291005 #> 1     0.3786043782  0.375324648  3.685934e-01  3.539807e-01  0.341917939 #> 1.05  0.3813592808  0.378190738  3.716902e-01  3.574925e-01  0.345696799 #> 1.3   0.3936186793  0.391120908  3.859260e-01  3.740939e-01  0.363856608 #> 1.35  0.3955856362  0.393241686  3.883216e-01  3.769923e-01  0.367090369 #> 1.4   0.3974327200  0.395223039  3.905821e-01  3.797761e-01  0.370233427 #> 1.8   0.4068306300  0.405853785  4.035950e-01  3.973044e-01  0.390899852 #> 1.85  0.4065228159  0.405754877  4.038087e-01  3.981419e-01  0.392205739 #> 2     0.4079806345  0.406721003  4.056943e-01  4.018075e-01  0.397140505 #> 2.05  0.4067210028  0.407357074  4.061367e-01  4.026755e-01  0.398483420 #> 2.15  0.4056943086  0.406136662  4.065314e-01  4.037818e-01  0.400480695 #> 2.35  0.4018074735  0.402675487  4.037818e-01  4.051406e-01  0.402662636 #> 2.5   0.3971405054  0.398483420  4.004807e-01  4.026626e-01  0.403369898 #> 2.6   0.3932793833  0.394927939  3.975070e-01  4.008821e-01  0.401933476 #> 2.7   0.3886514327  0.390595147  3.937335e-01  3.982672e-01  0.399999847 #> 2.9   0.3784968801  0.381000316  3.851864e-01  3.917362e-01  0.395157989 #> 2.95  0.3754204719  0.378010307  3.824165e-01  3.896186e-01  0.393499811 #> 3     0.3721589223  0.374863020  3.795124e-01  3.872288e-01  0.391533326 #> 3.05  0.3689968673  0.371817582  3.767044e-01  3.849256e-01  0.389631101 #> 3.2   0.3589164523  0.362094601  3.676828e-01  3.774096e-01  0.383322553 #> 3.35  0.3479684616  0.351458101  3.576821e-01  3.687911e-01  0.375888739 #> 3.5   0.3359788684  0.339734469  3.465310e-01  3.589412e-01  0.367077714 #> 3.55  0.3322015965  0.336055985  3.430404e-01  3.558297e-01  0.364349303 #> 3.65  0.3238159157  0.327808720  3.351107e-01  3.486159e-01  0.357760615 #> 3.7   0.3199390766  0.324015033  3.314894e-01  3.453764e-01  0.354829768 #> 3.8   0.3108566862  0.315049372  3.228027e-01  3.373303e-01  0.347401366 #> 3.9   0.3020331048  0.306326696  3.143665e-01  3.295903e-01  0.340222184 #> 4.05  0.2886591846  0.293126719  3.015077e-01  3.174987e-01  0.328909427 #> 4.1   0.2833714705  0.287848888  2.962993e-01  3.125058e-01  0.324079191 #> 4.15  0.2795232338  0.284068630  2.926495e-01  3.091459e-01  0.320959550 #> 4.2   0.2749302643  0.279512703  2.881850e-01  3.049060e-01  0.316926460 #> 4.4   0.2563819629  0.261083581  2.700640e-01  2.875690e-01  0.300329296 #> 4.55  0.2424481716  0.247215956  2.563692e-01  2.743469e-01  0.287573338 #> 4.6   0.2379189518  0.242681302  2.518503e-01  2.698982e-01  0.283209216 #> 4.85  0.2148205018  0.219609579  2.289119e-01  2.474201e-01  0.261246865 #> 4.9   0.2102314740  0.215003146  2.242993e-01  2.428305e-01  0.256708292 #> 4.95  0.2060405226  0.210826883  2.201391e-01  2.387348e-01  0.252680806 #> 5     0.2012082913  0.206003090  2.153346e-01  2.340238e-01  0.248064164 #> 5.05  0.1967998026  0.201573033  2.108841e-01  2.295540e-01  0.243619704 #> 5.3   0.1744679285  0.179136842  1.883123e-01  2.068787e-01  0.221012536 #> 5.4   0.1658713145  0.170487383  1.795792e-01  1.980370e-01  0.212137150 #> 5.6   0.1493309045  0.153825334  1.627056e-01  1.808447e-01  0.194798802 #> 5.65  0.1447119073  0.149151866  1.579461e-01  1.759514e-01  0.189840551 #> 5.75  0.1366799762  0.141038126  1.496895e-01  1.674569e-01  0.181205616 #> 6.1   0.1098035488  0.113830373  1.218735e-01  1.385651e-01  0.151636943 #> 6.15  0.1059366972  0.109882377  1.177906e-01  1.342345e-01  0.147137947 #> 6.2   0.1023288924  0.106230514  1.140477e-01  1.303270e-01  0.143123890 #> 6.4   0.0884684989  0.092136601  9.951215e-02  1.149665e-01  0.127198536 #> 6.6   0.0754026422  0.078817543  8.571468e-02  1.002543e-01  0.111843852 #> 6.65  0.0723246220  0.075673688  8.244512e-02  9.674143e-02  0.108155127 #> 6.9   0.0575111618  0.060522748  6.665637e-02  7.971314e-02  0.090234113 #> 6.95  0.0547487542  0.057691346  6.369313e-02  7.649003e-02  0.086820574 #> 7.1   0.0471066592  0.049845393  5.544755e-02  6.744643e-02  0.077182599 #> 7.15  0.0446509908  0.047320006  5.278892e-02  6.452106e-02  0.074058756 #> 7.3   0.0376277520  0.040092034  4.516498e-02  5.610183e-02  0.065037450 #> 7.7   0.0220364112  0.023967430  2.800663e-02  3.682776e-02  0.044123419 #> 7.8   0.0184589881  0.020254584  2.403649e-02  3.233222e-02  0.039224224 #> 7.85  0.0167761055  0.018513413  2.215506e-02  3.016845e-02  0.036847192 #> 7.9   0.0153097411  0.016971777  2.050037e-02  2.827154e-02  0.034751272 #> 8     0.0124793537  0.014016049  1.730275e-02  2.456844e-02  0.030647766 #> 8.05  0.0111794996  0.012647129  1.581966e-02  2.283981e-02  0.028720516 #> 8.25  0.0062553849  0.007485945  1.018942e-02  1.623140e-02  0.021334673 #> 8.35  0.0041141892  0.005226912  7.705429e-03  1.327241e-02  0.017999207 #> 8.5   0.0011795502  0.002118385  4.265277e-03  9.133592e-03  0.013304115 #> 8.55  0.0003300838  0.001219110  3.272415e-03  7.939359e-03  0.011945230 #> 8.7  -0.0018606565 -0.001128004  6.247123e-04  4.647906e-03  0.008133874 #> 8.75 -0.0023507108 -0.001664204 -2.036655e-06  3.820692e-03  0.007135720 #> 8.85 -0.0037573823 -0.003169898 -1.700348e-03  1.716153e-03  0.004712192 #> 8.95 -0.0048363130 -0.004339459 -3.049767e-03 -1.932584e-05  0.002664806 #> 9.3  -0.0077293772 -0.007515352 -6.792938e-03 -4.981504e-03 -0.003272725 #> 9.4  -0.0083189390 -0.008166723 -7.596269e-03 -6.107596e-03 -0.004651049 #> 9.45 -0.0085721827 -0.008448116 -7.953314e-03 -6.625560e-03 -0.005293073 #> 9.65 -0.0093353270 -0.009316606 -9.085848e-03 -8.322205e-03 -0.007430308 #> 9.7  -0.0095046432 -0.009502378 -9.343132e-03 -8.727732e-03 -0.007945767 #>               2.6           2.7           2.9          2.95            3 #> 0.1   0.248400674  0.2384611657  2.196056e-01  0.2153927558  0.210235723 #> 0.3   0.268692575  0.2587768531  2.398681e-01  0.2354726979  0.230318805 #> 0.45  0.283281267  0.2734678952  2.546930e-01  0.2502072815  0.245097494 #> 0.55  0.293267643  0.2835548974  2.648939e-01  0.2603339145  0.255207200 #> 0.6   0.297668756  0.2880146293  2.694748e-01  0.2649224320  0.259869251 #> 0.7   0.306913367  0.2974126139  2.791102e-01  0.2745354268  0.269536051 #> 0.75  0.311595117  0.3021759698  2.839751e-01  0.2794168590  0.274445355 #> 0.85  0.320378506  0.3111734605  2.933377e-01  0.2887674057  0.283864491 #> 1     0.333444496  0.3245987624  3.073262e-01  0.3027780521  0.297959194 #> 1.05  0.337392674  0.3286858798  3.116561e-01  0.3071396506  0.302400565 #> 1.3   0.356493868  0.3486077366  3.329081e-01  0.3285915160  0.324155732 #> 1.35  0.359933646  0.3522293057  3.368386e-01  0.3325700185  0.328162418 #> 1.4   0.363299878  0.3557975825  3.407380e-01  0.3365414656  0.332265429 #> 1.8   0.385926466  0.3802390331  3.682426e-01  0.3647088231  0.361026887 #> 1.85  0.387548787  0.3821440366  3.706459e-01  0.3672632680  0.363701970 #> 2     0.393279383  0.3886514327  3.784969e-01  0.3754204719  0.372158922 #> 2.05  0.394927939  0.3905951468  3.810003e-01  0.3780103070  0.374863020 #> 2.15  0.397506975  0.3937335053  3.851864e-01  0.3824165419  0.379512355 #> 2.35  0.400882084  0.3982672477  3.917362e-01  0.3896185532  0.387228844 #> 2.5   0.401933476  0.3999998473  3.951580e-01  0.3934998112  0.391533326 #> 2.6   0.402173957  0.4003827878  3.967107e-01  0.3953724067  0.393706588 #> 2.7   0.400382788  0.4008060209  3.973879e-01  0.3964901350  0.394996411 #> 2.9   0.396710719  0.3973879447  3.980213e-01  0.3968153831  0.396072695 #> 2.95  0.395372407  0.3964901350  3.968154e-01  0.3974403188  0.396028532 #> 3     0.393706588  0.3949964108  3.960727e-01  0.3960285320  0.396351901 #> 3.05  0.392147876  0.3936669823  3.953312e-01  0.3954385709  0.395189712 #> 3.2   0.386702103  0.3891262349  3.925512e-01  0.3931495187  0.393371683 #> 3.35  0.380019863  0.3833068134  3.884592e-01  0.3895254556  0.390374592 #> 3.5   0.371980459  0.3760631132  3.829263e-01  0.3844489277  0.385612979 #> 3.55  0.369494533  0.3738370659  3.812067e-01  0.3828708377  0.384278369 #> 3.65  0.363361491  0.3682178129  3.766711e-01  0.3786235230  0.380227774 #> 3.7   0.360662602  0.3657062780  3.746136e-01  0.3766741273  0.378390762 #> 3.8   0.353663958  0.3591918114  3.691735e-01  0.3715270937  0.373554969 #> 3.9   0.346910207  0.3528877576  3.639182e-01  0.3664540655  0.368747643 #> 4.05  0.336112589  0.3427067860  3.549962e-01  0.3579613526  0.360631114 #> 4.1   0.331484024  0.3382279555  3.509783e-01  0.3540324691  0.356833713 #> 4.15  0.328525238  0.3354814005  3.486095e-01  0.3517859426  0.354693586 #> 4.2   0.324649780  0.3317270848  3.453010e-01  0.3486684145  0.351589278 #> 4.4   0.308621768  0.3163908242  3.313769e-01  0.3350476169  0.338454433 #> 4.55  0.296205301  0.3044379570  3.203417e-01  0.3242272624  0.327915998 #> 4.6   0.291906685  0.3002396390  3.163963e-01  0.3203591211  0.324130032 #> 4.85  0.270359303  0.2792322177  2.966241e-01  0.3009138060  0.305048002 #> 4.9   0.265872296  0.2748212694  2.924117e-01  0.2967413302  0.300947443 #> 4.95  0.261889410  0.2709324789  2.886608e-01  0.2930563042  0.297295798 #> 5     0.257354560  0.2664971379  2.844440e-01  0.2889070891  0.293210625 #> 5.05  0.252933916  0.2621272969  2.802084e-01  0.2846939545  0.289038228 #> 5.3   0.230437788  0.2398990005  2.585477e-01  0.2631598550  0.267756599 #> 5.4   0.221558426  0.2310335473  2.498421e-01  0.2545437663  0.259143727 #> 5.6   0.204162851  0.2136643143  2.325959e-01  0.2373735032  0.242042000 #> 5.65  0.199178937  0.2086749234  2.276405e-01  0.2324242435  0.237112932 #> 5.75  0.190470410  0.1999258725  2.188604e-01  0.2236455457  0.228343479 #> 6.1   0.160514216  0.1696752832  1.881747e-01  0.1929037661  0.197548777 #> 6.15  0.155912624  0.1649950012  1.833746e-01  0.1880586408  0.192683966 #> 6.2   0.151837625  0.1608625144  1.791433e-01  0.1838233980  0.188430822 #> 6.4   0.135566239  0.1442770671  1.620163e-01  0.1665849266  0.171082747 #> 6.6   0.119810304  0.1281207224  1.452059e-01  0.1496435000  0.153976166 #> 6.65  0.116009101  0.1242319839  1.411003e-01  0.1454628150  0.149774036 #> 6.9   0.097522554  0.1051833240  1.210489e-01  0.1251572944  0.129244052 #> 6.95  0.093986203  0.1015253317  1.171648e-01  0.1212151221  0.125250645 #> 7.1   0.083960268  0.0911077228  1.060065e-01  0.1098758131  0.113738157 #> 7.15  0.080705222  0.0877226285  1.023726e-01  0.1061733297  0.109978183 #> 7.3   0.071288284  0.0779058318  9.178583e-02  0.0953770812  0.099000990 #> 7.7   0.049272837  0.0547795530  6.643941e-02  0.0693910227  0.072485583 #> 7.8   0.044103777  0.0493344295  6.045884e-02  0.0632535554  0.066223820 #> 7.85  0.041585133  0.0466698100  5.747571e-02  0.0602213203  0.063128071 #> 7.9   0.039352564  0.0442979789  5.485912e-02  0.0574826051  0.060318477 #> 8     0.034975751  0.0396422080  4.963695e-02  0.0520923379  0.054792329 #> 8.05  0.032912436  0.0374392590  4.717366e-02  0.0495221936  0.052153679 #> 8.25  0.024996522  0.0289745744  3.758760e-02  0.0396252743  0.041991796 #> 8.35  0.021403593  0.0251092625  3.318813e-02  0.0350712739  0.037307489 #> 8.5   0.016327934  0.0196371460  2.692961e-02  0.0285886446  0.030632586 #> 8.55  0.014854572  0.0180416189  2.508662e-02  0.0266624740  0.028647273 #> 8.7   0.010684814  0.0135065251  1.977322e-02  0.0211094115  0.022930417 #> 8.75  0.009563429  0.0122414105  1.825256e-02  0.0195256846  0.021254080 #> 8.85  0.006923454  0.0093609783  1.492356e-02  0.0160896882  0.017703207 #> 8.95  0.004659170  0.0068468809  1.196001e-02  0.0130276713  0.014502862 #> 9.3  -0.001952275 -0.0005149568  3.143318e-03  0.0038649867  0.004977823 #> 9.4  -0.003504719 -0.0022681788  9.889552e-04  0.0016620146  0.002675411 #> 9.45 -0.004232084 -0.0030944770 -3.883751e-05  0.0006175998  0.001583078 #> 9.65 -0.006675709 -0.0059011551 -3.551193e-03 -0.0029664990 -0.002188164 #> 9.7  -0.007266021 -0.0065794582 -4.429259e-03 -0.0038331037 -0.003095794 #>              3.05           3.2        3.35         3.5        3.55        3.65 #> 0.1   0.205493140  0.1916050588 0.178010058 0.164510192 0.160472475 0.152228109 #> 0.3   0.225454932  0.2111896205 0.197129915 0.183101752 0.178819889 0.170160977 #> 0.45  0.240192524  0.2257660813 0.211476285 0.197168935 0.192735804 0.183834769 #> 0.55  0.250294181  0.2357811066 0.221352743 0.206839577 0.202338344 0.193232965 #> 0.6   0.254958980  0.2404433677 0.225994127 0.211466148 0.206913833 0.197801134 #> 0.7   0.264644708  0.2501303218 0.235630926 0.221016463 0.216394224 0.207167262 #> 0.75  0.269568899  0.2550584327 0.240539447 0.225877578 0.221231650 0.211949822 #> 0.85  0.279035851  0.2646138445 0.250122533 0.235432506 0.230756643 0.221395598 #> 1     0.293247389  0.2789906033 0.264568216 0.249870810 0.245174897 0.235706148 #> 1.05  0.297712828  0.2835560394 0.269214178 0.254544385 0.249856948 0.240390484 #> 1.3   0.319700365  0.3061737995 0.292288610 0.277911799 0.273281766 0.263842698 #> 1.35  0.323810346  0.3104416359 0.296687506 0.282400183 0.277816984 0.268384659 #> 1.4   0.327922181  0.3147430779 0.301139022 0.286959774 0.282389462 0.273017918 #> 1.8   0.357436571  0.3461199233 0.334083372 0.321156879 0.317053814 0.308187869 #> 1.85  0.360313267  0.3492863090 0.337526633 0.324863187 0.320845368 0.312118399 #> 2     0.368996867  0.3589164523 0.347968462 0.335978868 0.332201597 0.323815916 #> 2.05  0.371817582  0.3620946011 0.351458101 0.339734469 0.336055985 0.327808720 #> 2.15  0.376704389  0.3676827574 0.357682130 0.346530962 0.343040389 0.335110725 #> 2.35  0.384925628  0.3774096068 0.368791072 0.358941238 0.355829683 0.348615867 #> 2.5   0.389631101  0.3833225532 0.375888739 0.367077714 0.364349303 0.357760615 #> 2.6   0.392147876  0.3867021032 0.380019863 0.371980459 0.369494533 0.363361491 #> 2.7   0.393666982  0.3891262349 0.383306813 0.376063113 0.373837066 0.368217813 #> 2.9   0.395331196  0.3925511678 0.388459197 0.382926275 0.381206663 0.376671118 #> 2.95  0.395438571  0.3931495187 0.389525456 0.384448928 0.382870838 0.378623523 #> 3     0.395189712  0.3933716827 0.390374592 0.385612979 0.384278369 0.380227774 #> 3.05  0.395487410  0.3937076016 0.390840470 0.386687661 0.385385633 0.381779303 #> 3.2   0.393707602  0.3942570958 0.392219277 0.389426128 0.388543434 0.385871387 #> 3.35  0.390840470  0.3922192766 0.392924082 0.390854244 0.390560306 0.388528833 #> 3.5   0.386687661  0.3894261285 0.390854244 0.391676495 0.390852080 0.389951416 #> 3.55  0.385385633  0.3885434337 0.390560306 0.390852080 0.391650358 0.390326885 #> 3.65  0.381779303  0.3858713871 0.388528833 0.389951416 0.390326885 0.391075203 #> 3.7   0.380180260  0.3844735693 0.387577459 0.389363997 0.389901580 0.390181534 #> 3.8   0.375482594  0.3807663174 0.384840135 0.387785966 0.388426189 0.389398397 #> 3.9   0.370950370  0.3770382655 0.381953872 0.385611297 0.386693559 0.388225546 #> 4.05  0.363186772  0.3704324551 0.376567334 0.381553612 0.382990566 0.385554836 #> 4.1   0.359571184  0.3671880442 0.373768212 0.379203751 0.380845265 0.383611918 #> 4.15  0.357527934  0.3654641083 0.372366176 0.378140896 0.379875179 0.382863791 #> 4.2   0.354550002  0.3628234813 0.370103675 0.376259906 0.378143551 0.381382486 #> 4.4   0.341854213  0.3514105193 0.360103218 0.367766166 0.370140692 0.374398485 #> 4.55  0.331618591  0.3420650218 0.351735874 0.360400704 0.363183474 0.368143830 #> 4.6   0.327879050  0.3385690440 0.348486294 0.357489766 0.360309509 0.365573504 #> 4.85  0.309197413  0.3210974814 0.332379526 0.342880136 0.346212982 0.352553742 #> 4.9   0.305163868  0.3172638693 0.328754116 0.339560556 0.342939100 0.349522879 #> 4.95  0.301550777  0.3138285667 0.325534258 0.336501728 0.340004862 0.346687450 #> 5     0.297534412  0.3100479333 0.322008498 0.333180684 0.336855298 0.343750388 #> 5.05  0.293417692  0.3060871791 0.318244051 0.329716310 0.333401052 0.340448996 #> 5.3   0.272363324  0.2857897336 0.298861109 0.311376788 0.315449920 0.323280516 #> 5.4   0.263809713  0.2774492532 0.290786750 0.303615319 0.307818990 0.315913080 #> 5.6   0.246787565  0.2607462993 0.274505877 0.287869120 0.292260497 0.300779727 #> 5.65  0.241870889  0.2559399668 0.269843836 0.283395827 0.287840308 0.296493398 #> 5.75  0.233127861  0.2472721143 0.261308649 0.275027044 0.279571093 0.288394609 #> 6.1   0.202311601  0.2164870357 0.230735565 0.244854216 0.249566196 0.258787662 #> 6.15  0.197419964  0.2115714239 0.225831642 0.239995014 0.244728857 0.254004256 #> 6.2   0.193156886  0.2072768378 0.221523929 0.235691625 0.240440264 0.249739545 #> 6.4   0.175714027  0.1896069470 0.203719404 0.217861891 0.222608977 0.231957971 #> 6.6   0.158478235  0.1720205605 0.185871767 0.199843791 0.204559212 0.213875232 #> 6.65  0.154242256  0.1676701313 0.181432190 0.195334666 0.200038515 0.209323510 #> 6.9   0.133508051  0.1463379313 0.159607621 0.173122961 0.177723260 0.186838137 #> 6.95  0.129465176  0.1421527070 0.155298238 0.168705169 0.173278653 0.182339922 #> 7.1   0.117794650  0.1299903020 0.142695609 0.155725922 0.160173046 0.169023946 #> 7.15  0.113978176  0.1260076205 0.138562028 0.151448156 0.155864600 0.164643009 #> 7.3   0.102827948  0.1143292711 0.126398833 0.138855001 0.143128600 0.151651183 #> 7.7   0.075783272  0.0856730249 0.096203881 0.107204707 0.111025857 0.118659247 #> 7.8   0.069367470  0.0788747104 0.089029243 0.099663681 0.103368284 0.110781994 #> 7.85  0.066208411  0.0755020270 0.085456598 0.095902268 0.099545398 0.106845636 #> 7.9   0.063319588  0.0724002946 0.082141278 0.092377250 0.095952050 0.103118433 #> 8     0.057641958  0.0662897117 0.075599454 0.085406566 0.088848319 0.095746688 #> 8.05  0.054921265  0.0633521987 0.072444234 0.082035030 0.085404728 0.092165300 #> 8.25  0.044453263  0.0520247597 0.060255136 0.068993867 0.072075804 0.078292592 #> 8.35  0.039614573  0.0467622585 0.054565023 0.062873509 0.065812078 0.071759568 #> 8.5   0.032699395  0.0392301332 0.046402158 0.054075958 0.056797978 0.062342332 #> 8.55  0.030639773  0.0369654722 0.043925645 0.051381478 0.054029867 0.059432577 #> 8.7   0.024694711  0.0303953767 0.036714562 0.043519356 0.045939040 0.050919095 #> 8.75  0.022938717  0.0284086223 0.034487012 0.041046526 0.043380720 0.048198999 #> 8.85  0.019241287  0.0243500338 0.030055442 0.036235753 0.038430615 0.043008152 #> 8.95  0.015894774  0.0206222477 0.025929485 0.031704278 0.033751245 0.038067345 #> 9.3   0.005907873  0.0094244688 0.013470673 0.017947832 0.019512625 0.022989676 #> 9.4   0.003486215  0.0066849759 0.010400126 0.014537007 0.015970776 0.019227823 #> 9.45  0.002334823  0.0053777251 0.008930561 0.012900882 0.014268897 0.017418511 #> 9.65 -0.001648178  0.0008227809 0.003777230 0.007127147 0.008256040 0.011003450 #> 9.7  -0.002606268 -0.0002741283 0.002536639 0.005740439 0.006808316 0.009460876 #>             3.7        3.8        3.9       4.05        4.1       4.15 #> 0.1  0.14765229 0.13968214 0.13165785 0.12018588 0.11676342 0.11260586 #> 0.3  0.16538705 0.15694373 0.14841341 0.13619431 0.13239420 0.12810308 #> 0.45 0.17895667 0.17021954 0.16135730 0.14865542 0.14458387 0.14022742 #> 0.55 0.18829831 0.17934489 0.17026410 0.15724313 0.15300603 0.14859229 #> 0.6  0.19285590 0.18383796 0.17468941 0.16155230 0.15723328 0.15282445 #> 0.7  0.20219840 0.19301786 0.18370588 0.17031633 0.16584271 0.16139442 #> 0.75 0.20697571 0.19771136 0.18833308 0.17481070 0.17026548 0.16581344 #> 0.85 0.21642346 0.20703457 0.19751879 0.18380411 0.17911295 0.17465536 #> 1    0.23077898 0.22117967 0.21152058 0.19753829 0.19266994 0.18820083 #> 1.05 0.23547201 0.22585058 0.21616318 0.20212682 0.19719411 0.19273659 #> 1.3  0.25908219 0.24931291 0.23957108 0.22532533 0.22016222 0.21576618 #> 1.35 0.26366626 0.25389387 0.24416295 0.22991097 0.22471650 0.22034016 #> 1.4  0.26834080 0.25857462 0.24886711 0.23461369 0.22938020 0.22503073 #> 1.8  0.30399862 0.29453191 0.28527270 0.27141147 0.26607061 0.26200425 #> 1.85 0.30796111 0.29863527 0.28949885 0.27574253 0.27039492 0.26640361 #> 2    0.31993908 0.31085669 0.30203310 0.28865918 0.28337147 0.27952323 #> 2.05 0.32401503 0.31504937 0.30632670 0.29312672 0.28784889 0.28406863 #> 2.15 0.33148936 0.32280275 0.31436653 0.30150774 0.29629926 0.29264950 #> 2.35 0.34537642 0.33733032 0.32959026 0.31749873 0.31250576 0.30914591 #> 2.5  0.35482977 0.34740137 0.34022218 0.32890943 0.32407919 0.32095955 #> 2.6  0.36066260 0.35366396 0.34691021 0.33611259 0.33148402 0.32852524 #> 2.7  0.36570628 0.35919181 0.35288776 0.34270679 0.33822796 0.33548140 #> 2.9  0.37461360 0.36917353 0.36391820 0.35499615 0.35097826 0.34860949 #> 2.95 0.37667413 0.37152709 0.36645407 0.35796135 0.35403247 0.35178594 #> 3    0.37839076 0.37355497 0.36874764 0.36063111 0.35683371 0.35469359 #> 3.05 0.38018026 0.37548259 0.37095037 0.36318677 0.35957118 0.35752793 #> 3.2  0.38447357 0.38076632 0.37703827 0.37043246 0.36718804 0.36546411 #> 3.35 0.38757746 0.38484014 0.38195387 0.37656733 0.37376821 0.37236618 #> 3.5  0.38936400 0.38778597 0.38561130 0.38155361 0.37920375 0.37814090 #> 3.55 0.38990158 0.38842619 0.38669356 0.38299057 0.38084527 0.37987518 #> 3.65 0.39018153 0.38939840 0.38822555 0.38555484 0.38361192 0.38286379 #> 3.7  0.39088248 0.38959389 0.38871618 0.38629886 0.38468668 0.38401655 #> 3.8  0.38959389 0.39041907 0.38949572 0.38812630 0.38674813 0.38632085 #> 3.9  0.38871618 0.38949572 0.39077318 0.38916889 0.38826423 0.38805544 #> 4.05 0.38629886 0.38812630 0.38916889 0.39044148 0.38950423 0.38960050 #> 4.1  0.38468668 0.38674813 0.38826423 0.38950423 0.39020077 0.38963844 #> 4.15 0.38401655 0.38632085 0.38805544 0.38960050 0.38963844 0.39092239 #> 4.2  0.38267656 0.38527019 0.38727915 0.38926314 0.38947566 0.38987334 #> 4.4  0.37622990 0.37993676 0.38300751 0.38668788 0.38758289 0.38837668 #> 4.55 0.37030113 0.37477143 0.37861353 0.38344863 0.38488559 0.38597399 #> 4.6  0.36784158 0.37255126 0.37663734 0.38186068 0.38365237 0.38466133 #> 4.85 0.35536683 0.36123772 0.36648127 0.37354490 0.37595704 0.37759737 #> 4.9  0.35243592 0.35852955 0.36398616 0.37140364 0.37396990 0.37569552 #> 4.95 0.34967306 0.35592337 0.36156348 0.36924896 0.37199525 0.37372592 #> 5    0.34692766 0.35328336 0.35914054 0.36724913 0.36995079 0.37187952 #> 5.05 0.34364551 0.35031953 0.35634432 0.36471846 0.36765568 0.36965351 #> 5.3  0.32689767 0.33443002 0.34141600 0.35128712 0.35483271 0.35727666 #> 5.4  0.31966825 0.32749171 0.33479396 0.34519182 0.34894029 0.35156189 #> 5.6  0.30474162 0.31308363 0.32092942 0.33221025 0.33624687 0.33919797 #> 5.65 0.30056001 0.30903942 0.31706640 0.32863048 0.33281555 0.33584574 #> 5.75 0.29253815 0.30122156 0.30949222 0.32146582 0.32576790 0.32894955 #> 6.1  0.26315386 0.27240377 0.28127540 0.29433324 0.29891409 0.30262841 #> 6.15 0.25837648 0.26774241 0.27670540 0.28995011 0.29465714 0.29838438 #> 6.2  0.25416189 0.26351592 0.27254927 0.28588558 0.29058626 0.29439195 #> 6.4  0.23642548 0.24592025 0.25511652 0.26881026 0.27357291 0.27758191 #> 6.6  0.21834945 0.22787711 0.23715786 0.25106765 0.25585291 0.26007012 #> 6.65 0.21379676 0.22331901 0.23259635 0.24654334 0.25133097 0.25558064 #> 6.9  0.19127149 0.20068784 0.20993157 0.22395038 0.22868920 0.23310938 #> 6.95 0.18675581 0.19613046 0.20534708 0.21934965 0.22407238 0.22852035 #> 7.1  0.17335349 0.18256152 0.19163739 0.20549480 0.21013237 0.21460362 #> 7.15 0.16894048 0.17809214 0.18710858 0.20092636 0.20552434 0.21000144 #> 7.3  0.15586837 0.16477963 0.17361356 0.18721609 0.19172579 0.19620458 #> 7.7  0.12255537 0.13059193 0.13868136 0.15137280 0.15551312 0.15983860 #> 7.8  0.11458933 0.12241341 0.13028835 0.14273834 0.14676266 0.15103947 #> 7.85 0.11061098 0.11831181 0.12611383 0.13840827 0.14239921 0.14663635 #> 7.9  0.10683256 0.11439460 0.12205034 0.13421274 0.13813618 0.14233054 #> 8    0.09935145 0.10663567 0.11404090 0.12587084 0.12967001 0.13379140 #> 8.05 0.09571434 0.10285334 0.11011236 0.12178855 0.12551734 0.12959019 #> 8.25 0.08161597 0.08817906 0.09492959 0.10588240 0.10935529 0.11322922 #> 8.35 0.07495548 0.08123485 0.08771544 0.09829929 0.10162776 0.10539614 #> 8.5  0.06534985 0.07120371 0.07728254 0.08731015 0.09044092 0.09403269 #> 8.55 0.06238639 0.06808037 0.07400535 0.08383194 0.08687518 0.09041357 #> 8.7  0.05366335 0.05891071 0.06440479 0.07360919 0.07642746 0.07977201 #> 8.75 0.05087785 0.05594262 0.06126949 0.07023865 0.07298185 0.07624836 #> 8.85 0.04555618 0.05036310 0.05543755 0.06402846 0.06663126 0.06977759 #> 8.95 0.04048428 0.04500327 0.04980311 0.05798110 0.06044410 0.06345507 #> 9.3  0.02494239 0.02855762 0.03245302 0.03923446 0.04120512 0.04375599 #> 9.4  0.02105372 0.02442994 0.02809842 0.03447749 0.03632235 0.03873718 #> 9.45 0.01918059 0.02243946 0.02599810 0.03217358 0.03395690 0.03630221 #> 9.65 0.01252415 0.01534947 0.01848112 0.02389878 0.02544570 0.02752779 #> 9.7  0.01092350 0.01364360 0.01668936 0.02190360 0.02340026 0.02541231 #>             4.2        4.4       4.55        4.6       4.85        4.9 #> 0.1  0.10890132 0.09460433 0.08452362 0.08150118 0.06601925 0.06315350 #> 0.3  0.12413407 0.10877563 0.09787253 0.09461202 0.07778200 0.07467651 #> 0.45 0.13607832 0.11999685 0.10852059 0.10508769 0.08729747 0.08401779 #> 0.55 0.14433302 0.12777505 0.11592588 0.11237456 0.09395169 0.09054074 #> 0.6  0.14851036 0.13175756 0.11974031 0.11613950 0.09742941 0.09397726 #> 0.7  0.15699927 0.13984026 0.12749003 0.12378203 0.10449383 0.10092960 #> 0.75 0.16136338 0.14400559 0.13149001 0.12773000 0.10815503 0.10453567 #> 0.85 0.17012449 0.15241386 0.13960371 0.13573989 0.11563107 0.11189977 #> 1    0.18356877 0.16538149 0.15217231 0.14815271 0.12729814 0.12339835 #> 1.05 0.18807359 0.16975599 0.15641872 0.15236591 0.13128258 0.12734300 #> 1.3  0.21100042 0.19216383 0.17833631 0.17408746 0.15201323 0.14784611 #> 1.35 0.21556686 0.19666630 0.18277503 0.17848407 0.15625097 0.15203063 #> 1.4  0.22024498 0.20128662 0.18731819 0.18301000 0.16062060 0.15637760 #> 1.8  0.25728787 0.23836269 0.22424823 0.21973979 0.19662343 0.19209939 #> 1.85 0.26171314 0.24287257 0.22880013 0.22427514 0.20114395 0.19659467 #> 2    0.27493026 0.25638196 0.24244817 0.23791895 0.21482050 0.21023147 #> 2.05 0.27951270 0.26108358 0.24721596 0.24268130 0.21960958 0.21500315 #> 2.15 0.28818504 0.27006398 0.25636920 0.25185026 0.22891185 0.22429933 #> 2.35 0.30490599 0.28756898 0.27434691 0.26989823 0.24742009 0.24283053 #> 2.5  0.31692646 0.30032930 0.28757334 0.28320922 0.26124687 0.25670829 #> 2.6  0.32464978 0.30862177 0.29620530 0.29190669 0.27035930 0.26587230 #> 2.7  0.33172708 0.31639082 0.30443796 0.30023964 0.27923222 0.27482127 #> 2.9  0.34530096 0.33137692 0.32034166 0.31639635 0.29662411 0.29241173 #> 2.95 0.34866841 0.33504762 0.32422726 0.32035912 0.30091381 0.29674133 #> 3    0.35158928 0.33845443 0.32791600 0.32413003 0.30504800 0.30094744 #> 3.05 0.35455000 0.34185421 0.33161859 0.32787905 0.30919741 0.30516387 #> 3.2  0.36282348 0.35141052 0.34206502 0.33856904 0.32109748 0.31726387 #> 3.35 0.37010367 0.36010322 0.35173587 0.34848629 0.33237953 0.32875412 #> 3.5  0.37625991 0.36776617 0.36040070 0.35748977 0.34288014 0.33956056 #> 3.55 0.37814355 0.37014069 0.36318347 0.36030951 0.34621298 0.34293910 #> 3.65 0.38138249 0.37439849 0.36814383 0.36557350 0.35255374 0.34952288 #> 3.7  0.38267656 0.37622990 0.37030113 0.36784158 0.35536683 0.35243592 #> 3.8  0.38527019 0.37993676 0.37477143 0.37255126 0.36123772 0.35852955 #> 3.9  0.38727915 0.38300751 0.37861353 0.37663734 0.36648127 0.36398616 #> 4.05 0.38926314 0.38668788 0.38344863 0.38186068 0.37354490 0.37140364 #> 4.1  0.38947566 0.38758289 0.38488559 0.38365237 0.37595704 0.37396990 #> 4.15 0.38987334 0.38837668 0.38597399 0.38466133 0.37759737 0.37569552 #> 4.2  0.39066019 0.38916959 0.38711989 0.38583902 0.37941395 0.37765950 #> 4.4  0.38916959 0.39090525 0.39001056 0.38927115 0.38541767 0.38416125 #> 4.55 0.38711989 0.39001056 0.39126827 0.39053653 0.38864129 0.38785974 #> 4.6  0.38583902 0.38927115 0.39053653 0.39114571 0.38928699 0.38851595 #> 4.85 0.37941395 0.38541767 0.38864129 0.38928699 0.39230123 0.39116198 #> 4.9  0.37765950 0.38416125 0.38785974 0.38851595 0.39116198 0.39201169 #> 4.95 0.37576499 0.38269619 0.38665860 0.38769885 0.39082137 0.39092416 #> 5    0.37403175 0.38147460 0.38583202 0.38687784 0.39076693 0.39099239 #> 5.05 0.37193482 0.37985905 0.38459553 0.38578585 0.39032620 0.39068187 #> 5.3  0.36008356 0.37033384 0.37690700 0.37868839 0.38631592 0.38730778 #> 5.4  0.35457136 0.36559768 0.37281597 0.37491399 0.38372116 0.38493549 #> 5.6  0.34256195 0.35503766 0.36345643 0.36606009 0.37694877 0.37860320 #> 5.65 0.33928935 0.35225661 0.36107408 0.36373772 0.37534538 0.37713622 #> 5.75 0.33258069 0.34620342 0.35557303 0.35846814 0.37111808 0.37312223 #> 6.1  0.30671112 0.32232304 0.33340792 0.33696106 0.35284159 0.35553539 #> 6.15 0.30253801 0.31849350 0.32986902 0.33350622 0.34994818 0.35275917 #> 6.2  0.29859656 0.31475624 0.32632614 0.33004419 0.34687400 0.34976664 #> 6.4  0.28198336 0.29894865 0.31126002 0.31525665 0.33360112 0.33682760 #> 6.6  0.26459770 0.28215682 0.29505202 0.29930097 0.31895445 0.32247566 #> 6.65 0.26011466 0.27783362 0.29087596 0.29514952 0.31510453 0.31870138 #> 6.9  0.23773039 0.25593344 0.26949047 0.27394583 0.29518319 0.29908902 #> 6.95 0.23314004 0.25140094 0.26503321 0.26951841 0.29096651 0.29492640 #> 7.1  0.21922927 0.23753018 0.25128183 0.25583395 0.27773942 0.28183261 #> 7.15 0.21462177 0.23292929 0.24671354 0.25127928 0.27332655 0.27746122 #> 7.3  0.20079354 0.21904582 0.23287396 0.23746473 0.25984674 0.26408835 #> 7.7  0.16420382 0.18177986 0.19531568 0.19984305 0.22240408 0.22679828 #> 7.8  0.15533482 0.17267837 0.18607916 0.19056119 0.21306082 0.21747368 #> 7.85 0.15089713 0.16811827 0.18144121 0.18589730 0.20835258 0.21277394 #> 7.9  0.14655363 0.16361861 0.17684912 0.18128009 0.20365703 0.20807787 #> 8    0.13790234 0.15462162 0.16763197 0.17200000 0.19415465 0.19856308 #> 8.05 0.13365251 0.15018889 0.16308465 0.16742177 0.18945556 0.19385712 #> 8.25 0.11707233 0.13282482 0.14519868 0.14938179 0.17081783 0.17516641 #> 8.35 0.10911969 0.12443406 0.13650406 0.14059975 0.16165572 0.16596353 #> 8.5  0.09757324 0.11223301 0.12385679 0.12782910 0.14830770 0.15254836 #> 8.55 0.09388770 0.10828598 0.11971513 0.12362116 0.14383580 0.14804075 #> 8.7  0.08303082 0.09667145 0.10755329 0.11128818 0.13072423 0.13483012 #> 8.75 0.07943824 0.09277099 0.10343504 0.10712701 0.12626581 0.13032688 #> 8.85 0.07283814 0.08567814 0.09598443 0.09957556 0.11819556 0.12218162 #> 8.95 0.06638278 0.07867651 0.08858434 0.09207783 0.11012207 0.11402026 #> 9.3  0.04620281 0.05661198 0.06509007 0.06816758 0.08403342 0.08759747 #> 9.4  0.04105174 0.05092228 0.05898428 0.06194405 0.07716205 0.08062208 #> 9.45 0.03855005 0.04814856 0.05599897 0.05889956 0.07378523 0.07719209 #> 9.65 0.02952434 0.03807078 0.04509707 0.04776436 0.06133730 0.06452242 #> 9.7  0.02734635 0.03563308 0.04245292 0.04506132 0.05830339 0.06143423 #>            4.95          5       5.05        5.3        5.4        5.6 #> 0.1  0.06018957 0.05736133 0.05476827 0.04202177 0.03725253 0.02843049 #> 0.3  0.07150018 0.06834577 0.06549795 0.05148337 0.04624090 0.03651705 #> 0.45 0.08069178 0.07729948 0.07423038 0.05930846 0.05370887 0.04331597 #> 0.55 0.08711930 0.08357782 0.08037805 0.06481731 0.05897735 0.04810807 #> 0.6  0.09050101 0.08687379 0.08361339 0.06776283 0.06180334 0.05072802 #> 0.7  0.09735904 0.09358138 0.09020009 0.07374161 0.06755855 0.05601698 #> 0.75 0.10091511 0.09706007 0.09362016 0.07685442 0.07054524 0.05877880 #> 0.85 0.10819874 0.10420931 0.10062633 0.08329128 0.07675121 0.06453752 #> 1    0.11957527 0.11538305 0.11167293 0.09343400 0.08655130 0.07365276 #> 1.05 0.12347517 0.11921965 0.11545421 0.09694067 0.08994873 0.07683587 #> 1.3  0.14380665 0.13928839 0.13528943 0.11545452 0.10793965 0.09375986 #> 1.35 0.14797422 0.14340841 0.13937027 0.11929822 0.11168481 0.09730416 #> 1.4  0.15228018 0.14767645 0.14359297 0.12328152 0.11557376 0.10099361 #> 1.8  0.18790311 0.18308432 0.17874997 0.15689178 0.14852378 0.13251815 #> 1.85 0.19242020 0.18756051 0.18323355 0.16125449 0.15282728 0.13670399 #> 2    0.20604052 0.20120829 0.19679980 0.17446793 0.16587131 0.14933090 #> 2.05 0.21082688 0.20600309 0.20157303 0.17913684 0.17048738 0.15382533 #> 2.15 0.22013911 0.21533460 0.21088415 0.18831234 0.17957922 0.16270558 #> 2.35 0.23873484 0.23402377 0.22955397 0.20687870 0.19803695 0.18084470 #> 2.5  0.25268081 0.24806416 0.24361970 0.22101254 0.21213715 0.19479880 #> 2.6  0.26188941 0.25735456 0.25293392 0.23043779 0.22155843 0.20416285 #> 2.7  0.27093248 0.26649714 0.26212730 0.23989900 0.23103355 0.21366431 #> 2.9  0.28866081 0.28444399 0.28020843 0.25854775 0.24984213 0.23259591 #> 2.95 0.29305630 0.28890709 0.28469395 0.26315985 0.25454377 0.23737350 #> 3    0.29729580 0.29321062 0.28903823 0.26775660 0.25914373 0.24204200 #> 3.05 0.30155078 0.29753441 0.29341769 0.27236332 0.26380971 0.24678757 #> 3.2  0.31382857 0.31004793 0.30608718 0.28578973 0.27744925 0.26074630 #> 3.35 0.32553426 0.32200850 0.31824405 0.29886111 0.29078675 0.27450588 #> 3.5  0.33650173 0.33318068 0.32971631 0.31137679 0.30361532 0.28786912 #> 3.55 0.34000486 0.33685530 0.33340105 0.31544992 0.30781899 0.29226050 #> 3.65 0.34668745 0.34375039 0.34044900 0.32328052 0.31591308 0.30077973 #> 3.7  0.34967306 0.34692766 0.34364551 0.32689767 0.31966825 0.30474162 #> 3.8  0.35592337 0.35328336 0.35031953 0.33443002 0.32749171 0.31308363 #> 3.9  0.36156348 0.35914054 0.35634432 0.34141600 0.33479396 0.32092942 #> 4.05 0.36924896 0.36724913 0.36471846 0.35128712 0.34519182 0.33221025 #> 4.1  0.37199525 0.36995079 0.36765568 0.35483271 0.34894029 0.33624687 #> 4.15 0.37372592 0.37187952 0.36965351 0.35727666 0.35156189 0.33919797 #> 4.2  0.37576499 0.37403175 0.37193482 0.36008356 0.35457136 0.34256195 #> 4.4  0.38269619 0.38147460 0.37985905 0.37033384 0.36559768 0.35503766 #> 4.55 0.38665860 0.38583202 0.38459553 0.37690700 0.37281597 0.36345643 #> 4.6  0.38769885 0.38687784 0.38578585 0.37868839 0.37491399 0.36606009 #> 4.85 0.39082137 0.39076693 0.39032620 0.38631592 0.38372116 0.37694877 #> 4.9  0.39092416 0.39099239 0.39068187 0.38730778 0.38493549 0.37860320 #> 4.95 0.39151472 0.39109580 0.39089541 0.38818911 0.38611121 0.38043770 #> 5    0.39109580 0.39211459 0.39138000 0.38935191 0.38748171 0.38214503 #> 5.05 0.39089541 0.39138000 0.39229034 0.39001999 0.38844451 0.38355681 #> 5.3  0.38818911 0.38935191 0.39001999 0.39255658 0.39156718 0.38916722 #> 5.4  0.38611121 0.38748171 0.38844451 0.39156718 0.39279382 0.39042976 #> 5.6  0.38043770 0.38214503 0.38355681 0.38916722 0.39042976 0.39178920 #> 5.65 0.37899498 0.38110313 0.38250283 0.38895206 0.39033556 0.39155070 #> 5.75 0.37525777 0.37744087 0.37938258 0.38674599 0.38879789 0.39105033 #> 6.1  0.35858700 0.36136543 0.36388159 0.37541129 0.37914576 0.38508454 #> 6.15 0.35585277 0.35886849 0.36145808 0.37364530 0.37760318 0.38390605 #> 6.2  0.35300338 0.35605616 0.35880354 0.37147150 0.37570272 0.38252654 #> 6.4  0.34048396 0.34385093 0.34694150 0.36164928 0.36679102 0.37548421 #> 6.6  0.32649478 0.33013375 0.33355352 0.35006263 0.35600721 0.36652914 #> 6.65 0.32278924 0.32647137 0.32992254 0.34695449 0.35306348 0.36400232 #> 6.9  0.30349557 0.30743313 0.31132832 0.33017202 0.33713735 0.35005265 #> 6.95 0.29938838 0.30337293 0.30733463 0.32652248 0.33363525 0.34692659 #> 7.1  0.28644173 0.29048998 0.29463180 0.31471404 0.32227990 0.33656867 #> 7.15 0.28210638 0.28616135 0.29038226 0.31073590 0.31843262 0.33303062 #> 7.3  0.26882092 0.27296063 0.27731926 0.29838449 0.30645252 0.32191254 #> 7.7  0.23161027 0.23577132 0.24047150 0.26272274 0.27151115 0.28867440 #> 7.8  0.22226353 0.22648090 0.23114561 0.25357776 0.26248542 0.27996937 #> 7.85 0.21752874 0.22172764 0.22644247 0.24890114 0.25785394 0.27545364 #> 7.9  0.21282560 0.21702692 0.22174827 0.24425355 0.25327567 0.27098827 #> 8    0.20326763 0.20744338 0.21217353 0.23468540 0.24373700 0.26165958 #> 8.05 0.19854285 0.20271658 0.20744238 0.22995533 0.23905105 0.25705235 #> 8.25 0.17971501 0.18383136 0.18852229 0.21085370 0.21999210 0.23817874 #> 8.35 0.17042694 0.17448378 0.17917214 0.20129980 0.21041500 0.22862400 #> 8.5  0.15689162 0.16092143 0.16549658 0.18738355 0.19646083 0.21464548 #> 8.55 0.15231560 0.15629932 0.16083166 0.18251435 0.19153997 0.20966527 #> 8.7  0.13893869 0.14280091 0.14723867 0.16841799 0.17730863 0.19523871 #> 8.75 0.13436940 0.13817850 0.14257507 0.16354470 0.17237742 0.19020913 #> 8.85 0.12611095 0.12987533 0.13416730 0.15476293 0.16347511 0.18112110 #> 8.95 0.11782130 0.12151329 0.12569619 0.14585632 0.15442382 0.17183157 #> 9.3  0.09089385 0.09425003 0.09799918 0.11636220 0.12427975 0.14059354 #> 9.4  0.08375886 0.08700859 0.09062452 0.10841240 0.11611021 0.13203562 #> 9.45 0.08024646 0.08344243 0.08698815 0.10447747 0.11205998 0.12777951 #> 9.65 0.06725109 0.07021148 0.07347897 0.08974179 0.09683381 0.11167580 #> 9.7  0.06407430 0.06697894 0.07017473 0.08612043 0.09308677 0.10769426 #>            5.65       5.75        6.1        6.15         6.2         6.4 #> 0.1  0.02675327 0.02279097 0.01093259 0.009810752 0.008258084 0.003330229 #> 0.3  0.03452897 0.03012479 0.01674454 0.015396878 0.013642593 0.007905646 #> 0.45 0.04108113 0.03635249 0.02179164 0.020254886 0.018363270 0.011978355 #> 0.55 0.04571182 0.04074516 0.02536645 0.023699103 0.021698523 0.014864327 #> 0.6  0.04823920 0.04317110 0.02739725 0.025661730 0.023612667 0.016557733 #> 0.7  0.05335662 0.04806002 0.03146547 0.029590585 0.027432965 0.019901050 #> 0.75 0.05603119 0.05061879 0.03360514 0.031661351 0.029446584 0.021687536 #> 0.85 0.06161634 0.05598148 0.03812979 0.036034969 0.033723581 0.025479411 #> 1    0.07047220 0.06447858 0.04536807 0.043052095 0.040548732 0.031583992 #> 1.05 0.07356905 0.06746328 0.04793451 0.045540719 0.042983300 0.033770996 #> 1.3  0.09007756 0.08340589 0.06179092 0.059003707 0.056155134 0.045697693 #> 1.35 0.09354354 0.08676261 0.06474238 0.061878735 0.058970952 0.048265802 #> 1.4  0.09715311 0.09026335 0.06783053 0.064883290 0.061920892 0.050961978 #> 1.8  0.12811684 0.12041707 0.09488281 0.091307948 0.087896349 0.074956673 #> 1.85 0.13224051 0.12446205 0.09859861 0.094965304 0.091491720 0.078323962 #> 2    0.14471191 0.13667998 0.10980355 0.105936697 0.102328892 0.088468499 #> 2.05 0.14915187 0.14103813 0.11383037 0.109882377 0.106230514 0.092136601 #> 2.15 0.15794615 0.14968951 0.12187354 0.117790645 0.114047683 0.099512151 #> 2.35 0.17595139 0.16745686 0.13856511 0.134234467 0.130326973 0.114966493 #> 2.5  0.18984055 0.18120562 0.15163694 0.147137947 0.143123890 0.127198536 #> 2.6  0.19917894 0.19047041 0.16051422 0.155912624 0.151837625 0.135566239 #> 2.7  0.20867492 0.19992587 0.16967528 0.164995001 0.160862514 0.144277067 #> 2.9  0.22764053 0.21886038 0.18817469 0.183374567 0.179143306 0.162016277 #> 2.95 0.23242424 0.22364555 0.19290377 0.188058641 0.183823398 0.166584927 #> 3    0.23711293 0.22834348 0.19754878 0.192683966 0.188430822 0.171082747 #> 3.05 0.24187089 0.23312786 0.20231160 0.197419964 0.193156886 0.175714027 #> 3.2  0.25593997 0.24727211 0.21648704 0.211571424 0.207276838 0.189606947 #> 3.35 0.26984384 0.26130865 0.23073556 0.225831642 0.221523929 0.203719404 #> 3.5  0.28339583 0.27502704 0.24485422 0.239995014 0.235691625 0.217861891 #> 3.55 0.28784031 0.27957109 0.24956620 0.244728857 0.240440264 0.222608977 #> 3.65 0.29649340 0.28839461 0.25878766 0.254004256 0.249739545 0.231957971 #> 3.7  0.30056001 0.29253815 0.26315386 0.258376480 0.254161888 0.236425475 #> 3.8  0.30903942 0.30122156 0.27240377 0.267742408 0.263515917 0.245920251 #> 3.9  0.31706640 0.30949222 0.28127540 0.276705398 0.272549269 0.255116516 #> 4.05 0.32863048 0.32146582 0.29433324 0.289950108 0.285885576 0.268810257 #> 4.1  0.33281555 0.32576790 0.29891409 0.294657141 0.290586259 0.273572915 #> 4.15 0.33584574 0.32894955 0.30262841 0.298384377 0.294391946 0.277581907 #> 4.2  0.33928935 0.33258069 0.30671112 0.302538010 0.298596561 0.281983358 #> 4.4  0.35225661 0.34620342 0.32232304 0.318493503 0.314756239 0.298948645 #> 4.55 0.36107408 0.35557303 0.33340792 0.329869015 0.326326140 0.311260020 #> 4.6  0.36373772 0.35846814 0.33696106 0.333506222 0.330044185 0.315256650 #> 4.85 0.37534538 0.37111808 0.35284159 0.349948181 0.346873999 0.333601115 #> 4.9  0.37713622 0.37312223 0.35553539 0.352759169 0.349766637 0.336827605 #> 4.95 0.37899498 0.37525777 0.35858700 0.355852765 0.353003380 0.340483956 #> 5    0.38110313 0.37744087 0.36136543 0.358868487 0.356056158 0.343850931 #> 5.05 0.38250283 0.37938258 0.36388159 0.361458079 0.358803545 0.346941495 #> 5.3  0.38895206 0.38674599 0.37541129 0.373645301 0.371471498 0.361649278 #> 5.4  0.39033556 0.38879789 0.37914576 0.377603182 0.375702721 0.366791022 #> 5.6  0.39155070 0.39105033 0.38508454 0.383906052 0.382526543 0.375484211 #> 5.65 0.39266207 0.39186990 0.38658205 0.385810052 0.384399532 0.377763089 #> 5.75 0.39186990 0.39284194 0.38865180 0.387998866 0.387135329 0.381326371 #> 6.1  0.38658205 0.38865180 0.39216609 0.391759853 0.391669991 0.389575508 #> 6.15 0.38581005 0.38799887 0.39175985 0.392874175 0.392164688 0.390549663 #> 6.2  0.38439953 0.38713533 0.39166999 0.392164688 0.393035085 0.391258580 #> 6.4  0.37776309 0.38132637 0.38957551 0.390549663 0.391258580 0.393169283 #> 6.6  0.36922535 0.37365693 0.38540619 0.386875821 0.388069335 0.391138210 #> 6.65 0.36673589 0.37150181 0.38402893 0.385607990 0.387100315 0.390502086 #> 6.9  0.35313521 0.35883698 0.37550443 0.377535218 0.379402000 0.385441606 #> 6.95 0.35008861 0.35598562 0.37342667 0.375572510 0.377549515 0.384112869 #> 7.1  0.33993985 0.34638095 0.36606371 0.368607343 0.370898761 0.378910628 #> 7.15 0.33647067 0.34306707 0.36345881 0.366105336 0.368486581 0.376959178 #> 7.3  0.32549869 0.33257994 0.35500578 0.357937844 0.360591269 0.370411868 #> 7.7  0.29257816 0.30069100 0.32765157 0.331366534 0.334537103 0.347562690 #> 7.8  0.28392517 0.29219162 0.32016541 0.323907472 0.327322620 0.341061468 #> 7.85 0.27942677 0.28780876 0.31617820 0.319994932 0.323440017 0.337517798 #> 7.9  0.27498643 0.28346338 0.31225963 0.316129220 0.319649974 0.333993546 #> 8    0.26569341 0.27431439 0.30382802 0.307824995 0.311456129 0.326511741 #> 8.05 0.26110639 0.26980715 0.29968040 0.303725209 0.307426821 0.322737283 #> 8.25 0.24226538 0.25118204 0.28219744 0.286424904 0.290323649 0.306673311 #> 8.35 0.23272271 0.24168756 0.27314424 0.277439193 0.281402562 0.298227205 #> 8.5  0.21879599 0.22787861 0.25980107 0.264186120 0.268339358 0.285703946 #> 8.55 0.21375535 0.22281764 0.25486242 0.259211887 0.263405961 0.280938055 #> 8.7  0.19928709 0.20838260 0.24060110 0.245019273 0.249299684 0.267245576 #> 8.75 0.19425927 0.20331749 0.23557263 0.240030331 0.244312664 0.262391075 #> 8.85 0.18516621 0.19417811 0.22638944 0.230822390 0.235178634 0.253417759 #> 8.95 0.17587012 0.18479518 0.21689480 0.221321948 0.225716773 0.244085989 #> 9.3  0.14445225 0.15301341 0.18406047 0.188312602 0.192827178 0.211231237 #> 9.4  0.13583714 0.14424198 0.17482489 0.179008715 0.183525690 0.201831704 #> 9.45 0.13155149 0.13987341 0.17019920 0.174345509 0.178862770 0.197106000 #> 9.65 0.11531575 0.12324770 0.15236838 0.156333182 0.160813470 0.178659844 #> 9.7  0.11129748 0.11912989 0.14792990 0.151850781 0.156314973 0.174052294 #>               6.6         6.65           6.9          6.95           7.1 #> 0.1  -0.000938314 -0.001839766 -0.0056442034 -0.0062986130 -0.0079580199 #> 0.3   0.002886134  0.001802567 -0.0029073201 -0.0037223070 -0.0058304606 #> 0.45  0.006353430  0.005123779 -0.0003276872 -0.0012767136 -0.0037564663 #> 0.55  0.008824396  0.007495189  0.0015420291  0.0005023776 -0.0022316170 #> 0.6   0.010297331  0.008913033  0.0026859683  0.0015945949 -0.0012775210 #> 0.7   0.013215274  0.011723567  0.0049572939  0.0037710468  0.0006141366 #> 0.75  0.014768535  0.013221997  0.0061795406  0.0049390596  0.0016449213 #> 0.85  0.018099709  0.016441044  0.0088257583  0.0074784408  0.0038860382 #> 1     0.023499863  0.021670127  0.0131928507  0.0116817374  0.0076390235 #> 1.05  0.025445680  0.023554280  0.0147727244  0.0132041420  0.0089980516 #> 1.3   0.036141379  0.033946735  0.0236305839  0.0217662769  0.0167297644 #> 1.35  0.038462490  0.036207024  0.0255812981  0.0236565180  0.0184493850 #> 1.4   0.040903038  0.038582645  0.0276327756  0.0256449791  0.0202570653 #> 1.8   0.062867043  0.060039446  0.0465033579  0.0440008398  0.0371292279 #> 1.85  0.065985106  0.063089419  0.0492150380  0.0466451171  0.0395707672 #> 2     0.075402642  0.072324622  0.0575111618  0.0547487542  0.0471066592 #> 2.05  0.078817543  0.075673688  0.0605227484  0.0576913462  0.0498453932 #> 2.15  0.085714683  0.082445125  0.0666563677  0.0636931294  0.0554475475 #> 2.35  0.100254311  0.096741427  0.0797131417  0.0764900331  0.0674464277 #> 2.5   0.111843852  0.108155127  0.0902341131  0.0868205738  0.0771825993 #> 2.6   0.119810304  0.116009101  0.0975225536  0.0939862033  0.0839602684 #> 2.7   0.128120722  0.124231984  0.1051833240  0.1015253317  0.0911077228 #> 2.9   0.145205922  0.141100258  0.1210489044  0.1171647765  0.1060065261 #> 2.95  0.149643500  0.145462815  0.1251572944  0.1212151221  0.1098758131 #> 3     0.153976166  0.149774036  0.1292440523  0.1252506455  0.1137381566 #> 3.05  0.158478235  0.154242256  0.1335080507  0.1294651761  0.1177946500 #> 3.2   0.172020560  0.167670131  0.1463379313  0.1421527070  0.1299903020 #> 3.35  0.185871767  0.181432190  0.1596076210  0.1552982384  0.1426956090 #> 3.5   0.199843791  0.195334666  0.1731229611  0.1687051690  0.1557259225 #> 3.55  0.204559212  0.200038515  0.1777232603  0.1732786535  0.1601730455 #> 3.65  0.213875232  0.209323510  0.1868381370  0.1823399218  0.1690239463 #> 3.7   0.218349452  0.213796755  0.1912714893  0.1867558118  0.1733534916 #> 3.8   0.227877110  0.223319010  0.2006878390  0.1961304560  0.1825615199 #> 3.9   0.237157858  0.232596349  0.2099315738  0.2053470801  0.1916373888 #> 4.05  0.251067650  0.246543336  0.2239503812  0.2193496498  0.2054947968 #> 4.1   0.255852908  0.251330969  0.2286891973  0.2240723759  0.2101323704 #> 4.15  0.260070118  0.255580645  0.2331093788  0.2285203481  0.2146036207 #> 4.2   0.264597700  0.260114656  0.2377303908  0.2331400416  0.2192292697 #> 4.4   0.282156818  0.277833621  0.2559334372  0.2514009432  0.2375301843 #> 4.55  0.295052020  0.290875958  0.2694904672  0.2650332121  0.2512818257 #> 4.6   0.299300970  0.295149518  0.2739458317  0.2695184102  0.2558339547 #> 4.85  0.318954452  0.315104526  0.2951831931  0.2909665148  0.2777394208 #> 4.9   0.322475664  0.318701381  0.2990890209  0.2949264024  0.2818326100 #> 4.95  0.326494778  0.322789237  0.3034955730  0.2993883818  0.2864417312 #> 5     0.330133753  0.326471374  0.3074331280  0.3033729316  0.2904899800 #> 5.05  0.333553518  0.329922544  0.3113283189  0.3073346334  0.2946318002 #> 5.3   0.350062635  0.346954492  0.3301720182  0.3265224843  0.3147140382 #> 5.4   0.356007208  0.353063484  0.3371373452  0.3336352482  0.3222798963 #> 5.6   0.366529139  0.364002321  0.3500526476  0.3469265918  0.3365686741 #> 5.65  0.369225348  0.366735895  0.3531352062  0.3500886077  0.3399398480 #> 5.75  0.373656927  0.371501808  0.3588369769  0.3559856208  0.3463809530 #> 6.1   0.385406187  0.384028935  0.3755044304  0.3734266671  0.3660637059 #> 6.15  0.386875821  0.385607990  0.3775352185  0.3755725103  0.3686073429 #> 6.2   0.388069335  0.387100315  0.3794019998  0.3775495155  0.3708987612 #> 6.4   0.391138210  0.390502086  0.3854416065  0.3841128694  0.3789106276 #> 6.6   0.393153280  0.392093146  0.3896086700  0.3887705263  0.3852483354 #> 6.65  0.392093146  0.392882921  0.3903178706  0.3896148338  0.3865199662 #> 6.9   0.389608670  0.390317871  0.3924091799  0.3918643995  0.3906704185 #> 6.95  0.388770526  0.389614834  0.3918643995  0.3924395459  0.3911953603 #> 7.1   0.385248335  0.386519966  0.3906704185  0.3911953603  0.3930162057 #> 7.15  0.383806871  0.385214115  0.3900269665  0.3906901499  0.3919568162 #> 7.3   0.378758015  0.380568836  0.3873617045  0.3884391104  0.3910397812 #> 7.7   0.359560881  0.362368340  0.3741977865  0.3763457902  0.3823446778 #> 7.8   0.353909637  0.357056862  0.3699852678  0.3723906132  0.3792243351 #> 7.85  0.350780965  0.353948591  0.3675847457  0.3701201062  0.3773884293 #> 7.9   0.347703858  0.350971900  0.3651830489  0.3678830577  0.3754611421 #> 8     0.340832721  0.344302272  0.3595567875  0.3624120602  0.3708383510 #> 8.05  0.337458851  0.341020613  0.3568240820  0.3598297732  0.3685630844 #> 8.25  0.322676193  0.326593980  0.3443912424  0.3478334605  0.3579377697 #> 8.35  0.314790638  0.318846880  0.3375570800  0.3411985161  0.3519285034 #> 8.5   0.302951298  0.307181633  0.3270884714  0.3309867641  0.3424067653 #> 8.55  0.298451405  0.302773683  0.3230847837  0.3270834455  0.3389121990 #> 8.7   0.285344405  0.289759612  0.3110998552  0.3153293051  0.3278394421 #> 8.75  0.280678594  0.285187181  0.3069319343  0.3112558596  0.3240962978 #> 8.85  0.271904432  0.276463480  0.2986761681  0.3031030437  0.3162072931 #> 8.95  0.262753824  0.267393348  0.2900984648  0.2946377439  0.3080787394 #> 9.3   0.230181728  0.234808072  0.2585995316  0.2633904508  0.2775823359 #> 9.4   0.220740712  0.225345060  0.2493021075  0.2541340294  0.2684502271 #> 9.45  0.215978463  0.220566310  0.2445880741  0.2494367172  0.2637998404 #> 9.65  0.197219737  0.201702792  0.2257349883  0.2305947793  0.2450045397 #> 9.7   0.192528331  0.196985749  0.2210191607  0.2258822837  0.2403013871 #>               7.15           7.3          7.7           7.8          7.85 #> 0.1  -0.0083975129 -0.0096231718 -0.011471453 -0.0114797137 -0.0114275330 #> 0.3  -0.0064184206 -0.0080641575 -0.010810279 -0.0110401115 -0.0110991097 #> 0.45 -0.0044698673 -0.0064727639 -0.010000870 -0.0104413651 -0.0105895867 #> 0.55 -0.0030299173 -0.0052692059 -0.009320027 -0.0098921148 -0.0101037249 #> 0.6  -0.0021238532 -0.0045050351 -0.008876468 -0.0095381647 -0.0097878796 #> 0.7  -0.0003262853 -0.0029750111 -0.007950416 -0.0087713855 -0.0090947786 #> 0.75  0.0006565203 -0.0021289387 -0.007414019 -0.0083171830 -0.0086803021 #> 0.85  0.0027959599 -0.0002791413 -0.006227459 -0.0073141422 -0.0077522310 #> 1     0.0063958912  0.0028859170 -0.004073787 -0.0054212623 -0.0059913992 #> 1.05  0.0076999947  0.0040298595 -0.003303119 -0.0047465512 -0.0053630155 #> 1.3   0.0151502157  0.0106756759  0.001435276 -0.0005099630 -0.0013700917 #> 1.35  0.0168118898  0.0121704994  0.002525153  0.0004747555 -0.0004359689 #> 1.4   0.0185588879  0.0137425171  0.003678487  0.0015195154  0.0005536531 #> 1.8   0.0349314026  0.0286660488  0.015012796  0.0119273566  0.0104980010 #> 1.85  0.0373056146  0.0308344937  0.016660987  0.0134504130  0.0119460557 #> 2     0.0446509908  0.0376277520  0.022036411  0.0184589881  0.0167761055 #> 2.05  0.0473200060  0.0400920344  0.023967430  0.0202545836  0.0185134127 #> 2.15  0.0527889189  0.0451649836  0.028006628  0.0240364914  0.0221550637 #> 2.35  0.0645210558  0.0561018255  0.036827760  0.0323322208  0.0301684497 #> 2.5   0.0740587562  0.0650374497  0.044123419  0.0392242242  0.0368471917 #> 2.6   0.0807052224  0.0712882838  0.049272837  0.0441037771  0.0415851328 #> 2.7   0.0877226285  0.0779058318  0.054779553  0.0493344295  0.0466698100 #> 2.9   0.1023725928  0.0917858292  0.066439412  0.0604588389  0.0574757058 #> 2.95  0.1061733297  0.0953770812  0.069391023  0.0632535554  0.0602213203 #> 3     0.1099781827  0.0990009903  0.072485583  0.0662238202  0.0631280714 #> 3.05  0.1139781759  0.1028279479  0.075783272  0.0693674700  0.0662084113 #> 3.2   0.1260076205  0.1143292711  0.085673025  0.0788747104  0.0755020270 #> 3.35  0.1385620280  0.1263988329  0.096203881  0.0890292425  0.0854565978 #> 3.5   0.1514481557  0.1388550006  0.107204707  0.0996636806  0.0959022680 #> 3.55  0.1558646002  0.1431286003  0.111025857  0.1033682840  0.0995453984 #> 3.65  0.1646430085  0.1516511831  0.118659247  0.1107819937  0.1068456357 #> 3.7   0.1689404840  0.1558683725  0.122555374  0.1145893303  0.1106109765 #> 3.8   0.1780921367  0.1647796253  0.130591929  0.1224134120  0.1183118096 #> 3.9   0.1871085760  0.1736135580  0.138681359  0.1302883457  0.1261138284 #> 4.05  0.2009263566  0.1872160881  0.151372803  0.1427383367  0.1384082708 #> 4.1   0.2055243425  0.1917257910  0.155513115  0.1467626585  0.1423992119 #> 4.15  0.2100014441  0.1962045776  0.159838596  0.1510394742  0.1466363547 #> 4.2   0.2146217683  0.2007935434  0.164203819  0.1553348156  0.1508971320 #> 4.4   0.2329292931  0.2190458242  0.181779865  0.1726783742  0.1681182650 #> 4.55  0.2467135375  0.2328739592  0.195315676  0.1860791599  0.1814412078 #> 4.6   0.2512792833  0.2374647339  0.199843046  0.1905611903  0.1858972969 #> 4.85  0.2733265509  0.2598467371  0.222404075  0.2130608183  0.2083525824 #> 4.9   0.2774612153  0.2640883524  0.226798280  0.2174736840  0.2127739419 #> 4.95  0.2821063757  0.2688209207  0.231610275  0.2222635340  0.2175287404 #> 5     0.2861613477  0.2729606268  0.235771317  0.2264809035  0.2217276411 #> 5.05  0.2903822573  0.2773192566  0.240471498  0.2311456070  0.2264424727 #> 5.3   0.3107359034  0.2983844930  0.262722742  0.2535777564  0.2489011422 #> 5.4   0.3184326197  0.3064525199  0.271511145  0.2624854233  0.2578539390 #> 5.6   0.3330306165  0.3219125381  0.288674402  0.2799693728  0.2754536426 #> 5.65  0.3364706701  0.3254986911  0.292578163  0.2839251748  0.2794267690 #> 5.75  0.3430670727  0.3325799391  0.300690998  0.2921916214  0.2878087593 #> 6.1   0.3634588137  0.3550057803  0.327651569  0.3201654053  0.3161781979 #> 6.15  0.3661053360  0.3579378441  0.331366534  0.3239074717  0.3199949323 #> 6.2   0.3684865810  0.3605912688  0.334537103  0.3273226201  0.3234400173 #> 6.4   0.3769591782  0.3704118680  0.347562690  0.3410614682  0.3375177981 #> 6.6   0.3838068710  0.3787580155  0.359560881  0.3539096371  0.3507809645 #> 6.65  0.3852141154  0.3805688358  0.362368340  0.3570568619  0.3539485913 #> 6.9   0.3900269665  0.3873617045  0.374197787  0.3699852678  0.3675847457 #> 6.95  0.3906901499  0.3884391104  0.376345790  0.3723906132  0.3701201062 #> 7.1   0.3919568162  0.3910397812  0.382344678  0.3792243351  0.3773884293 #> 7.15  0.3930276497  0.3915602729  0.384026728  0.3811900509  0.3795045492 #> 7.3   0.3915602729  0.3934040628  0.388418532  0.3864611697  0.3852362720 #> 7.7   0.3840267282  0.3884185322  0.395267463  0.3948976403  0.3949675493 #> 7.8   0.3811900509  0.3864611697  0.394897640  0.3968674441  0.3964632173 #> 7.85  0.3795045492  0.3852362720  0.394967549  0.3964632173  0.3978649119 #> 7.9   0.3777066107  0.3838467645  0.394793918  0.3965907134  0.3973401861 #> 8     0.3733445269  0.3802980943  0.393643953  0.3960517671  0.3971203606 #> 8.05  0.3711963199  0.3785531267  0.393137925  0.3958559280  0.3972988670 #> 8.25  0.3610701795  0.3699750496  0.389289091  0.3932158513  0.3950581946 #> 8.35  0.3552732361  0.3649029064  0.386439321  0.3911149574  0.3930588799 #> 8.5   0.3460245957  0.3565568321  0.381016260  0.3862278607  0.3887103676 #> 8.55  0.3426592459  0.3536042111  0.379383201  0.3848946041  0.3875573127 #> 8.7   0.3318388581  0.3436461843  0.372270241  0.3785697454  0.3815755858 #> 8.75  0.3282130055  0.3403900238  0.370176344  0.3767383779  0.3799646248 #> 8.85  0.3204276009  0.3329992430  0.364222996  0.3711863852  0.3745097488 #> 8.95  0.3124243293  0.3254442365  0.358233623  0.3655964981  0.3691087244 #> 9.3   0.2821868796  0.2962933006  0.333150654  0.3415367294  0.3454704612 #> 9.4   0.2730971839  0.2874201976  0.325168377  0.3337812547  0.3378256799 #> 9.45  0.2684642997  0.2828838904  0.321052123  0.3297726569  0.3338885999 #> 9.65  0.2496675991  0.2642836254  0.303489820  0.3124671911  0.3166972441 #> 9.7   0.2449719932  0.2596423261  0.299147430  0.3082050573  0.3125012431 #>                7.9            8         8.05         8.25          8.35 #> 0.1  -0.0114920285 -0.011466422 -0.011448027 -0.010994571 -1.063568e-02 #> 0.3  -0.0112383835 -0.011364472 -0.011406759 -0.011225847 -1.098491e-02 #> 0.45 -0.0107971276 -0.011064040 -0.011163280 -0.011234093 -1.110112e-02 #> 0.55 -0.0103562891 -0.010716759 -0.010854449 -0.011097339 -1.104036e-02 #> 0.6  -0.0100737252 -0.010497383 -0.010664385 -0.011022035 -1.101520e-02 #> 0.7  -0.0094407862 -0.009976396 -0.010195159 -0.010766096 -1.085488e-02 #> 0.75 -0.0090516940 -0.009649514 -0.009893062 -0.010574449 -1.071199e-02 #> 0.85 -0.0081890772 -0.008917518 -0.009218811 -0.010141090 -1.038618e-02 #> 1    -0.0065302136 -0.007465053 -0.007862000 -0.009174520 -9.601051e-03 #> 1.05 -0.0059395006 -0.006948819 -0.007379718 -0.008830216 -9.318432e-03 #> 1.3  -0.0021418290 -0.003551556 -0.004168695 -0.006375530 -7.217680e-03 #> 1.35 -0.0012504466 -0.002746970 -0.003404907 -0.005775899 -6.694420e-03 #> 1.4  -0.0003042981 -0.001890054 -0.002589978 -0.005129938 -6.128597e-03 #> 1.8   0.0092502318  0.006866107  0.005783365  0.001717748 -8.898214e-06 #> 1.85  0.0106425624  0.008142591  0.007004679  0.002715563  8.835914e-04 #> 2     0.0153097411  0.012479354  0.011179500  0.006255385  4.114189e-03 #> 2.05  0.0169717771  0.014016049  0.012647129  0.007485945  5.226912e-03 #> 2.15  0.0205003698  0.017302750  0.015819656  0.010189419  7.705429e-03 #> 2.35  0.0282715407  0.024568439  0.022839809  0.016231401  1.327241e-02 #> 2.5   0.0347512715  0.030647766  0.028720516  0.021334673  1.799921e-02 #> 2.6   0.0393525644  0.034975751  0.032912436  0.024996522  2.140359e-02 #> 2.7   0.0442979789  0.039642208  0.037439259  0.028974574  2.510926e-02 #> 2.9   0.0548591200  0.049636954  0.047173662  0.037587599  3.318813e-02 #> 2.95  0.0574826051  0.052092338  0.049522194  0.039625274  3.507127e-02 #> 3     0.0603184773  0.054792329  0.052153679  0.041991796  3.730749e-02 #> 3.05  0.0633195882  0.057641958  0.054921265  0.044453263  3.961457e-02 #> 3.2   0.0724002946  0.066289712  0.063352199  0.052024760  4.676226e-02 #> 3.35  0.0821412775  0.075599454  0.072444234  0.060255136  5.456502e-02 #> 3.5   0.0923772501  0.085406566  0.082035030  0.068993867  6.287351e-02 #> 3.55  0.0959520500  0.088848319  0.085404728  0.072075804  6.581208e-02 #> 3.65  0.1031184328  0.095746688  0.092165300  0.078292592  7.175957e-02 #> 3.7   0.1068325575  0.099351451  0.095714340  0.081615969  7.495548e-02 #> 3.8   0.1143945969  0.106635672  0.102853341  0.088179056  8.123485e-02 #> 3.9   0.1220503388  0.114040895  0.110112359  0.094929588  8.771544e-02 #> 4.05  0.1342127366  0.125870839  0.121788546  0.105882397  9.829929e-02 #> 4.1   0.1381361830  0.129670015  0.125517343  0.109355287  1.016278e-01 #> 4.15  0.1423305432  0.133791395  0.129590188  0.113229219  1.053961e-01 #> 4.2   0.1465536263  0.137902345  0.133652506  0.117072334  1.091197e-01 #> 4.4   0.1636186090  0.154621616  0.150188887  0.132824817  1.244341e-01 #> 4.55  0.1768491174  0.167631967  0.163084651  0.145198683  1.365041e-01 #> 4.6   0.1812800938  0.172000002  0.167421768  0.149381792  1.405998e-01 #> 4.85  0.2036570309  0.194154645  0.189455562  0.170817827  1.616557e-01 #> 4.9   0.2080778745  0.198563079  0.193857118  0.175166412  1.659635e-01 #> 4.95  0.2128255977  0.203267630  0.198542851  0.179715014  1.704269e-01 #> 5     0.2170269231  0.207443383  0.202716580  0.183831357  1.744838e-01 #> 5.05  0.2217482716  0.212173533  0.207442384  0.188522288  1.791721e-01 #> 5.3   0.2442535488  0.234685398  0.229955333  0.210853702  2.012998e-01 #> 5.4   0.2532756693  0.243736997  0.239051051  0.219992095  2.104150e-01 #> 5.6   0.2709882678  0.261659577  0.257052346  0.238178740  2.286240e-01 #> 5.65  0.2749864292  0.265693412  0.261106388  0.242265376  2.327227e-01 #> 5.75  0.2834633833  0.274314393  0.269807152  0.251182044  2.416876e-01 #> 6.1   0.3122596292  0.303828020  0.299680404  0.282197442  2.731442e-01 #> 6.15  0.3161292202  0.307824995  0.303725209  0.286424904  2.774392e-01 #> 6.2   0.3196499743  0.311456129  0.307426821  0.290323649  2.814026e-01 #> 6.4   0.3339935465  0.326511741  0.322737283  0.306673311  2.982272e-01 #> 6.6   0.3477038580  0.340832721  0.337458851  0.322676193  3.147906e-01 #> 6.65  0.3509718996  0.344302272  0.341020613  0.326593980  3.188469e-01 #> 6.9   0.3651830489  0.359556787  0.356824082  0.344391242  3.375571e-01 #> 6.95  0.3678830577  0.362412060  0.359829773  0.347833460  3.411985e-01 #> 7.1   0.3754611421  0.370838351  0.368563084  0.357937770  3.519285e-01 #> 7.15  0.3777066107  0.373344527  0.371196320  0.361070179  3.552732e-01 #> 7.3   0.3838467645  0.380298094  0.378553127  0.369975050  3.649029e-01 #> 7.7   0.3947939183  0.393643953  0.393137925  0.389289091  3.864393e-01 #> 7.8   0.3965907134  0.396051767  0.395855928  0.393215851  3.911150e-01 #> 7.85  0.3973401861  0.397120361  0.397298867  0.395058195  3.930589e-01 #> 7.9   0.3985490273  0.398076273  0.398009913  0.396642686  3.949679e-01 #> 8     0.3980762726  0.399414949  0.399046167  0.398931939  3.978637e-01 #> 8.05  0.3980099135  0.399046167  0.400435589  0.400276003  3.995564e-01 #> 8.25  0.3966426860  0.398931939  0.400276003  0.404464526  4.040520e-01 #> 8.35  0.3949679471  0.397863714  0.399556389  0.404052024  4.060170e-01 #> 8.5   0.3910862053  0.394794771  0.396995019  0.403303379  4.055495e-01 #> 8.55  0.3900906895  0.394151668  0.396522062  0.403536333  4.060898e-01 #> 8.7   0.3845935143  0.389504172  0.392406216  0.401346602  4.049509e-01 #> 8.75  0.3831343998  0.388367729  0.391433245  0.401031894  4.050653e-01 #> 8.85  0.3779667281  0.383653084  0.387034950  0.397745098  4.023224e-01 #> 8.95  0.3728429608  0.379009975  0.382694983  0.394526780  3.997351e-01 #> 9.3   0.3500792896  0.357608226  0.362263863  0.377440812  3.847125e-01 #> 9.4   0.3426307723  0.350484760  0.355327014  0.371386208  3.791904e-01 #> 9.45  0.3387709165  0.346784385  0.351700105  0.368220865  3.762940e-01 #> 9.65  0.3218911804  0.330364897  0.335592929  0.353460115  3.624384e-01 #> 9.7   0.3177482904  0.326350463  0.331604911  0.349887790  3.590994e-01 #>               8.5          8.55           8.7          8.75         8.85 #> 0.1  -0.010023071 -0.0098041111 -0.0090990456 -8.890265e-03 -0.008283326 #> 0.3  -0.010505180 -0.0103450404 -0.0097336414 -9.537079e-03 -0.009000210 #> 0.45 -0.010747321 -0.0106462293 -0.0101220990 -9.943785e-03 -0.009471315 #> 0.55 -0.010784602 -0.0107147671 -0.0102625136 -1.009263e-02 -0.009673473 #> 0.6  -0.010823854 -0.0107843606 -0.0103778698 -1.022414e-02 -0.009837887 #> 0.7  -0.010790112 -0.0107958270 -0.0104844349 -1.035080e-02 -0.010033997 #> 0.75 -0.010713786 -0.0107419835 -0.0104791320 -1.035581e-02 -0.010075004 #> 0.85 -0.010532837 -0.0106127010 -0.0104586424 -1.035990e-02 -0.010157678 #> 1    -0.010012783 -0.0101652247 -0.0102191542 -1.016276e-02 -0.010112849 #> 1.05 -0.009815097 -0.0099959249 -0.0101159073 -1.007674e-02 -0.010071811 #> 1.3  -0.008228907 -0.0085545058 -0.0090902419 -9.145021e-03 -0.009435816 #> 1.35 -0.007818419 -0.0081753308 -0.0088026692 -8.880265e-03 -0.009234536 #> 1.4  -0.007368289 -0.0077576652 -0.0084820364 -8.582588e-03 -0.009004062 #> 1.8  -0.002329388 -0.0030101119 -0.0046563082 -4.993678e-03 -0.006042355 #> 1.85 -0.001583937 -0.0023149950 -0.0040925278 -4.473437e-03 -0.005605771 #> 2     0.001179550  0.0003300838 -0.0018606565 -2.350711e-03 -0.003757382 #> 2.05  0.002118385  0.0012191104 -0.0011280037 -1.664204e-03 -0.003169898 #> 2.15  0.004265277  0.0032724151  0.0006247123 -2.036655e-06 -0.001700348 #> 2.35  0.009133592  0.0079393593  0.0046479064  3.820692e-03  0.001716153 #> 2.5   0.013304115  0.0119452302  0.0081338742  7.135720e-03  0.004712192 #> 2.6   0.016327934  0.0148545720  0.0106848142  9.563429e-03  0.006923454 #> 2.7   0.019637146  0.0180416189  0.0135065251  1.224141e-02  0.009360978 #> 2.9   0.026929613  0.0250866239  0.0197732236  1.825256e-02  0.014923562 #> 2.95  0.028588645  0.0266624740  0.0211094115  1.952568e-02  0.016089688 #> 3     0.030632586  0.0286472733  0.0229304172  2.125408e-02  0.017703207 #> 3.05  0.032699395  0.0306397731  0.0246947108  2.293872e-02  0.019241287 #> 3.2   0.039230133  0.0369654722  0.0303953767  2.840862e-02  0.024350034 #> 3.35  0.046402158  0.0439256452  0.0367145620  3.448701e-02  0.030055442 #> 3.5   0.054075958  0.0513814779  0.0435193558  4.104653e-02  0.036235753 #> 3.55  0.056797978  0.0540298670  0.0459390395  4.338072e-02  0.038430615 #> 3.65  0.062342332  0.0594325772  0.0509190951  4.819900e-02  0.043008152 #> 3.7   0.065349850  0.0623863898  0.0536633523  5.087785e-02  0.045556179 #> 3.8   0.071203707  0.0680803745  0.0589107072  5.594262e-02  0.050363101 #> 3.9   0.077282543  0.0740053546  0.0644047924  6.126949e-02  0.055437554 #> 4.05  0.087310150  0.0838319414  0.0736091863  7.023865e-02  0.064028455 #> 4.1   0.090440921  0.0868751812  0.0764274617  7.298185e-02  0.066631263 #> 4.15  0.094032694  0.0904135654  0.0797720130  7.624836e-02  0.069777590 #> 4.2   0.097573242  0.0938876990  0.0830308216  7.943824e-02  0.072838142 #> 4.4   0.112233007  0.1082859772  0.0966714531  9.277099e-02  0.085678145 #> 4.55  0.123856787  0.1197151316  0.1075532872  1.034350e-01  0.095984430 #> 4.6   0.127829102  0.1236211602  0.1112881790  1.071270e-01  0.099575559 #> 4.85  0.148307698  0.1438357969  0.1307242261  1.262658e-01  0.118195564 #> 4.9   0.152548357  0.1480407543  0.1348301243  1.303269e-01  0.122181621 #> 4.95  0.156891620  0.1523155977  0.1389386926  1.343694e-01  0.126110954 #> 5     0.160921429  0.1562993235  0.1428009068  1.381785e-01  0.129875330 #> 5.05  0.165496582  0.1608316645  0.1472386734  1.425751e-01  0.134167296 #> 5.3   0.187383548  0.1825143456  0.1684179875  1.635447e-01  0.154762928 #> 5.4   0.196460835  0.1915399713  0.1773086331  1.723774e-01  0.163475111 #> 5.6   0.214645484  0.2096652728  0.1952387065  1.902091e-01  0.181121102 #> 5.65  0.218795994  0.2137553515  0.1992870924  1.942593e-01  0.185166207 #> 5.75  0.227878614  0.2228176355  0.2083826040  2.033175e-01  0.194178107 #> 6.1   0.259801068  0.2548624230  0.2406011027  2.355726e-01  0.226389438 #> 6.15  0.264186120  0.2592118873  0.2450192730  2.400303e-01  0.230822390 #> 6.2   0.268339358  0.2634059613  0.2492996839  2.443127e-01  0.235178634 #> 6.4   0.285703946  0.2809380545  0.2672455756  2.623911e-01  0.253417759 #> 6.6   0.302951298  0.2984514052  0.2853444046  2.806786e-01  0.271904432 #> 6.65  0.307181633  0.3027736830  0.2897596118  2.851872e-01  0.276463480 #> 6.9   0.327088471  0.3230847837  0.3110998552  3.069319e-01  0.298676168 #> 6.95  0.330986764  0.3270834455  0.3153293051  3.112559e-01  0.303103044 #> 7.1   0.342406765  0.3389121990  0.3278394421  3.240963e-01  0.316207293 #> 7.15  0.346024596  0.3426592459  0.3318388581  3.282130e-01  0.320427601 #> 7.3   0.356556832  0.3536042111  0.3436461843  3.403900e-01  0.332999243 #> 7.7   0.381016260  0.3793832011  0.3722702411  3.701763e-01  0.364222996 #> 7.8   0.386227861  0.3848946041  0.3785697454  3.767384e-01  0.371186385 #> 7.85  0.388710368  0.3875573127  0.3815755858  3.799646e-01  0.374509749 #> 7.9   0.391086205  0.3900906895  0.3845935143  3.831344e-01  0.377966728 #> 8     0.394794771  0.3941516676  0.3895041721  3.883677e-01  0.383653084 #> 8.05  0.396995019  0.3965220619  0.3924062160  3.914332e-01  0.387034950 #> 8.25  0.403303379  0.4035363329  0.4013466025  4.010319e-01  0.397745098 #> 8.35  0.405549451  0.4060897696  0.4049509345  4.050653e-01  0.402322386 #> 8.5   0.407891798  0.4081850782  0.4086387546  4.092677e-01  0.407477471 #> 8.55  0.408185078  0.4103830681  0.4103314796  4.109549e-01  0.409605461 #> 8.7   0.408638755  0.4103314796  0.4139836795  4.141160e-01  0.413998011 #> 8.75  0.409267676  0.4109549058  0.4141160120  4.161379e-01  0.415482985 #> 8.85  0.407477471  0.4096054615  0.4139980106  4.154830e-01  0.417524557 #> 8.95  0.405852763  0.4082511478  0.4138157781  4.155066e-01  0.417348217 #> 9.3   0.394081090  0.3972288570  0.4066879335  4.091570e-01  0.414086195 #> 9.4   0.389405416  0.3927391459  0.4032542435  4.059032e-01  0.411687501 #> 9.45  0.386940926  0.3903657052  0.4014201941  4.041575e-01  0.410380616 #> 9.65  0.374563042  0.3782525308  0.3912411135  3.942393e-01  0.402143482 #> 9.7   0.371595785  0.3753647339  0.3888295911  3.919042e-01  0.400205324 #>               8.95           9.3           9.4          9.45          9.65 #> 0.1  -7.695091e-03 -0.0054651091 -0.0047561561 -4.387410e-03 -0.0030137736 #> 0.3  -8.457286e-03 -0.0063587116 -0.0056795090 -5.321836e-03 -0.0039886737 #> 0.45 -8.974636e-03 -0.0069966860 -0.0063444594 -5.996719e-03 -0.0046993959 #> 0.55 -9.211989e-03 -0.0073388584 -0.0067118290 -6.374761e-03 -0.0051132270 #> 0.6  -9.405699e-03 -0.0076100514 -0.0070005568 -6.670899e-03 -0.0054366856 #> 0.7  -9.654922e-03 -0.0080148644 -0.0074429284 -7.130033e-03 -0.0059535356 #> 0.75 -9.723525e-03 -0.0081629884 -0.0076125154 -7.309984e-03 -0.0061667926 #> 0.85 -9.867336e-03 -0.0084813976 -0.0079718047 -7.686980e-03 -0.0066058752 #> 1    -9.941693e-03 -0.0089261055 -0.0085097906 -8.269668e-03 -0.0073394175 #> 1.05 -9.938083e-03 -0.0090310188 -0.0086409583 -8.412783e-03 -0.0075242778 #> 1.3  -9.542302e-03 -0.0093813312 -0.0091819551 -9.046303e-03 -0.0084719072 #> 1.35 -9.394216e-03 -0.0093940903 -0.0092352425 -9.119082e-03 -0.0086108759 #> 1.4  -9.219854e-03 -0.0093985559 -0.0092860669 -9.192726e-03 -0.0087629938 #> 1.8  -6.798908e-03 -0.0086733572 -0.0089985123 -9.120817e-03 -0.0094296714 #> 1.85 -6.442634e-03 -0.0085651987 -0.0089567484 -9.112073e-03 -0.0095357969 #> 2    -4.836313e-03 -0.0077293772 -0.0083189390 -8.572183e-03 -0.0093353270 #> 2.05 -4.339459e-03 -0.0075153517 -0.0081667227 -8.448116e-03 -0.0093166060 #> 2.15 -3.049767e-03 -0.0067929382 -0.0075962691 -7.953314e-03 -0.0090858483 #> 2.35 -1.932584e-05 -0.0049815043 -0.0061075960 -6.625560e-03 -0.0083222046 #> 2.5   2.664806e-03 -0.0032727252 -0.0046510494 -5.293073e-03 -0.0074303077 #> 2.6   4.659170e-03 -0.0019522749 -0.0035047195 -4.232084e-03 -0.0066757086 #> 2.7   6.846881e-03 -0.0005149568 -0.0022681788 -3.094477e-03 -0.0059011551 #> 2.9   1.196001e-02  0.0031433180  0.0009889552 -3.883751e-05 -0.0035511934 #> 2.95  1.302767e-02  0.0038649867  0.0016620146  6.175998e-04 -0.0029664990 #> 3     1.450286e-02  0.0049778231  0.0026754108  1.583078e-03 -0.0021881638 #> 3.05  1.589477e-02  0.0059078734  0.0034862149  2.334823e-03 -0.0016481777 #> 3.2   2.062225e-02  0.0094244688  0.0066849759  5.377725e-03  0.0008227809 #> 3.35  2.592949e-02  0.0134706730  0.0104001261  8.930561e-03  0.0037772297 #> 3.5   3.170428e-02  0.0179478317  0.0145370068  1.290088e-02  0.0071271473 #> 3.55  3.375124e-02  0.0195126246  0.0159707758  1.426890e-02  0.0082560397 #> 3.65  3.806735e-02  0.0229896756  0.0192278234  1.741851e-02  0.0110034501 #> 3.7   4.048428e-02  0.0249423879  0.0210537157  1.918059e-02  0.0125241523 #> 3.8   4.500327e-02  0.0285576150  0.0244299394  2.243946e-02  0.0153494666 #> 3.9   4.980311e-02  0.0324530200  0.0280984194  2.599810e-02  0.0184811204 #> 4.05  5.798110e-02  0.0392344614  0.0344774901  3.217358e-02  0.0238987835 #> 4.1   6.044410e-02  0.0412051187  0.0363223480  3.395690e-02  0.0254457024 #> 4.15  6.345507e-02  0.0437559863  0.0387371792  3.630221e-02  0.0275277876 #> 4.2   6.638278e-02  0.0462028079  0.0410517372  3.855005e-02  0.0295243447 #> 4.4   7.867651e-02  0.0566119792  0.0509222763  4.814856e-02  0.0380707776 #> 4.55  8.858434e-02  0.0650900723  0.0589842816  5.599897e-02  0.0450970668 #> 4.6   9.207783e-02  0.0681675845  0.0619440486  5.889956e-02  0.0477643609 #> 4.85  1.101221e-01  0.0840334214  0.0771620488  7.378523e-02  0.0613373049 #> 4.9   1.140203e-01  0.0875974675  0.0806220830  7.719209e-02  0.0645224185 #> 4.95  1.178213e-01  0.0908938482  0.0837588586  8.024646e-02  0.0672510871 #> 5     1.215133e-01  0.0942500298  0.0870085909  8.344243e-02  0.0702114803 #> 5.05  1.256962e-01  0.0979991826  0.0906245225  8.698815e-02  0.0734789695 #> 5.3   1.458563e-01  0.1163622047  0.1084124013  1.044775e-01  0.0897417895 #> 5.4   1.544238e-01  0.1242797462  0.1161102146  1.120600e-01  0.0968338105 #> 5.6   1.718316e-01  0.1405935363  0.1320356160  1.277795e-01  0.1116758003 #> 5.65  1.758701e-01  0.1444522517  0.1358371419  1.315515e-01  0.1153157514 #> 5.75  1.847952e-01  0.1530134096  0.1442419849  1.398734e-01  0.1232476965 #> 6.1   2.168948e-01  0.1840604696  0.1748248888  1.701992e-01  0.1523683827 #> 6.15  2.213219e-01  0.1883126023  0.1790087153  1.743455e-01  0.1563331820 #> 6.2   2.257168e-01  0.1928271781  0.1835256903  1.788628e-01  0.1608134698 #> 6.4   2.440860e-01  0.2112312371  0.2018317041  1.971060e-01  0.1786598443 #> 6.6   2.627538e-01  0.2301817276  0.2207407121  2.159785e-01  0.1972197373 #> 6.65  2.673933e-01  0.2348080716  0.2253450596  2.205663e-01  0.2017027918 #> 6.9   2.900985e-01  0.2585995316  0.2493021075  2.445881e-01  0.2257349883 #> 6.95  2.946377e-01  0.2633904508  0.2541340294  2.494367e-01  0.2305947793 #> 7.1   3.080787e-01  0.2775823359  0.2684502271  2.637998e-01  0.2450045397 #> 7.15  3.124243e-01  0.2821868796  0.2730971839  2.684643e-01  0.2496675991 #> 7.3   3.254442e-01  0.2962933006  0.2874201976  2.828839e-01  0.2642836254 #> 7.7   3.582336e-01  0.3331506544  0.3251683771  3.210521e-01  0.3034898201 #> 7.8   3.655965e-01  0.3415367294  0.3337812547  3.297727e-01  0.3124671911 #> 7.85  3.691087e-01  0.3454704612  0.3378256799  3.338886e-01  0.3166972441 #> 7.9   3.728430e-01  0.3500792896  0.3426307723  3.387709e-01  0.3218911804 #> 8     3.790100e-01  0.3576082260  0.3504847597  3.467844e-01  0.3303648969 #> 8.05  3.826950e-01  0.3622638633  0.3553270138  3.517001e-01  0.3355929292 #> 8.25  3.945268e-01  0.3774408121  0.3713862081  3.682209e-01  0.3534601150 #> 8.35  3.997351e-01  0.3847125009  0.3791904372  3.762940e-01  0.3624384325 #> 8.5   4.058528e-01  0.3940810900  0.3894054157  3.869409e-01  0.3745630421 #> 8.55  4.082511e-01  0.3972288570  0.3927391459  3.903657e-01  0.3782525308 #> 8.7   4.138158e-01  0.4066879335  0.4032542435  4.014202e-01  0.3912411135 #> 8.75  4.155066e-01  0.4091569570  0.4059032012  4.041575e-01  0.3942392572 #> 8.85  4.173482e-01  0.4140861946  0.4116875009  4.103806e-01  0.4021434816 #> 8.95  4.198468e-01  0.4183150992  0.4166576754  4.157281e-01  0.4089259739 #> 9.3   4.183151e-01  0.4294000693  0.4303322535  4.307861e-01  0.4304759204 #> 9.4   4.166577e-01  0.4303322535  0.4332051919  4.336392e-01  0.4352901445 #> 9.45  4.157281e-01  0.4307860982  0.4336391506  4.359928e-01  0.4376294335 #> 9.65  4.089260e-01  0.4304759204  0.4352901445  4.376294e-01  0.4456506727 #> 9.7   4.073316e-01  0.4303960922  0.4357336833  4.381964e-01  0.4461952884 #>                9.7 #> 0.1  -0.0026195164 #> 0.3  -0.0036049069 #> 0.45 -0.0043245292 #> 0.55 -0.0047487467 #> 0.6  -0.0050776269 #> 0.7  -0.0056093293 #> 0.75 -0.0058335922 #> 0.85 -0.0062874081 #> 1    -0.0070613389 #> 1.05 -0.0072565629 #> 1.3  -0.0082888175 #> 1.35 -0.0084451751 #> 1.4  -0.0086183437 #> 1.8  -0.0094807226 #> 1.85 -0.0096182073 #> 2    -0.0095046432 #> 2.05 -0.0095023779 #> 2.15 -0.0093431320 #> 2.35 -0.0087277320 #> 2.5  -0.0079457674 #> 2.6  -0.0072660209 #> 2.7  -0.0065794582 #> 2.9  -0.0044292593 #> 2.95 -0.0038331037 #> 3    -0.0030957940 #> 3.05 -0.0026062683 #> 3.2  -0.0002741283 #> 3.35  0.0025366387 #> 3.5   0.0057404387 #> 3.55  0.0068083163 #> 3.65  0.0094608761 #> 3.7   0.0109235040 #> 3.8   0.0136436048 #> 3.9   0.0166893616 #> 4.05  0.0219035992 #> 4.1   0.0234002600 #> 4.15  0.0254123095 #> 4.2   0.0273463538 #> 4.4   0.0356330815 #> 4.55  0.0424529204 #> 4.6   0.0450613158 #> 4.85  0.0583033884 #> 4.9   0.0614342300 #> 4.95  0.0640742990 #> 5     0.0669789430 #> 5.05  0.0701747314 #> 5.3   0.0861204317 #> 5.4   0.0930867702 #> 5.6   0.1076942648 #> 5.65  0.1112974797 #> 5.75  0.1191298897 #> 6.1   0.1479298952 #> 6.15  0.1518507812 #> 6.2   0.1563149731 #> 6.4   0.1740522937 #> 6.6   0.1925283307 #> 6.65  0.1969857486 #> 6.9   0.2210191607 #> 6.95  0.2258822837 #> 7.1   0.2403013871 #> 7.15  0.2449719932 #> 7.3   0.2596423261 #> 7.7   0.2991474301 #> 7.8   0.3082050573 #> 7.85  0.3125012431 #> 7.9   0.3177482904 #> 8     0.3263504629 #> 8.05  0.3316049109 #> 8.25  0.3498877899 #> 8.35  0.3590994263 #> 8.5   0.3715957855 #> 8.55  0.3753647339 #> 8.7   0.3888295911 #> 8.75  0.3919042279 #> 8.85  0.4002053236 #> 8.95  0.4073316133 #> 9.3   0.4303960922 #> 9.4   0.4357336833 #> 9.45  0.4381964124 #> 9.65  0.4461952884 #> 9.7   0.4488644211 #>"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/elbo_GP_mod_common_hp_k.html","id":null,"dir":"Reference","previous_headings":"","what":"Penalised elbo for multiple mean GPs with common HPs — elbo_GP_mod_common_hp_k","title":"Penalised elbo for multiple mean GPs with common HPs — elbo_GP_mod_common_hp_k","text":"Penalised elbo multiple mean GPs common HPs","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/elbo_GP_mod_common_hp_k.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Penalised elbo for multiple mean GPs with common HPs — elbo_GP_mod_common_hp_k","text":"","code":"elbo_GP_mod_common_hp_k(hp, db, mean, kern, post_cov, pen_diag = NULL)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/elbo_GP_mod_common_hp_k.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Penalised elbo for multiple mean GPs with common HPs — elbo_GP_mod_common_hp_k","text":"hp tibble, data frame named vector containing hyper-parameters. db tibble containing values want compute elbo . Required columns: Input, Output. Additional covariate columns allowed. mean list K mean GPs union observed timestamps. kern kernel function used compute covariance matrix corresponding timestamps. post_cov List K posterior covariance mean GP (mu_k). Used compute correction term (cor_term). pen_diag jitter term added covariance matrix avoid numerical issues inverting, cases nearly singular matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/elbo_GP_mod_common_hp_k.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Penalised elbo for multiple mean GPs with common HPs — elbo_GP_mod_common_hp_k","text":"value penalised Gaussian elbo sum k mean GPs common HPs.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/elbo_GP_mod_common_hp_k.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Penalised elbo for multiple mean GPs with common HPs — elbo_GP_mod_common_hp_k","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/elbo_clust_multi_GP.html","id":null,"dir":"Reference","previous_headings":"","what":"Evidence Lower Bound for a mixture of GPs — elbo_clust_multi_GP","title":"Evidence Lower Bound for a mixture of GPs — elbo_clust_multi_GP","text":"Evidence Lower Bound mixture GPs","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/elbo_clust_multi_GP.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evidence Lower Bound for a mixture of GPs — elbo_clust_multi_GP","text":"","code":"elbo_clust_multi_GP(hp, db, hyperpost, kern, pen_diag)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/elbo_clust_multi_GP.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evidence Lower Bound for a mixture of GPs — elbo_clust_multi_GP","text":"hp tibble, data frame named vector containing hyper-parameters. db tibble containing values want compute elbo . Required columns: Input, Output. Additional covariate columns allowed. hyperpost List parameters K mean GPs. kern kernel function used compute covariance matrix corresponding timestamps. pen_diag jitter term added covariance matrix avoid numerical issues inverting, cases nearly singular matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/elbo_clust_multi_GP.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evidence Lower Bound for a mixture of GPs — elbo_clust_multi_GP","text":"value penalised Gaussian elbo mixture GPs","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/elbo_clust_multi_GP.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Evidence Lower Bound for a mixture of GPs — elbo_clust_multi_GP","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/elbo_clust_multi_GP_common_hp_i.html","id":null,"dir":"Reference","previous_headings":"","what":"Penalised elbo for multiple individual GPs with common HPs — elbo_clust_multi_GP_common_hp_i","title":"Penalised elbo for multiple individual GPs with common HPs — elbo_clust_multi_GP_common_hp_i","text":"Penalised elbo multiple individual GPs common HPs","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/elbo_clust_multi_GP_common_hp_i.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Penalised elbo for multiple individual GPs with common HPs — elbo_clust_multi_GP_common_hp_i","text":"","code":"elbo_clust_multi_GP_common_hp_i(hp, db, hyperpost, kern, pen_diag)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/elbo_clust_multi_GP_common_hp_i.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Penalised elbo for multiple individual GPs with common HPs — elbo_clust_multi_GP_common_hp_i","text":"hp tibble, data frame named vector containing hyper-parameters. db tibble containing values want compute elbo . Required columns: Input, Output. Additional covariate columns allowed. hyperpost List parameters K mean Gaussian processes. kern kernel function used compute covariance matrix corresponding timestamps. pen_diag jitter term added covariance matrix avoid numerical issues inverting, cases nearly singular matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/elbo_clust_multi_GP_common_hp_i.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Penalised elbo for multiple individual GPs with common HPs — elbo_clust_multi_GP_common_hp_i","text":"value penalised Gaussian elbo sum M individual GPs common HPs.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/elbo_clust_multi_GP_common_hp_i.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Penalised elbo for multiple individual GPs with common HPs — elbo_clust_multi_GP_common_hp_i","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/elbo_monitoring_VEM.html","id":null,"dir":"Reference","previous_headings":"","what":"Evidence Lower Bound maximised in MagmaClust — elbo_monitoring_VEM","title":"Evidence Lower Bound maximised in MagmaClust — elbo_monitoring_VEM","text":"Evidence Lower Bound maximised MagmaClust","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/elbo_monitoring_VEM.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evidence Lower Bound maximised in MagmaClust — elbo_monitoring_VEM","text":"","code":"elbo_monitoring_VEM(hp_k, hp_i, db, kern_i, kern_k, hyperpost, m_k, pen_diag)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/elbo_monitoring_VEM.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evidence Lower Bound maximised in MagmaClust — elbo_monitoring_VEM","text":"hp_k tibble, data frame named vector hyper-parameters clusters. hp_i tibble, data frame named vector hyper-parameters individuals. db tibble containing values want compute elbo . Required columns: Input, Output. Additional covariate columns allowed. kern_i Kernel used compute covariance matrix individuals GPs corresponding inputs. kern_k Kernel used compute covariance matrix mean GPs corresponding inputs. hyperpost list parameters variational distributions K mean GPs. m_k Prior value mean parameter mean GPs (mu_k). Length = 1 nrow(db). pen_diag jitter term added covariance matrix avoid numerical issues inverting, cases nearly singular matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/elbo_monitoring_VEM.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evidence Lower Bound maximised in MagmaClust — elbo_monitoring_VEM","text":"Value elbo maximised VEM algorithm used training MagmaClust.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/elbo_monitoring_VEM.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Evidence Lower Bound maximised in MagmaClust — elbo_monitoring_VEM","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_GP.html","id":null,"dir":"Reference","previous_headings":"","what":"Gradient of the logLikelihood of a Gaussian Process — gr_GP","title":"Gradient of the logLikelihood of a Gaussian Process — gr_GP","text":"Gradient logLikelihood Gaussian Process","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_GP.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gradient of the logLikelihood of a Gaussian Process — gr_GP","text":"","code":"gr_GP(hp, db, mean, kern, post_cov, pen_diag)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_GP.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gradient of the logLikelihood of a Gaussian Process — gr_GP","text":"hp tibble, data frame named vector containing hyper-parameters. db tibble containing values want compute logL . Required columns: Input, Output. Additional covariate columns allowed. mean vector, specifying mean GP reference inputs. kern kernel function. post_cov (optional) matrix, corresponding covariance parameter hyper-posterior. Used compute hyper-prior distribution new individual Magma. pen_diag jitter term added covariance matrix avoid numerical issues inverting, cases nearly singular matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_GP.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gradient of the logLikelihood of a Gaussian Process — gr_GP","text":"named vector, corresponding value hyper-parameters gradients Gaussian log-Likelihood (covariance can sum individual hyper-posterior's mean process covariances).","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_GP.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gradient of the logLikelihood of a Gaussian Process — gr_GP","text":"","code":"db <- tibble::tibble(Input = 1:5, Output = 2:6) mean <- rep(0, 5) hp <- tibble::tibble(se_variance = 1, se_lengthscale = 0.5) post_cov <- kern_to_cov(1:5, \"SE\", hp) MagmaClustR:::gr_GP(hp, db, mean, \"SE\", post_cov, 0.001) #>    se_variance se_lengthscale  #>     -0.8468554     -1.5165957"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_GP_mod.html","id":null,"dir":"Reference","previous_headings":"","what":"Gradient of the modified logLikelihood for GPs in Magma — gr_GP_mod","title":"Gradient of the modified logLikelihood for GPs in Magma — gr_GP_mod","text":"Gradient modified logLikelihood GPs Magma","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_GP_mod.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gradient of the modified logLikelihood for GPs in Magma — gr_GP_mod","text":"","code":"gr_GP_mod(hp, db, mean, kern, post_cov, pen_diag)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_GP_mod.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gradient of the modified logLikelihood for GPs in Magma — gr_GP_mod","text":"hp tibble, data frame named vector containing hyper-parameters. db tibble containing values want compute logL . Required columns: Input, Output. Additional covariate columns allowed. mean vector, specifying mean GPs reference inputs. kern kernel function. post_cov matrix, covariance parameter hyper-posterior. Used compute correction term. pen_diag jitter term added covariance matrix avoid numerical issues inverting, cases nearly singular matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_GP_mod.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gradient of the modified logLikelihood for GPs in Magma — gr_GP_mod","text":"named vector, corresponding value hyper-parameters gradients modified Gaussian log-Likelihood involved Magma.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_GP_mod.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gradient of the modified logLikelihood for GPs in Magma — gr_GP_mod","text":"","code":"db <- tibble::tibble(Input = 1:5, Output = 2:6) mean <- rep(0, 5) hp <- tibble::tibble(se_variance = 1, se_lengthscale = 0.5) post_cov <- kern_to_cov(1:5, \"SE\", hp) MagmaClustR:::gr_GP_mod(hp, db, mean, \"SE\", post_cov, 0.001) #>    se_variance se_lengthscale  #>      -8.358967      -0.746123"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_GP_mod_common_hp.html","id":null,"dir":"Reference","previous_headings":"","what":"Gradient of the modified logLikelihood with common HPs for GPs in Magma — gr_GP_mod_common_hp","title":"Gradient of the modified logLikelihood with common HPs for GPs in Magma — gr_GP_mod_common_hp","text":"Gradient modified logLikelihood common HPs GPs Magma","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_GP_mod_common_hp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gradient of the modified logLikelihood with common HPs for GPs in Magma — gr_GP_mod_common_hp","text":"","code":"gr_GP_mod_common_hp(hp, db, mean, kern, post_cov, pen_diag)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_GP_mod_common_hp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gradient of the modified logLikelihood with common HPs for GPs in Magma — gr_GP_mod_common_hp","text":"hp tibble data frame containing hyper-parameters individuals. db tibble containing values want compute logL . Required columns: ID, Input, Output. Additional covariate columns allowed. mean vector, specifying mean GPs reference inputs. kern kernel function. post_cov matrix, covariance parameter hyper-posterior. Used compute correction term. pen_diag jitter term added covariance matrix avoid numerical issues inverting, cases nearly singular matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_GP_mod_common_hp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gradient of the modified logLikelihood with common HPs for GPs in Magma — gr_GP_mod_common_hp","text":"named vector, corresponding value hyper-parameters' gradients modified Gaussian log-Likelihood involved Magma 'common HP' setting.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_GP_mod_common_hp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gradient of the modified logLikelihood with common HPs for GPs in Magma — gr_GP_mod_common_hp","text":"","code":"db <- simu_db(N = 10, common_input = TRUE) mean <- tibble::tibble(Input = unique(db$Input), Output = 0) hp <- tibble::tibble(se_variance = 1, se_lengthscale = 0.5) post_cov <- kern_to_cov(unique(db$Input), \"SE\", hp) MagmaClustR:::gr_GP_mod_common_hp(hp, db, mean, \"SE\", post_cov, 0.001) #>    se_variance se_lengthscale  #>      -20667.15       68565.82"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_GP_mod_common_hp_k.html","id":null,"dir":"Reference","previous_headings":"","what":"Gradient of the penalised elbo for multiple mean GPs with common HPs — gr_GP_mod_common_hp_k","title":"Gradient of the penalised elbo for multiple mean GPs with common HPs — gr_GP_mod_common_hp_k","text":"Gradient penalised elbo multiple mean GPs common HPs","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_GP_mod_common_hp_k.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gradient of the penalised elbo for multiple mean GPs with common HPs — gr_GP_mod_common_hp_k","text":"","code":"gr_GP_mod_common_hp_k(hp, db, mean, kern, post_cov, pen_diag = NULL)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_GP_mod_common_hp_k.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gradient of the penalised elbo for multiple mean GPs with common HPs — gr_GP_mod_common_hp_k","text":"hp tibble, data frame named vector containing hyper-parameters. db tibble containing values want compute elbo . Required columns: Input, Output. Additional covariate columns allowed. mean list k means GPs union observed timestamps. kern kernel function post_cov list k posterior covariance mean GP (mu_k). Used compute correction term (cor_term) pen_diag jitter term added covariance matrix avoid numerical issues inverting, cases nearly singular matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_GP_mod_common_hp_k.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gradient of the penalised elbo for multiple mean GPs with common HPs — gr_GP_mod_common_hp_k","text":"gradient penalised Gaussian elbo sum k mean GPs common HPs.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_GP_mod_common_hp_k.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gradient of the penalised elbo for multiple mean GPs with common HPs — gr_GP_mod_common_hp_k","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_clust_multi_GP.html","id":null,"dir":"Reference","previous_headings":"","what":"Gradient of the elbo for a mixture of GPs — gr_clust_multi_GP","title":"Gradient of the elbo for a mixture of GPs — gr_clust_multi_GP","text":"Gradient elbo mixture GPs","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_clust_multi_GP.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gradient of the elbo for a mixture of GPs — gr_clust_multi_GP","text":"","code":"gr_clust_multi_GP(hp, db, hyperpost, kern, pen_diag)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_clust_multi_GP.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gradient of the elbo for a mixture of GPs — gr_clust_multi_GP","text":"hp tibble, data frame named vector containing hyper-parameters. db tibble containing values want compute elbo . Required columns: Input, Output. Additional covariate columns allowed. hyperpost List parameters K mean Gaussian processes. kern kernel function. pen_diag jitter term added covariance matrix avoid numerical issues inverting, cases nearly singular matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_clust_multi_GP.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gradient of the elbo for a mixture of GPs — gr_clust_multi_GP","text":"gradient penalised Gaussian elbo mixture GPs","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_clust_multi_GP.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gradient of the elbo for a mixture of GPs — gr_clust_multi_GP","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_clust_multi_GP_common_hp_i.html","id":null,"dir":"Reference","previous_headings":"","what":"Gradient of the penalised elbo for multiple individual GPs with common HPs — gr_clust_multi_GP_common_hp_i","title":"Gradient of the penalised elbo for multiple individual GPs with common HPs — gr_clust_multi_GP_common_hp_i","text":"Gradient penalised elbo multiple individual GPs common HPs","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_clust_multi_GP_common_hp_i.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gradient of the penalised elbo for multiple individual GPs with common HPs — gr_clust_multi_GP_common_hp_i","text":"","code":"gr_clust_multi_GP_common_hp_i(hp, db, hyperpost, kern, pen_diag = NULL)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_clust_multi_GP_common_hp_i.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gradient of the penalised elbo for multiple individual GPs with common HPs — gr_clust_multi_GP_common_hp_i","text":"hp tibble, data frame name vector hyper-parameters. db tibble containing values want compute elbo . Required columns: Input, Output. Additional covariate columns allowed. hyperpost List parameters K mean Gaussian processes. kern kernel function used compute covariance matrix corresponding timestamps. pen_diag jitter term added covariance matrix avoid numerical issues inverting, cases nearly singular matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_clust_multi_GP_common_hp_i.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gradient of the penalised elbo for multiple individual GPs with common HPs — gr_clust_multi_GP_common_hp_i","text":"gradient penalised Gaussian elbo sum M individual GPs common HPs.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_clust_multi_GP_common_hp_i.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gradient of the penalised elbo for multiple individual GPs with common HPs — gr_clust_multi_GP_common_hp_i","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_sum_logL_GP_clust.html","id":null,"dir":"Reference","previous_headings":"","what":"Gradient of the mixture of Gaussian likelihoods — gr_sum_logL_GP_clust","title":"Gradient of the mixture of Gaussian likelihoods — gr_sum_logL_GP_clust","text":"Compute gradient sum Gaussian log-likelihoods, weighted mixture probabilities.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_sum_logL_GP_clust.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gradient of the mixture of Gaussian likelihoods — gr_sum_logL_GP_clust","text":"","code":"gr_sum_logL_GP_clust(hp, db, mixture, mean, kern, post_cov, pen_diag)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_sum_logL_GP_clust.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gradient of the mixture of Gaussian likelihoods — gr_sum_logL_GP_clust","text":"hp tibble, data frame named vector hyper-parameters. db tibble containing data want evaluate logL . Required columns: Input, Output. Additional covariate columns allowed. mixture tibble data frame, indicating mixture probabilities cluster new individual/task. mean list hyper-posterior mean parameters clusters. kern kernel function. post_cov list hyper-posterior covariance parameters clusters. pen_diag jitter term added covariance matrix avoid numerical issues inverting, cases nearly singular matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_sum_logL_GP_clust.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gradient of the mixture of Gaussian likelihoods — gr_sum_logL_GP_clust","text":"named vector, corresponding value hyper-parameters' gradients mixture Gaussian log-likelihoods involved prediction step MagmaClust.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_sum_logL_GP_clust.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gradient of the mixture of Gaussian likelihoods — gr_sum_logL_GP_clust","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/hp.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate random hyper-parameters — hp","title":"Generate random hyper-parameters — hp","text":"Generate set random hyper-parameters, specific chosen type kernel, format used Magma.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/hp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate random hyper-parameters — hp","text":"","code":"hp(kern = \"SE\", list_ID = NULL, list_hp = NULL, noise = F, common_hp = F)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/hp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate random hyper-parameters — hp","text":"kern function, character string indicating chosen type kernel among: \"SE\": Squared Exponential kernel, \"LIN\": Linear kernel, \"PERIO\": Periodic kernel, \"RQ\": Rational Quadratic kernel. Compound kernels can created sums products kernels. combining kernels, simply provide formula character string elements separated whitespaces (e.g. \"SE + PERIO\"). elements treated sequentially left right, product operator '*' shall always used '+' operators (e.g. 'SE * LIN + RQ' valid whereas 'RQ + SE * LIN'  ). case custom kernel function, argument list_hp provided well, designing tibble correct names hyper-parameters. list_ID vector, associating ID value individual hyper-parameters generated. NULL (default) one set hyper-parameters return without ID column. list_hp vector characters, providing name hyper-parameter, case kern custom kernel function. noise logical value, indicating whether 'noise' hyper-parameter included. common_hp logical value, indicating whether set hyper-parameters assumed common indiviuals.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/hp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate random hyper-parameters — hp","text":"tibble, providing set random hyper-parameters associated kernel specified argument kern.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/hp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate random hyper-parameters — hp","text":"","code":"hp(\"PERIO\") #> # A tibble: 1 × 3 #>   perio_variance perio_lengthscale period #>            <dbl>             <dbl>  <dbl> #> 1           2.72              1.89   3.22 hp(MagmaClustR:::se_kernel, 1:5, c(\"var\", \"lengthsc\"), TRUE) #> # A tibble: 5 × 4 #>   ID      var lengthsc  noise #>   <chr> <dbl>    <dbl>  <dbl> #> 1 1     0.344   0.420  -1.28  #> 2 2     1.66    0.502  -1.72  #> 3 3     1.39    1.18   -1.71  #> 4 4     2.29    0.0732 -0.386 #> 5 5     2.29    1.46   -0.254"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/hyperposterior.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the hyper-posterior distribution in Magma — hyperposterior","title":"Compute the hyper-posterior distribution in Magma — hyperposterior","text":"Compute parameters hyper-posterior Gaussian distribution mean process Magma (similarly expectation step EM algorithm used learning). hyper-posterior distribution, evaluated grid inputs provided grid_inputs argument, key component making prediction Magma, required function pred_magma.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/hyperposterior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the hyper-posterior distribution in Magma — hyperposterior","text":"","code":"hyperposterior(   data,   hp_0,   hp_i,   kern_0,   kern_i,   prior_mean = NULL,   grid_inputs = NULL,   pen_diag = 1e-08 )"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/hyperposterior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the hyper-posterior distribution in Magma — hyperposterior","text":"data tibble data frame. Required columns: 'Input', 'Output'. Additional columns covariates can specified. 'Input' column define variable used reference observations (e.g. time longitudinal data). 'Output' column specifies observed values (response variable). data frame can also provide many covariates desired, constraints column names. covariates additional inputs (explanatory variables) models also observed reference 'Input'. hp_0 named vector, tibble data frame hyper-parameters associated kern_0. hp_i tibble data frame hyper-parameters associated kern_i. kern_0 kernel function, associated mean GP. Several popular kernels (see Kernel Cookbook) already implemented can selected within following list: \"SE\": (default value) Squared Exponential Kernel (also called Radial Basis Function Gaussian kernel), \"LIN\": Linear kernel, \"PERIO\": Periodic kernel, \"RQ\": Rational Quadratic kernel. Compound kernels can created sums products kernels. combining kernels, simply provide formula character string elements separated whitespaces (e.g. \"SE + PERIO\"). elements treated sequentially left right, product operator '*' shall always used '+' operators (e.g. 'SE * LIN + RQ' valid whereas 'RQ + SE * LIN'  ). kern_i kernel function, associated individual GPs. (\"SE\", \"PERIO\" \"RQ\" aso available ) prior_mean Hyper-prior mean parameter mean GP. argument, can specified various formats, : NULL (default). hyper-prior mean set 0 everywhere. number. hyper-prior mean constant function. vector length distinct Input values data argument. vector considered evaluation hyper-prior mean function training Inputs. function. function defined hyper-prior mean. tibble data frame. Required columns: Input, Output. Input values include least values data argument. grid_inputs vector, indicating grid additional reference inputs mean process' hyper-posterior evaluated. pen_diag number. jitter term, added diagonal prevent numerical issues inverting nearly singular matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/hyperposterior.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the hyper-posterior distribution in Magma — hyperposterior","text":"list gathering parameters mean processes' hyper-posterior distributions, namely: mean: tibble, hyper-posterior mean parameter evaluated training Input. cov: matrix, covariance parameter hyper-posterior distribution mean process. pred: tibble, predicted mean variance Input mean process' hyper-posterior distribution format allows direct visualisation GP prediction.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/hyperposterior.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute the hyper-posterior distribution in Magma — hyperposterior","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/hyperposterior_clust.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the hyper-posterior distribution for each cluster in MagmaClust — hyperposterior_clust","title":"Compute the hyper-posterior distribution for each cluster in MagmaClust — hyperposterior_clust","text":"Recompute E-step VEM algorithm MagmaClust new set reference Input. training completed, can necessary evaluate hyper-posterior distributions mean processes specific locations, want make predictions. process directly implemented pred_magmaclust function user might want use hyperpost_clust tailored control 'hand' prediction procedure.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/hyperposterior_clust.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the hyper-posterior distribution for each cluster in MagmaClust — hyperposterior_clust","text":"","code":"hyperposterior_clust(   data,   mixture,   hp_k,   hp_i,   kern_k,   kern_i,   prior_mean_k = NULL,   grid_inputs = NULL,   pen_diag = 1e-08 )"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/hyperposterior_clust.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the hyper-posterior distribution for each cluster in MagmaClust — hyperposterior_clust","text":"data tibble data frame. Required columns: ID, Input , Output. Additional columns covariates can specified. ID column contains unique names/codes used identify individual/task (batch data). Input column define variable used reference observations (e.g. time longitudinal data). Output column specifies observed values (response variable). data frame can also provide many covariates desired, constraints column names. covariates additional inputs (explanatory variables) models also observed reference Input. mixture tibble data frame, indicating mixture probabilities cluster individual. Required column: ID. hp_k tibble data frame hyper-parameters associated kern_k. hp_i tibble data frame hyper-parameters associated kern_i. kern_k kernel function, associated mean GPs. Several popular kernels (see Kernel Cookbook) already implemented can selected within following list: \"SE\": (default value) Squared Exponential Kernel (also called Radial Basis Function Gaussian kernel), \"LIN\": Linear kernel, \"PERIO\": Periodic kernel, \"RQ\": Rational Quadratic kernel. Compound kernels can created sums products kernels. combining kernels, simply provide formula character string elements separated whitespaces (e.g. \"SE + PERIO\"). elements treated sequentially left right, product operator '*' shall always used '+' operators (e.g. 'SE * LIN + RQ' valid whereas 'RQ + SE * LIN'  ). kern_i kernel function, associated individual GPs. (\"SE\", \"LIN\", PERIO\" \"RQ\" also available ) prior_mean_k set hyper-prior mean parameters (m_k) K mean GPs, one value cluster. cluster. argument can specified various formats, : NULL (default). hyper-prior means set 0 everywhere. numerical vector length number clusters. number associated one cluster, considered hyper-prior mean parameter cluster (.e. constant function Input). list functions. function associated one cluster. functions evaluated Input values, provide specific hyper-prior mean vectors cluster. grid_inputs vector, indicating grid additional reference inputs mean process' hyper-posterior evaluated. pen_diag number. jitter term, added diagonal prevent numerical issues inverting nearly singular matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/hyperposterior_clust.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the hyper-posterior distribution for each cluster in MagmaClust — hyperposterior_clust","text":"list containing parameters mean processes' hyper-posterior distribution, namely: mean: list tibbles containing, cluster, hyper-posterior mean parameters evaluated Input. cov: list matrices containing, cluster, hyper-posterior covariance parameter mean process. mixture: tibble, indicating mixture probabilities cluster individual.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/hyperposterior_clust.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute the hyper-posterior distribution for each cluster in MagmaClust — hyperposterior_clust","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/ini_kmeans.html","id":null,"dir":"Reference","previous_headings":"","what":"ini_kmeans — ini_kmeans","title":"ini_kmeans — ini_kmeans","text":"ini_kmeans","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/ini_kmeans.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ini_kmeans — ini_kmeans","text":"","code":"ini_kmeans(data, k, nstart = 50, summary = F)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/ini_kmeans.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"ini_kmeans — ini_kmeans","text":"data tibble containing common Input associated Output values cluster. k number clusters assumed running kmeans algorithm. nstart number, indicating many re-starts kmeans set. summary boolean, indicating whether want outcome summary","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/ini_kmeans.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"ini_kmeans — ini_kmeans","text":"tibble containing initial clustering obtained kmeans.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/ini_kmeans.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"ini_kmeans — ini_kmeans","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/ini_mixture.html","id":null,"dir":"Reference","previous_headings":"","what":"Mixture initialisation with kmeans — ini_mixture","title":"Mixture initialisation with kmeans — ini_mixture","text":"Provide initial kmeans allocation individuals/tasks dataset definite number clusters, return associated mixture probabilities.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/ini_mixture.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mixture initialisation with kmeans — ini_mixture","text":"","code":"ini_mixture(data, k, name_clust = NULL, nstart = 50)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/ini_mixture.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mixture initialisation with kmeans — ini_mixture","text":"data tibble data frame. Required columns: ID, Input , Output. k number, indicating number clusters. name_clust vector characters. element correspond name one cluster. nstart number restart used underlying kmeans algorithm","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/ini_mixture.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mixture initialisation with kmeans — ini_mixture","text":"tibble indicating ID cluster belongs kmeans initialisation.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/ini_mixture.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mixture initialisation with kmeans — ini_mixture","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/kern_to_cov.html","id":null,"dir":"Reference","previous_headings":"","what":"Create covariance matrix from a kernel — kern_to_cov","title":"Create covariance matrix from a kernel — kern_to_cov","text":"kern_to_cov() creates covariance matrix input values (either scalars vectors) evaluated within kernel function, characterised specified hyper-parameters. matrix finite-dimensional evaluation infinite-dimensional covariance structure GP, defined thanks kernel.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/kern_to_cov.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create covariance matrix from a kernel — kern_to_cov","text":"","code":"kern_to_cov(input, kern = \"SE\", hp, deriv = NULL, input_2 = NULL)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/kern_to_cov.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create covariance matrix from a kernel — kern_to_cov","text":"input vector, matrix, data frame tibble containing inputs one individual. vector, elements used reference, otherwise , one column named 'Input' indicate represents reference (e.g. 'Input' contain timestamps time-series applications). columns considered covariates. column named 'Input', first one used default. kern kernel function. Several popular kernels (see Kernel Cookbook) already implemented can selected within following list: \"SE\": (default value) Squared Exponential Kernel (also called Radial Basis Function Gaussian kernel), \"LIN\": Linear kernel, \"PERIO\": Periodic kernel, \"RQ\": Rational Quadratic kernel. Compound kernels can created sums products kernels. combining kernels, simply provide formula character string elements separated whitespaces (e.g. \"SE + PERIO\"). elements treated sequentially left right, product operator '*' shall always used '+' operators (e.g. 'SE * LIN + RQ' valid whereas 'RQ + SE * LIN'  ). hp list, data frame tibble containing hyper-parameters used kernel. name elements (columns) correspond exactly used kernel definition. hp contains element column 'Noise', value added diagonal covariance matrix. deriv character, indicating according hyper-parameter derivative computed. NULL (default), function simply returns covariance matrix. input_2 (optional) vector, matrix, data frame tibble format input. argument used kernel needs evaluated two different sets inputs, typically resulting non-square matrix.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/kern_to_cov.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create covariance matrix from a kernel — kern_to_cov","text":"covariance matrix, elements evaluations associated kernel pair reference inputs.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/kern_to_cov.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create covariance matrix from a kernel — kern_to_cov","text":"","code":"kern_to_cov(   rbind(c(1, 0, 1), c(2, 1, 2), c(1, 2, 3)),   \"SE\",   tibble::tibble(se_variance = 1, se_lengthscale = 0.5) ) #>           1        2         1 #> 1 2.7182818 1.094398 0.2402386 #> 2 1.0943975 2.718282 1.0943975 #> 1 0.2402386 1.094398 2.7182818"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/kern_to_inv.html","id":null,"dir":"Reference","previous_headings":"","what":"Create inverse of a covariance matrix from a kernel — kern_to_inv","title":"Create inverse of a covariance matrix from a kernel — kern_to_inv","text":"kern_to_inv() creates inverse covariance matrix input values (either scalars vectors) evaluated within kernel function, characterised specified hyper-parameters. matrix finite-dimensional evaluation infinite-dimensional covariance structure GP, defined thanks kernel.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/kern_to_inv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create inverse of a covariance matrix from a kernel — kern_to_inv","text":"","code":"kern_to_inv(input, kern, hp, pen_diag = 0, deriv = NULL)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/kern_to_inv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create inverse of a covariance matrix from a kernel — kern_to_inv","text":"input vector, matrix, data frame tibble containing inputs one individual. vector, elements used reference, otherwise ,one column named 'Input' indicate represents reference (e.g. 'Input' contain timestamps time-series applications). columns considered covariates. column named 'Input', first one used default. kern kernel function. Several popular kernels (see Kernel Cookbook) already implemented can selected within following list: \"SE\": (default value) Squared Exponential Kernel (also called Radial Basis Function Gaussian kernel), \"LIN\": Linear kernel, \"PERIO\": Periodic kernel, \"RQ\": Rational Quadratic kernel. Compound kernels can created sums products kernels. combining kernels, simply provide formula character string elements separated whitespaces (e.g. \"SE + PERIO\"). elements treated sequentially left right, product operator '*' shall always used '+' operators (e.g. 'SE * LIN + RQ' valid whereas 'RQ + SE * LIN'  ). hp list, data frame tibble containing hyper-parameters used kernel. name elements (columns) correspond exactly used kernel definition. pen_diag jitter term added covariance matrix avoid numerical issues inverting, cases nearly singular matrices. deriv character, indicating according hyper-parameter derivative computed. NULL (default), function simply returns inverse covariance matrix.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/kern_to_inv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create inverse of a covariance matrix from a kernel — kern_to_inv","text":"inverse covariance matrix, elements evaluations associated kernel pair reference inputs.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/kern_to_inv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create inverse of a covariance matrix from a kernel — kern_to_inv","text":"","code":"kern_to_inv(   rbind(c(1, 0, 1), c(2, 1, 2), c(1, 2, 3)),   \"SE\",   tibble::tibble(se_variance = 1, se_lengthscale = 0.5) )"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/lin_kernel.html","id":null,"dir":"Reference","previous_headings":"","what":"Linear Kernel — lin_kernel","title":"Linear Kernel — lin_kernel","text":"Linear Kernel","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/lin_kernel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Linear Kernel — lin_kernel","text":"","code":"lin_kernel(x = NULL, y = NULL, hp, deriv = NULL, vectorized = F)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/lin_kernel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Linear Kernel — lin_kernel","text":"x vector (matrix vectorized = T) inputs. y vector (matrix vectorized = T) inputs. hp tibble, data frame named vector, containing kernel's hyperparameters. Required columns: 'lin_slope' 'lin_offset'. deriv character, indicating according hyper-parameter derivative computed. NULL (default), function simply returns evaluation kernel. vectorized logical value, indicating whether function provides vectorized version speeded-calculations. TRUE, x y arguments vector matrix containing inputs kernel evaluated pairs elements. FALSE, x y arguments simply two inputs.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/lin_kernel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Linear Kernel — lin_kernel","text":"scalar, corresponding evaluation kernel.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/lin_kernel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Linear Kernel — lin_kernel","text":"","code":"MagmaClustR:::lin_kernel(   c(1, 0), c(0, 1),   tibble::tibble(lin_slope = 1, lin_offset = 1) ) #>          [,1] #> [1,] 2.718282"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/list_kern_to_cov.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute a covariance matrix for multiple individuals — list_kern_to_cov","title":"Compute a covariance matrix for multiple individuals — list_kern_to_cov","text":"Compute covariance matrices associated individuals database, taking account specific inputs hyper-parameters.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/list_kern_to_cov.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute a covariance matrix for multiple individuals — list_kern_to_cov","text":"","code":"list_kern_to_cov(data, kern, hp, deriv = NULL)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/list_kern_to_cov.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute a covariance matrix for multiple individuals — list_kern_to_cov","text":"data tibble data frame input data. Required column: 'ID'. Suggested column: 'Input' (indicating reference input). kern kernel function. hp tibble data frame, containing hyper-parameters associated individual. deriv character, indicating according hyper-parameter derivative computed. NULL (default), function simply returns list covariance matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/list_kern_to_cov.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute a covariance matrix for multiple individuals — list_kern_to_cov","text":"named list containing inverse covariance matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/list_kern_to_cov.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute a covariance matrix for multiple individuals — list_kern_to_cov","text":"","code":"db <- simu_db(M = 3) hp <- tibble::tibble(ID = unique(db$ID), hp()) MagmaClustR:::list_kern_to_cov(db, \"SE\", hp) #> $`1` #>             0.25       1.05       1.35      3.55      6.35      6.55       6.9 #> 0.25 11.42924067 11.0516887 10.7259446  6.453286  1.621135  1.423272  1.121941 #> 1.05 11.05168869 11.4292407 11.3753780  8.232832  2.616427  2.335994  1.896352 #> 1.35 10.72594463 11.3753780 11.4292407  8.865231  3.077123  2.764670  2.269225 #> 3.55  6.45328631  8.2328322  8.8652313 11.429241  7.573652  7.126287  6.341641 #> 6.35  1.62113509  2.6164273  3.0771234  7.573652 11.429241 11.405270 11.249207 #> 6.55  1.42327184  2.3359939  2.7646701  7.126287 11.405270 11.429241 11.355990 #> 6.9   1.12194090  1.8963520  2.2692248  6.341641 11.249207 11.355990 11.429241 #> 8.65  0.28158489  0.5512950  0.6970714  2.918247  8.658295  9.067590  9.732132 #> 9.8   0.09529402  0.2054863  0.2694044  1.470929  6.119291  6.565174  7.350422 #> 9.85  0.09062323  0.1962368  0.2576831  1.423272  6.008691  6.453286  7.238437 #>            8.65         9.8        9.85 #> 0.25  0.2815849  0.09529402  0.09062323 #> 1.05  0.5512950  0.20548634  0.19623679 #> 1.35  0.6970714  0.26940437  0.25768312 #> 3.55  2.9182471  1.47092881  1.42327184 #> 6.35  8.6582947  6.11929089  6.00869101 #> 6.55  9.0675900  6.56517433  6.45328631 #> 6.9   9.7321322  7.35042214  7.23843658 #> 8.65 11.4292407 10.66279660 10.59723888 #> 9.8  10.6627966 11.42924067 11.42774105 #> 9.85 10.5972389 11.42774105 11.42924067 #>  #> $`2` #>             0.25       1.05       1.35      3.55      6.35      6.55       6.9 #> 0.25 11.42924067 11.0516887 10.7259446  6.453286  1.621135  1.423272  1.121941 #> 1.05 11.05168869 11.4292407 11.3753780  8.232832  2.616427  2.335994  1.896352 #> 1.35 10.72594463 11.3753780 11.4292407  8.865231  3.077123  2.764670  2.269225 #> 3.55  6.45328631  8.2328322  8.8652313 11.429241  7.573652  7.126287  6.341641 #> 6.35  1.62113509  2.6164273  3.0771234  7.573652 11.429241 11.405270 11.249207 #> 6.55  1.42327184  2.3359939  2.7646701  7.126287 11.405270 11.429241 11.355990 #> 6.9   1.12194090  1.8963520  2.2692248  6.341641 11.249207 11.355990 11.429241 #> 8.65  0.28158489  0.5512950  0.6970714  2.918247  8.658295  9.067590  9.732132 #> 9.8   0.09529402  0.2054863  0.2694044  1.470929  6.119291  6.565174  7.350422 #> 9.85  0.09062323  0.1962368  0.2576831  1.423272  6.008691  6.453286  7.238437 #>            8.65         9.8        9.85 #> 0.25  0.2815849  0.09529402  0.09062323 #> 1.05  0.5512950  0.20548634  0.19623679 #> 1.35  0.6970714  0.26940437  0.25768312 #> 3.55  2.9182471  1.47092881  1.42327184 #> 6.35  8.6582947  6.11929089  6.00869101 #> 6.55  9.0675900  6.56517433  6.45328631 #> 6.9   9.7321322  7.35042214  7.23843658 #> 8.65 11.4292407 10.66279660 10.59723888 #> 9.8  10.6627966 11.42924067 11.42774105 #> 9.85 10.5972389 11.42774105 11.42924067 #>  #> $`3` #>             0.25       1.05       1.35      3.55      6.35      6.55       6.9 #> 0.25 11.42924067 11.0516887 10.7259446  6.453286  1.621135  1.423272  1.121941 #> 1.05 11.05168869 11.4292407 11.3753780  8.232832  2.616427  2.335994  1.896352 #> 1.35 10.72594463 11.3753780 11.4292407  8.865231  3.077123  2.764670  2.269225 #> 3.55  6.45328631  8.2328322  8.8652313 11.429241  7.573652  7.126287  6.341641 #> 6.35  1.62113509  2.6164273  3.0771234  7.573652 11.429241 11.405270 11.249207 #> 6.55  1.42327184  2.3359939  2.7646701  7.126287 11.405270 11.429241 11.355990 #> 6.9   1.12194090  1.8963520  2.2692248  6.341641 11.249207 11.355990 11.429241 #> 8.65  0.28158489  0.5512950  0.6970714  2.918247  8.658295  9.067590  9.732132 #> 9.8   0.09529402  0.2054863  0.2694044  1.470929  6.119291  6.565174  7.350422 #> 9.85  0.09062323  0.1962368  0.2576831  1.423272  6.008691  6.453286  7.238437 #>            8.65         9.8        9.85 #> 0.25  0.2815849  0.09529402  0.09062323 #> 1.05  0.5512950  0.20548634  0.19623679 #> 1.35  0.6970714  0.26940437  0.25768312 #> 3.55  2.9182471  1.47092881  1.42327184 #> 6.35  8.6582947  6.11929089  6.00869101 #> 6.55  9.0675900  6.56517433  6.45328631 #> 6.9   9.7321322  7.35042214  7.23843658 #> 8.65 11.4292407 10.66279660 10.59723888 #> 9.8  10.6627966 11.42924067 11.42774105 #> 9.85 10.5972389 11.42774105 11.42924067 #>"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/list_kern_to_inv.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute an inverse covariance matrix for multiple individuals — list_kern_to_inv","title":"Compute an inverse covariance matrix for multiple individuals — list_kern_to_inv","text":"Compute inverse covariance matrices associated individuals database, taking account specific inputs hyper-parameters.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/list_kern_to_inv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute an inverse covariance matrix for multiple individuals — list_kern_to_inv","text":"","code":"list_kern_to_inv(db, kern, hp, pen_diag, deriv = NULL)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/list_kern_to_inv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute an inverse covariance matrix for multiple individuals — list_kern_to_inv","text":"db tibble data frame input data. Required column: 'ID'. Suggested column: 'Input' (indicating reference input). kern kernel function. hp tibble data frame, containing hyper-parameters associated individual. pen_diag number. jitter term, added diagonal prevent numerical issues inverting nearly singular matrices. deriv character, indicating according hyper-parameter derivative computed. NULL (default), function simply returns list covariance matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/list_kern_to_inv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute an inverse covariance matrix for multiple individuals — list_kern_to_inv","text":"named list containing inverse covariance matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/list_kern_to_inv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute an inverse covariance matrix for multiple individuals — list_kern_to_inv","text":"","code":"db <- simu_db(M = 3) hp <- tibble::tibble(ID = unique(db$ID), MagmaClustR:::hp()) MagmaClustR:::list_kern_to_inv(db, \"SE\", hp, 0) #> $`1` #>              0.75          2.75           3.3         3.45           3.9 #> 0.75   0.47292180    -3.5423223     35.518878    -43.56471     24.884412 #> 2.75  -3.54232228   115.0792734  -1308.507915   1650.84764  -1014.083118 #> 3.3   35.51887762 -1308.5079147  15853.428859 -20316.49574  13025.222175 #> 3.45 -43.56471291  1650.8476394 -20316.495743  26147.61368 -16973.668966 #> 3.9   24.88441199 -1014.0831180  13025.222175 -16973.66897  11452.171266 #> 4.05 -13.51126807   562.1839895  -7314.639966   9569.84380  -6541.805519 #> 7      0.97001022   -46.4722653    661.737844   -891.06528    672.780077 #> 7.1   -1.05614976    50.6564544   -721.852187    972.24795   -734.705755 #> 7.75   0.12761284    -6.1560658     88.054879   -118.74598     90.128136 #> 9.25  -0.01374688     0.6668982     -9.574443     12.92724     -9.854154 #>             4.05            7         7.1         7.75        9.25 #> 0.75   -13.51127    0.9700102   -1.056150    0.1276128 -0.01374688 #> 2.75   562.18399  -46.4722653   50.656454   -6.1560658  0.66689821 #> 3.3  -7314.63997  661.7378442 -721.852187   88.0548791 -9.57444333 #> 3.45  9569.84380 -891.0652801  972.247954 -118.7459770 12.92723672 #> 3.9  -6541.80552  672.7800772 -734.705755   90.1281357 -9.85415361 #> 4.05  3754.71709 -401.1400256  438.210942  -53.8495635  5.89767961 #> 7     -401.14003  283.0314750 -318.434425   45.6367662 -5.80609169 #> 7.1    438.21094 -318.4344246  359.601185  -52.5639554  6.81340754 #> 7.75   -53.84956   45.6367662  -52.563955    8.8638736 -1.34355762 #> 9.25     5.89768   -5.8060917    6.813408   -1.3435576  0.57093153 #>  #> $`2` #>              0.75          2.75           3.3         3.45           3.9 #> 0.75   0.47292180    -3.5423223     35.518878    -43.56471     24.884412 #> 2.75  -3.54232228   115.0792734  -1308.507915   1650.84764  -1014.083118 #> 3.3   35.51887762 -1308.5079147  15853.428859 -20316.49574  13025.222175 #> 3.45 -43.56471291  1650.8476394 -20316.495743  26147.61368 -16973.668966 #> 3.9   24.88441199 -1014.0831180  13025.222175 -16973.66897  11452.171266 #> 4.05 -13.51126807   562.1839895  -7314.639966   9569.84380  -6541.805519 #> 7      0.97001022   -46.4722653    661.737844   -891.06528    672.780077 #> 7.1   -1.05614976    50.6564544   -721.852187    972.24795   -734.705755 #> 7.75   0.12761284    -6.1560658     88.054879   -118.74598     90.128136 #> 9.25  -0.01374688     0.6668982     -9.574443     12.92724     -9.854154 #>             4.05            7         7.1         7.75        9.25 #> 0.75   -13.51127    0.9700102   -1.056150    0.1276128 -0.01374688 #> 2.75   562.18399  -46.4722653   50.656454   -6.1560658  0.66689821 #> 3.3  -7314.63997  661.7378442 -721.852187   88.0548791 -9.57444333 #> 3.45  9569.84380 -891.0652801  972.247954 -118.7459770 12.92723672 #> 3.9  -6541.80552  672.7800772 -734.705755   90.1281357 -9.85415361 #> 4.05  3754.71709 -401.1400256  438.210942  -53.8495635  5.89767961 #> 7     -401.14003  283.0314750 -318.434425   45.6367662 -5.80609169 #> 7.1    438.21094 -318.4344246  359.601185  -52.5639554  6.81340754 #> 7.75   -53.84956   45.6367662  -52.563955    8.8638736 -1.34355762 #> 9.25     5.89768   -5.8060917    6.813408   -1.3435576  0.57093153 #>  #> $`3` #>              0.75          2.75           3.3         3.45           3.9 #> 0.75   0.47292180    -3.5423223     35.518878    -43.56471     24.884412 #> 2.75  -3.54232228   115.0792734  -1308.507915   1650.84764  -1014.083118 #> 3.3   35.51887762 -1308.5079147  15853.428859 -20316.49574  13025.222175 #> 3.45 -43.56471291  1650.8476394 -20316.495743  26147.61368 -16973.668966 #> 3.9   24.88441199 -1014.0831180  13025.222175 -16973.66897  11452.171266 #> 4.05 -13.51126807   562.1839895  -7314.639966   9569.84380  -6541.805519 #> 7      0.97001022   -46.4722653    661.737844   -891.06528    672.780077 #> 7.1   -1.05614976    50.6564544   -721.852187    972.24795   -734.705755 #> 7.75   0.12761284    -6.1560658     88.054879   -118.74598     90.128136 #> 9.25  -0.01374688     0.6668982     -9.574443     12.92724     -9.854154 #>             4.05            7         7.1         7.75        9.25 #> 0.75   -13.51127    0.9700102   -1.056150    0.1276128 -0.01374688 #> 2.75   562.18399  -46.4722653   50.656454   -6.1560658  0.66689821 #> 3.3  -7314.63997  661.7378442 -721.852187   88.0548791 -9.57444333 #> 3.45  9569.84380 -891.0652801  972.247954 -118.7459770 12.92723672 #> 3.9  -6541.80552  672.7800772 -734.705755   90.1281357 -9.85415361 #> 4.05  3754.71709 -401.1400256  438.210942  -53.8495635  5.89767961 #> 7     -401.14003  283.0314750 -318.434425   45.6367662 -5.80609169 #> 7.1    438.21094 -318.4344246  359.601185  -52.5639554  6.81340754 #> 7.75   -53.84956   45.6367662  -52.563955    8.8638736 -1.34355762 #> 9.25     5.89768   -5.8060917    6.813408   -1.3435576  0.57093153 #>"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/logL_GP.html","id":null,"dir":"Reference","previous_headings":"","what":"Log-Likelihood function of a Gaussian Process — logL_GP","title":"Log-Likelihood function of a Gaussian Process — logL_GP","text":"Log-Likelihood function Gaussian Process","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/logL_GP.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log-Likelihood function of a Gaussian Process — logL_GP","text":"","code":"logL_GP(hp, db, mean, kern, post_cov, pen_diag)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/logL_GP.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log-Likelihood function of a Gaussian Process — logL_GP","text":"hp tibble, data frame named vector containing hyper-parameters. db tibble containing values want compute logL . Required columns: Input, Output. Additional covariate columns allowed. mean vector, specifying mean GP reference inputs. kern kernel function. post_cov (optional) matrix, corresponding covariance parameter hyper-posterior. Used compute hyper-prior distribution new individual Magma. pen_diag jitter term added covariance matrix avoid numerical issues inverting, cases nearly singular matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/logL_GP.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Log-Likelihood function of a Gaussian Process — logL_GP","text":"number, corresponding value Gaussian log-Likelihood (covariance can sum individual hyper-posterior's mean process covariances).","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/logL_GP.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Log-Likelihood function of a Gaussian Process — logL_GP","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/logL_GP_mod.html","id":null,"dir":"Reference","previous_headings":"","what":"Modified log-Likelihood function for GPs — logL_GP_mod","title":"Modified log-Likelihood function for GPs — logL_GP_mod","text":"Log-Likelihood function involved Magma maximisation step training. log-Likelihood defined simple Gaussian likelihood added correction trace term.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/logL_GP_mod.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Modified log-Likelihood function for GPs — logL_GP_mod","text":"","code":"logL_GP_mod(hp, db, mean, kern, post_cov, pen_diag)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/logL_GP_mod.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Modified log-Likelihood function for GPs — logL_GP_mod","text":"hp tibble, data frame named vector hyper-parameters. db tibble containing values want compute logL . Required columns: Input, Output. Additional covariate columns allowed. mean vector, specifying mean GP reference inputs. kern kernel function. post_cov matrix, covariance parameter hyper-posterior. Used compute correction term. pen_diag jitter term added covariance matrix avoid numerical issues inverting, cases nearly singular matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/logL_GP_mod.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Modified log-Likelihood function for GPs — logL_GP_mod","text":"number, corresponding value modified Gaussian log-Likelihood defined Magma.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/logL_GP_mod.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Modified log-Likelihood function for GPs — logL_GP_mod","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/logL_GP_mod_common_hp.html","id":null,"dir":"Reference","previous_headings":"","what":"Modified log-Likelihood function with common HPs for GPs — logL_GP_mod_common_hp","title":"Modified log-Likelihood function with common HPs for GPs — logL_GP_mod_common_hp","text":"Log-Likelihood function involved Magma maximisation step training, particular case hyper-parameters shared individuals. log-Likelihood defined sum individuals Gaussian likelihoods added correction trace terms.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/logL_GP_mod_common_hp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Modified log-Likelihood function with common HPs for GPs — logL_GP_mod_common_hp","text":"","code":"logL_GP_mod_common_hp(hp, db, mean, kern, post_cov, pen_diag)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/logL_GP_mod_common_hp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Modified log-Likelihood function with common HPs for GPs — logL_GP_mod_common_hp","text":"hp tibble, data frame hyper-parameters. db tibble containing values want compute logL . Required columns: ID, Input, Output. Additional covariate columns allowed. mean vector, specifying mean GP reference inputs. kern kernel function. post_cov matrix, covariance parameter hyper-posterior. Used compute correction term. pen_diag jitter term added covariance matrix avoid numerical issues inverting, cases nearly singular matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/logL_GP_mod_common_hp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Modified log-Likelihood function with common HPs for GPs — logL_GP_mod_common_hp","text":"number, corresponding value modified Gaussian log-Likelihood common hyper-parameters defined Magma.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/logL_GP_mod_common_hp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Modified log-Likelihood function with common HPs for GPs — logL_GP_mod_common_hp","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/logL_monitoring.html","id":null,"dir":"Reference","previous_headings":"","what":"Log-Likelihood for monitoring the EM algorithm in Magma — logL_monitoring","title":"Log-Likelihood for monitoring the EM algorithm in Magma — logL_monitoring","text":"Log-Likelihood monitoring EM algorithm Magma","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/logL_monitoring.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log-Likelihood for monitoring the EM algorithm in Magma — logL_monitoring","text":"","code":"logL_monitoring(   hp_0,   hp_i,   db,   m_0,   kern_0,   kern_i,   post_mean,   post_cov,   pen_diag )"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/logL_monitoring.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log-Likelihood for monitoring the EM algorithm in Magma — logL_monitoring","text":"hp_0 named vector, tibble data frame, containing hyper-parameters associated mean GP. hp_i tibble data frame, containing hyper-parameters individual GPs. db tibble data frame. Columns required: ID, Input, Output. Additional columns covariates can specified. m_0 vector, corresponding prior mean mean GP. kern_0 kernel function, associated mean GP. kern_i kernel function, associated individual GPs. post_mean tibble, coming E step, containing Input associated Output hyper-posterior mean parameter. post_cov matrix, coming E step, hyper-posterior covariance parameter. pen_diag jitter term added covariance matrix avoid numerical issues inverting, cases nearly singular matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/logL_monitoring.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Log-Likelihood for monitoring the EM algorithm in Magma — logL_monitoring","text":"number, expectation joint log-likelihood model. quantity supposed increase step EM algorithm, thus used monitoring procedure.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/logL_monitoring.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Log-Likelihood for monitoring the EM algorithm in Magma — logL_monitoring","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/m_step.html","id":null,"dir":"Reference","previous_headings":"","what":"M-Step of the EM algorithm — m_step","title":"M-Step of the EM algorithm — m_step","text":"Maximisation step EM algorithm compute hyper-parameters kernels involved Magma.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/m_step.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"M-Step of the EM algorithm — m_step","text":"","code":"m_step(   db,   m_0,   kern_0,   kern_i,   old_hp_0,   old_hp_i,   post_mean,   post_cov,   common_hp,   pen_diag )"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/m_step.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"M-Step of the EM algorithm — m_step","text":"db tibble data frame. Columns required: ID, Input, Output. Additional columns covariates can specified. m_0 vector, corresponding prior mean mean GP. kern_0 kernel function, associated mean GP. kern_i kernel function, associated individual GPs. old_hp_0 named vector, tibble data frame, containing hyper-parameters previous M-step (initialisation) associated mean GP. old_hp_i tibble data frame, containing hyper-parameters previous M-step (initialisation) associated individual GPs. post_mean tibble, coming E step, containing Input associated Output hyper-posterior mean parameter. post_cov matrix, coming E step, hyper-posterior covariance parameter. common_hp logical value, indicating whether set hyper-parameters assumed common indiviuals. pen_diag number. jitter term, added diagonal prevent numerical issues inverting nearly singular matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/m_step.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"M-Step of the EM algorithm — m_step","text":"named list, containing elements hp_0, tibble containing hyper-parameters associated mean GP, hp_i, tibble containing hyper-parameters associated individual GPs.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/m_step.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"M-Step of the EM algorithm — m_step","text":"","code":"if (FALSE) { ## Common inputs across individuals and different HPs db <- simu_db(N = 10, common_input = TRUE) m_0 <- rep(0, 10) hp_0 <- MagmaClustR:::hp() hp_i <- MagmaClustR:::hp(\"SE\", list_ID = unique(db$ID)) post <- MagmaClustR:::e_step(db, m_0, \"SE\", \"SE\", hp_0, hp_i, 0.001)  MagmaClustR:::m_step(   db, m_0, \"SE\", \"SE\", hp_0, hp_i, post$mean, post$cov,   TRUE, 0.1 )  ## Common inputs across individuals and common HPs hp_i_common <- tibble::tibble(   ID = unique(db$ID),   variance = 1, lengthscale = 1 ) MagmaClustR:::m_step(   db, m_0, \"SE\", \"SE\", hp_0, hp_i_common,   post$mean, post$cov, TRUE, 0.5 )  ## Different inputs across individuals and different HPs db_async <- simu_db(N = 10, common_input = FALSE) m_0_async <- rep(0, db_async$Input %>% unique() %>% length()) post_async <- MagmaClustR:::e_step(   db_async, m_0_async, \"SE\", \"SE\",   hp_0, hp_i, 0.001 )  MagmaClustR:::m_step(   db_async, m_0_async, \"SE\", \"SE\", hp_0, hp_i,   post_async$mean, post_async$cov, FALSE, 0.01 ) }"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/perio_kernel.html","id":null,"dir":"Reference","previous_headings":"","what":"Periodic Kernel — perio_kernel","title":"Periodic Kernel — perio_kernel","text":"Periodic Kernel","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/perio_kernel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Periodic Kernel — perio_kernel","text":"","code":"perio_kernel(x, y, hp, deriv = NULL, vectorized = F)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/perio_kernel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Periodic Kernel — perio_kernel","text":"x vector (matrix vectorized = T) inputs. y vector (matrix vectorized = T) inputs. hp tibble, data frame named vector, containing kernel's hyperparameters. Required columns: 'perio_variance', 'perio_lengthscale', 'period'. deriv character, indicating according hyper-parameter derivative computed. NULL (default), function simply returns evaluation kernel. vectorized logical value, indicating whether function provides vectorized version speeded-calculations. TRUE, x y arguments vector matrix containing inputs kernel evaluated pairs elements. FALSE, x y arguments simply two inputs.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/perio_kernel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Periodic Kernel — perio_kernel","text":"scalar, corresponding evaluation kernel.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/perio_kernel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Periodic Kernel — perio_kernel","text":"","code":"MagmaClustR:::perio_kernel(   c(1, 0), c(0, 1),   tibble::tibble(perio_variance = 1, perio_lengthscale = 0.5, period = 2) ) #> [1] 1.799002"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/pipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipe operator — %>%","text":"lhs value magrittr placeholder. rhs function call using magrittr semantics.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/pipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipe operator — %>%","text":"result calling rhs(lhs).","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/plot_db.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot smoothed curves of raw data — plot_db","title":"Plot smoothed curves of raw data — plot_db","text":"Display raw data Magma format smoothed curves.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/plot_db.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot smoothed curves of raw data — plot_db","text":"","code":"plot_db(data, cluster = F, legend = F)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/plot_db.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot smoothed curves of raw data — plot_db","text":"data data frame tibble format : ID, Input, Output. cluster boolean indicating whether data coloured cluster. Requires column named 'Cluster'. legend boolean indicating whether legend displayed.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/plot_db.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot smoothed curves of raw data — plot_db","text":"Graph smoothed curves raw data.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/plot_db.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot smoothed curves of raw data — plot_db","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/plot_gif.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a GIF of Magma or GP predictions — plot_gif","title":"Create a GIF of Magma or GP predictions — plot_gif","text":"Create GIF animation displaying Magma classic GP predictions evolve improve number data points increase.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/plot_gif.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a GIF of Magma or GP predictions — plot_gif","text":"","code":"plot_gif(   pred_gp,   x_input = NULL,   data = NULL,   data_train = NULL,   prior_mean = NULL,   y_grid = NULL,   heatmap = F,   prob_CI = 0.95,   size_data = 3,   size_data_train = 1,   alpha_data_train = 0.5,   export_gif = FALSE,   path = \"gif_gp.gif\",   ... )"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/plot_gif.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a GIF of Magma or GP predictions — plot_gif","text":"pred_gp tibble, typically coming pred_gif function. Required columns: 'Input', 'Mean', 'Var' 'Index'. x_input vector character strings, indicating input displayed. NULL(default) 'Input' column used x-axis. providing 2-dimensional vector, corresponding columns used x-axis y-axis. data (Optional) tibble data frame. Required columns: 'Input', 'Output'. Additional columns covariates can specified. 'Input' column define variable used reference observations (e.g. time longitudinal data). 'Output' column specifies observed values (response variable). data frame can also provide many covariates desired, constraints column names. covariates additional inputs (explanatory variables) models also observed reference 'Input'. data_train (Optional) tibble data frame, containing training data Magma model. data set format data argument additional column 'ID' identifying different individuals/tasks. provided, data displayed backward colourful points (colour corresponding one individual/task). prior_mean (Optional) tibble data frame, containing 'Input' associated 'Output' prior mean parameter GP prediction. y_grid vector, indicating grid values y-axis probabilities computed heatmaps 1-dimensional predictions. NULL (default), vector length 50 defined, ranging min max 'Output' values contained pred_gp. heatmap logical value indicating whether GP prediction represented heatmap probabilities 1-dimensional inputs. FALSE (default), mean curve associated 95% CI displayed. prob_CI number 0 1 (default 0.95), indicating level Credible Interval associated posterior mean curve. size_data number, controlling size data points. size_data_train number, controlling size data_train points. alpha_data_train number, 0 1, controlling transparency data_train points. export_gif logical value indicating whether animation exported .gif file. path character string defining path GIF file exported. ... additional parameters can passed function transition_states gganimate package.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/plot_gif.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a GIF of Magma or GP predictions — plot_gif","text":"Visualisation Magma GP prediction (optional: display data points, training data points prior mean function), data points added sequentially visualising changes prediction information increases.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/plot_gif.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a GIF of Magma or GP predictions — plot_gif","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/plot_gp.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Magma or GP predictions — plot_gp","title":"Plot Magma or GP predictions — plot_gp","text":"Display Magma classic GP predictions. According dimension inputs, graph may mean curve + Credible Interval heatmap probabilities.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/plot_gp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Magma or GP predictions — plot_gp","text":"","code":"plot_gp(   pred_gp,   x_input = NULL,   data = NULL,   data_train = NULL,   prior_mean = NULL,   y_grid = NULL,   heatmap = F,   prob_CI = 0.95,   size_data = 3,   size_data_train = 1,   alpha_data_train = 0.5 )"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/plot_gp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Magma or GP predictions — plot_gp","text":"pred_gp tibble data frame, typically coming pred_magma pred_gp functions. Required columns: 'Input', 'Mean', 'Var'. Additional covariate columns may present case multi-dimensional inputs. x_input vector character strings, indicating input displayed. NULL (default) 'Input' column used x-axis. providing 2-dimensional vector, corresponding columns used x-axis y-axis. data (Optional) tibble data frame. Required columns: 'Input', 'Output'. Additional columns covariates can specified. argument corresponds raw data prediction performed. data_train (Optional) tibble data frame, containing training data Magma model. data set format data argument additional required column 'ID' identifying different individuals/tasks. provided, data displayed backward colourful points (colour corresponding one individual/task). prior_mean (Optional) tibble data frame, containing 'Input' associated 'Output' prior mean parameter GP prediction. y_grid vector, indicating grid values y-axis probabilities computed heatmaps 1-dimensional predictions. NULL (default), vector length 50 defined, ranging min max 'Output' values contained pred_gp. heatmap logical value indicating whether GP prediction represented heatmap probabilities 1-dimensional inputs. FALSE (default), mean curve associated Credible Interval displayed. prob_CI number 0 1 (default 0.95), indicating level Credible Interval associated posterior mean curve. argument set 1, Credible Interval displayed. size_data number, controlling size data points. size_data_train number, controlling size data_train points. alpha_data_train number, 0 1, controlling transparency data_train points.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/plot_gp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Magma or GP predictions — plot_gp","text":"Visualisation Magma GP prediction (optional: display data points, training data points prior mean function). 1-D inputs, prediction represented mean curve associated 95%  Credible Interval, heatmap probabilities heatmap = TRUE. 2-D inputs, prediction represented heatmap, couple inputs x-axis y-axis associated gradient colours posterior mean values, whereas uncertainty indicated transparency (narrower Credible Interval, opaque associated colour, vice versa)","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/plot_gp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Magma or GP predictions — plot_gp","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/plot_magmaclust.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot MagmaClust predictions — plot_magmaclust","title":"Plot MagmaClust predictions — plot_magmaclust","text":"Display MagmaClust predictions. According dimension inputs, graph may mean curve (dim inputs = 1) heatmap (dim inputs = 2) probabilities. Moreover, MagmaClust can provide credible intervals visualising cluster-specific predictions (e.g. probable cluster). visualising full mixture--GPs prediction, can multimodal, user choose simple mean function full heatmap probabilities (informative slower).","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/plot_magmaclust.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot MagmaClust predictions — plot_magmaclust","text":"","code":"plot_magmaclust(   pred_clust,   cluster = \"all\",   x_input = NULL,   data = NULL,   data_train = NULL,   col_clust = FALSE,   prior_mean = NULL,   y_grid = NULL,   heatmap = FALSE,   prob_CI = 0.95,   size_data = 3,   size_data_train = 1,   alpha_data_train = 0.5 )"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/plot_magmaclust.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot MagmaClust predictions — plot_magmaclust","text":"pred_clust list predictions, typically coming pred_magmaclust. Required elements: pred, mixture, mixture_pred. cluster character string, indicating cluster plot . '' (default) mixture GPs prediction displayed mean curve (1-D inputs) mean heatmap (2-D inputs). Alternatively, name one cluster provided, classic mean curve + credible interval displayed (1-D inputs), heatmap colour gradient mean transparency gradient Credible Interval (2-D inputs). x_input vector character strings, indicating input displayed. NULL (default) 'Input' column used x-axis. providing 2-dimensional vector, corresponding columns used x-axis y-axis. data (Optional) tibble data frame. Required columns: Input , Output. Additional columns covariates can specified. argument corresponds raw data prediction performed. data_train (Optional) tibble data frame, containing training data MagmaClust model. data set format data argument additional required column ID identifying different individuals/tasks. provided, data displayed backward colourful points (colour corresponding one individual cluster, see col_clust ). col_clust boolean indicating whether backward points coloured according individuals probable cluster. one wants colour clusters, column Cluster shall present data_train. advise use data_allocate_cluster automatically creating well-formatted dataset trained MagmaClust model. prior_mean (Optional) list providing, cluster, tibble containing prior mean parameters prediction. argument typically comes outcome hyperpost$mean, available train_magmaclust, pred_magmaclust functions. y_grid vector, indicating grid values y-axis probabilities computed heatmaps 1-dimensional predictions. NULL (default), vector length 50 defined, ranging min max 'Output' values contained pred. heatmap logical value indicating whether GP prediction represented heatmap probabilities 1-dimensional inputs. FALSE (default), mean curve (associated Credible Interval available) displayed. prob_CI number 0 1 (default 0.95), indicating level Credible Interval associated posterior mean curve. argument set 1, Credible Interval displayed. size_data number, controlling size data points. size_data_train number, controlling size data_train points. alpha_data_train number, 0 1, controlling transparency data_train points.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/plot_magmaclust.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot MagmaClust predictions — plot_magmaclust","text":"Visualisation MagmaClust prediction (optional: display data points, training data points prior mean functions). 1-D inputs, prediction represented mean curve (associated 95% Credible Interval cluster-specific predictions), heatmap probabilities heatmap = TRUE. case MagmaClust, heatmap representation preferred clarity, although default display remains mean curve quicker execution. 2-D inputs, prediction represented heatmap, couple inputs x-axis y-axis associated gradient colours posterior mean values, whereas uncertainty indicated transparency (narrower Credible Interval, opaque associated colour, vice versa). 1-D inputs, Credible Interval information available cluster-specific predictions.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/plot_magmaclust.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot MagmaClust predictions — plot_magmaclust","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/pred_gif.html","id":null,"dir":"Reference","previous_headings":"","what":"Magma prediction for ploting GIFs — pred_gif","title":"Magma prediction for ploting GIFs — pred_gif","text":"Generate Magma classic GP prediction format compatible GIF visualisation results. Magma prediction, either trained_model hyperpost argument required. Otherwise, classic GP prediction applied prior mean can specified mean argument.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/pred_gif.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Magma prediction for ploting GIFs — pred_gif","text":"","code":"pred_gif(   data,   trained_model = NULL,   hyperpost = NULL,   mean = NULL,   hp = NULL,   kern = \"SE\",   grid_inputs = NULL,   pen_diag = 1e-08 )"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/pred_gif.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Magma prediction for ploting GIFs — pred_gif","text":"data tibble data frame. Required columns: 'Input', 'Output'. Additional columns covariates can specified. 'Input' column define variable used reference observations (e.g. time longitudinal data). 'Output' column specifies observed values (response variable). data frame can also provide many covariates desired, constraints column names. covariates additional inputs (explanatory variables) models also observed reference 'Input'. trained_model list, containing  information coming Magma model, previously trained using train_magma function. hyperpost list, containing elements 'mean' 'cov', parameters hyper-posterior distribution mean process. Typically, argument previous learning using train_magma, previous prediction pred_magma, argument get_hyperpost set TRUE. 'mean' element data frame two columns 'Input' 'Output'. 'cov' element covariance matrix colnames rownames corresponding 'Input' 'mean'. cases, column 'Input' contain values appearing 'Input' column data grid_inputs. mean Mean parameter GP. argument can specified various formats, : NULL (default). mean set 0 everywhere. number. mean constant function. function. function defined mean. tibble data frame. Required columns: Input, Output. Input values include least values data argument. hp named vector, tibble data frame hyper-parameters associated kern. columns/elements named according hyper-parameters used kern. function train_gp can used learn maximum-likelihood estimators hyper-parameters, kern kernel function, defining covariance structure GP. Several popular kernels (see Kernel Cookbook) already implemented can selected within following list: \"SE\": (default value) Squared Exponential Kernel (also called Radial Basis Function Gaussian kernel), \"LIN\": Linear kernel, \"PERIO\": Periodic kernel, \"RQ\": Rational Quadratic kernel. Compound kernels can created sums products kernels. combining kernels, simply provide formula character string elements separated whitespaces (e.g. \"SE + PERIO\"). elements treated sequentially left right, product operator '*' shall always used '+' operators (e.g. 'SE * LIN + RQ' valid whereas 'RQ + SE * LIN'  ). grid_inputs grid inputs (reference Input covariates) values GP evaluated. Ideally, argument tibble data frame, providing columns data, except 'Output'. Nonetheless, cases data provides one 'Input' column, grid_inputs argument can NULL (default) vector. vector used reference input prediction NULL, vector length 500 defined, ranging min max Input values data. pen_diag number. jitter term, added diagonal prevent numerical issues inverting nearly singular matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/pred_gif.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Magma prediction for ploting GIFs — pred_gif","text":"tibble, representing Magma GP predictions two column 'Mean' 'Var', evaluated grid_inputs. column 'Input' additional covariates columns associated predicted values. additional 'Index' column created sake GIF creation using function plot_gif","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/pred_gif.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Magma prediction for ploting GIFs — pred_gif","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/pred_gp.html","id":null,"dir":"Reference","previous_headings":"","what":"Gaussian Process prediction — pred_gp","title":"Gaussian Process prediction — pred_gp","text":"Compute posterior distribution simple GP, using formalism Magma. providing observed data, prior mean covariance matrix (defining kernel associated hyper-parameters), mean covariance parameters posterior distribution computed grid inputs specified. predictive distribution can evaluated arbitrary inputs since GP infinite-dimensional object.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/pred_gp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gaussian Process prediction — pred_gp","text":"","code":"pred_gp(   data,   mean = NULL,   hp = NULL,   kern = \"SE\",   grid_inputs = NULL,   get_full_cov = FALSE,   plot = TRUE,   pen_diag = 1e-08 )"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/pred_gp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gaussian Process prediction — pred_gp","text":"data tibble data frame. Required columns: 'Input', 'Output'. Additional columns covariates can specified. 'Input' column define variable used reference observations (e.g. time longitudinal data). 'Output' column specifies observed values (response variable). data frame can also provide many covariates desired, constraints column names. covariates additional inputs (explanatory variables) models also observed reference 'Input'. mean Mean parameter GP. argument can specified various formats, : NULL (default). mean set 0 everywhere. number. mean constant function. function. function defined mean. tibble data frame. Required columns: Input, Output. Input values include least values data argument. hp named vector, tibble data frame hyper-parameters associated kern. columns/elements named according hyper-parameters used kern. NULL (default), function train_gp called random initial values learning maximum-likelihood estimators hyper-parameters associated kern. kern kernel function, defining covariance structure GP. Several popular kernels (see Kernel Cookbook) already implemented can selected within following list: \"SE\": (default value) Squared Exponential Kernel (also called Radial Basis Function Gaussian kernel), \"LIN\": Linear kernel, \"PERIO\": Periodic kernel, \"RQ\": Rational Quadratic kernel. Compound kernels can created sums products kernels. combining kernels, simply provide formula character string elements separated whitespaces (e.g. \"SE + PERIO\"). elements treated sequentially left right, product operator '*' shall always used '+' operators (e.g. 'SE * LIN + RQ' valid whereas 'RQ + SE * LIN'  ). grid_inputs grid inputs (reference Input covariates) values GP evaluated. Ideally, argument tibble data frame, providing columns data, except 'Output'. Nonetheless, cases data provides one 'Input' column, grid_inputs argument can NULL (default) vector. vector used reference input prediction NULL, vector length 500 defined, ranging min max Input values data. get_full_cov logical value, indicating whether full posterior covariance matrix returned. plot logical value, indicating whether plot results automatically displayed. pen_diag number. jitter term, added diagonal prevent numerical issues inverting nearly singular matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/pred_gp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gaussian Process prediction — pred_gp","text":"tibble, representing GP predictions two column 'Mean' 'Var', evaluated grid_inputs. column 'Input' additional covariates columns associated predicted values. get_full_cov argument TRUE, function returns list, tibble described defined 'pred' full posterior covariance matrix defined 'cov'.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/pred_gp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gaussian Process prediction — pred_gp","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/pred_magma.html","id":null,"dir":"Reference","previous_headings":"","what":"Magma prediction — pred_magma","title":"Magma prediction — pred_magma","text":"Compute posterior predictive distribution Magma. Providing data new individual/task, trained hyper-parameters previously trained Magma model, predictive distribution evaluated arbitrary inputs specified 'grid_inputs' argument.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/pred_magma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Magma prediction — pred_magma","text":"","code":"pred_magma(   data,   trained_model = NULL,   hp = NULL,   kern = \"SE\",   grid_inputs = NULL,   hyperpost = NULL,   get_hyperpost = FALSE,   get_full_cov = FALSE,   plot = TRUE,   pen_diag = 1e-08 )"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/pred_magma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Magma prediction — pred_magma","text":"data tibble data frame. Required columns: 'Input', 'Output'. Additional columns covariates can specified. 'Input' column define variable used reference observations (e.g. time longitudinal data). 'Output' column specifies observed values (response variable). data frame can also provide many covariates desired, constraints column names. covariates additional inputs (explanatory variables) models also observed reference 'Input'. trained_model list, containing  information coming Magma model, previously trained using train_magma function. hp named vector, tibble data frame hyper-parameters associated kern. columns/elements named according hyper-parameters used kern. function train_gp can used learn maximum-likelihood estimators hyper-parameters. kern kernel function, defining covariance structure GP. Several popular kernels (see Kernel Cookbook) already implemented can selected within following list: \"SE\": (default value) Squared Exponential Kernel (also called Radial Basis Function Gaussian kernel), \"LIN\": Linear kernel, \"PERIO\": Periodic kernel, \"RQ\": Rational Quadratic kernel. Compound kernels can created sums products kernels. combining kernels, simply provide formula character string elements separated whitespaces (e.g. \"SE + PERIO\"). elements treated sequentially left right, product operator '*' shall always used '+' operators (e.g. 'SE * LIN + RQ' valid whereas 'RQ + SE * LIN'  ). grid_inputs grid inputs (reference Input covariates) values GP evaluated. Ideally, argument tibble data frame, providing columns data, except 'Output'. Nonetheless, cases data provides one 'Input' column, grid_inputs argument can NULL (default) vector. vector used reference input prediction NULL, vector length 500 defined, ranging min max Input values data. hyperpost list, containing elements 'mean' 'cov', parameters hyper-posterior distribution mean process. Typically, argument come previous learning using train_magma, previous prediction pred_magma, argument get_hyperpost set TRUE. 'mean' element data frame two columns 'Input' 'Output'. 'cov' element covariance matrix colnames rownames corresponding 'Input' 'mean'. cases, column 'Input' contain values appearing 'Input' column data grid_inputs. get_hyperpost logical value, indicating whether hyper-posterior distribution mean process returned. can useful planning perform several predictions grid inputs, since recomputation hyper-posterior can prohibitive high dimensional grids. get_full_cov logical value, indicating whether full posterior covariance matrix returned. plot logical value, indicating whether plot results automatically displayed. pen_diag number. jitter term, added diagonal prevent numerical issues inverting nearly singular matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/pred_magma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Magma prediction — pred_magma","text":"tibble, representing Magma predictions two column 'Mean' 'Var', evaluated grid_inputs. column 'Input' additional covariates columns associated predicted values. get_full_cov get_hyperpost arguments TRUE, function returns list, tibble described defined 'pred_gp' full posterior covariance matrix defined 'cov', hyper-posterior distribution mean process defined 'hyperpost'.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/pred_magma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Magma prediction — pred_magma","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/pred_magmaclust.html","id":null,"dir":"Reference","previous_headings":"","what":"MagmaClust prediction — pred_magmaclust","title":"MagmaClust prediction — pred_magmaclust","text":"Compute posterior predictive distribution MagmaClust. Providing data new individual/task, trained hyper-parameters previously trained MagmaClust model, multi-task posterior distribution evaluated arbitrary inputs specified 'grid_inputs' argument. Due nature model, prediction defined mixture Gaussian distributions. Therefore present function computes parameters predictive distribution associated cluster, well posterior mixture probabilities new individual/task.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/pred_magmaclust.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"MagmaClust prediction — pred_magmaclust","text":"","code":"pred_magmaclust(   data,   trained_model = NULL,   mixture = NULL,   hp = NULL,   kern = \"SE\",   grid_inputs = NULL,   hyperpost = NULL,   prop_mixture = NULL,   get_hyperpost = FALSE,   get_full_cov = FALSE,   plot = TRUE,   pen_diag = 1e-08 )"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/pred_magmaclust.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"MagmaClust prediction — pred_magmaclust","text":"data tibble data frame. Required columns: Input, Output. Additional columns covariates can specified. Input column define variable used reference observations (e.g. time longitudinal data). Output column specifies observed values (response variable). data frame can also provide many covariates desired, constraints column names. covariates additional inputs (explanatory variables) models also observed reference 'Input'. trained_model list, containing  information coming MagmaClust model, previously trained using train_magmaclust function. trained_model set NULL, hyperpost prop_mixture arguments mandatory perform required re-computations prediction succeed. mixture tibble data frame, indicating mixture probabilities cluster new individual/task. NULL, train_gp_clust function used compute posterior probabilities according data. hp named vector, tibble data frame hyper-parameters associated kern. columns/elements named according hyper-parameters used kern. train_gp_clust function can used learn maximum-likelihood estimators hyper-parameters. kern kernel function, defining covariance structure GP. Several popular kernels (see Kernel Cookbook) already implemented can selected within following list: \"SE\": (default value) Squared Exponential Kernel (also called Radial Basis Function Gaussian kernel), \"LIN\": Linear kernel, \"PERIO\": Periodic kernel, \"RQ\": Rational Quadratic kernel. Compound kernels can created sums products kernels. combining kernels, simply provide formula character string elements separated whitespaces (e.g. \"SE + PERIO\"). elements treated sequentially left right, product operator '*' shall always used '+' operators (e.g. 'SE * LIN + RQ' valid whereas 'RQ + SE * LIN'  ). grid_inputs grid inputs (reference Input covariates) values GP evaluated. Ideally, argument tibble data frame, providing columns data, except 'Output'. Nonetheless, cases data provides one 'Input' column, grid_inputs argument can NULL (default) vector. vector used reference input prediction NULL, vector length 500 defined, ranging min max Input values data. hyperpost list, containing elements mean, cov mixture parameters hyper-posterior distributions mean processes. Typically, argument come previous learning using train_magmaclust, previous prediction pred_magmaclust, argument get_hyperpost set TRUE. prop_mixture tibble named vector mixture proportions. name column element refer cluster. value associated cluster number 0 1. mixture trained_model set NULL, argument allows recompute mixture probabilities, thanks hyperpost argument train_gp_clust function. get_hyperpost logical value, indicating whether hyper-posterior distributions mean processes returned. can useful planning perform several predictions grid inputs, since recomputation hyper-posterior can prohibitive high dimensional grids. get_full_cov logical value, indicating whether full posterior covariance matrices returned. plot logical value, indicating whether plot results automatically displayed. pen_diag number. jitter term, added diagonal prevent numerical issues inverting nearly singular matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/pred_magmaclust.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"MagmaClust prediction — pred_magmaclust","text":"list GP prediction results composed : pred: sub-list containing, cluster: pred_gp: tibble, representing GP predictions two column Mean Var, evaluated grid_inputs. column Input additional covariates columns associated predicted values. proba: number, posterior probability associated cluster. cov (get_full_cov = TRUE): matrix, full posterior covariance matrix associated cluster. mixture: tibble, indicating mixture probabilities cluster predicted individual/task. hyperpost (get_hyperpost = TRUE): list, containing hyper-posterior distributions information useful visualisation purposes.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/pred_magmaclust.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"MagmaClust prediction — pred_magmaclust","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/proba_max_cluster.html","id":null,"dir":"Reference","previous_headings":"","what":"Indicates the most probable cluster — proba_max_cluster","title":"Indicates the most probable cluster — proba_max_cluster","text":"Indicates probable cluster","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/proba_max_cluster.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Indicates the most probable cluster — proba_max_cluster","text":"","code":"proba_max_cluster(mixture)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/proba_max_cluster.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Indicates the most probable cluster — proba_max_cluster","text":"mixture tibble data frame containing mixture probabilities.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/proba_max_cluster.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Indicates the most probable cluster — proba_max_cluster","text":"tibble, retaining probable cluster. column Cluster indicates cluster's name whereas Probarefers associated probability. ID initially column mixture (optional), function returns probable cluster different ID values.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/proba_max_cluster.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Indicates the most probable cluster — proba_max_cluster","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/rq_kernel.html","id":null,"dir":"Reference","previous_headings":"","what":"Rational Quadratic Kernel — rq_kernel","title":"Rational Quadratic Kernel — rq_kernel","text":"Rational Quadratic Kernel","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/rq_kernel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rational Quadratic Kernel — rq_kernel","text":"","code":"rq_kernel(x, y, hp, deriv = NULL, vectorized = FALSE)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/rq_kernel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rational Quadratic Kernel — rq_kernel","text":"x vector (matrix vectorized = T) inputs. y vector (matrix vectorized = T) inputs. hp tibble, data frame named vector, containing kernel's hyperparameters. Required columns: 'rq_variance', 'rq_lengthscale', 'rq_scale'. deriv character, indicating according hyper-parameter derivative computed. NULL (default), function simply returns evaluation kernel. vectorized logical value, indicating whether function provides vectorized version speeded-calculations. TRUE, x y arguments vector matrix containing inputs kernel evaluated pairs elements. FALSE, x y arguments simply two inputs.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/rq_kernel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Rational Quadratic Kernel — rq_kernel","text":"scalar, corresponding evaluation kernel.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/rq_kernel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Rational Quadratic Kernel — rq_kernel","text":"","code":"MagmaClustR:::rq_kernel(   c(1, 0), c(0, 1),   tibble::tibble(rq_variance = 1, rq_lengthscale = 0.5, rq_scale = 3) ) #> [1] 1.56455"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/sample_gp.html","id":null,"dir":"Reference","previous_headings":"","what":"Display Realisation From Posterior GP — sample_gp","title":"Display Realisation From Posterior GP — sample_gp","text":"realisation posterior GP distribution drawn displayed. According dimension inputs, graph may curve heatmap.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/sample_gp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Display Realisation From Posterior GP — sample_gp","text":"","code":"sample_gp(   pred_gp,   x_input = NULL,   data = NULL,   data_train = NULL,   prior_mean = NULL,   size_data = 3,   size_data_train = 1,   alpha_data_train = 0.5 )"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/sample_gp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Display Realisation From Posterior GP — sample_gp","text":"pred_gp tibble data frame, typically coming pred_magma pred_gp functions. Required columns: 'Input', 'Mean', 'Var'. Additional covariate columns may present case multi-dimensional inputs. x_input vector character strings, indicating input displayed. NULL(default) 'Input' column used x-axis. providing 2-dimensional vector, corresponding columns used x-axis y-axis. data (Optional) tibble data frame, containing data used GP prediction. data_train (Optional) tibble data frame, containing training data Magma model. data set format data argument additional column 'ID' identifying different individuals/tasks. provided, data displayed backward colourful points (colour corresponding one individual/task). prior_mean (Optional) tibble data frame, containing 'Input' associated 'Output' prior mean parameter GP prediction. size_data number, controlling size data points. size_data_train number, controlling size data_train points. alpha_data_train number, 0 1, controlling transparency data_train points.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/sample_gp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Display Realisation From Posterior GP — sample_gp","text":"Draw visualise posterior distribution Magma GP prediction (optional: display data points, training data points prior mean function).","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/sample_gp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Display Realisation From Posterior GP — sample_gp","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/se_kernel.html","id":null,"dir":"Reference","previous_headings":"","what":"Squared Exponential Kernel — se_kernel","title":"Squared Exponential Kernel — se_kernel","text":"Squared Exponential Kernel","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/se_kernel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Squared Exponential Kernel — se_kernel","text":"","code":"se_kernel(x = NULL, y = NULL, hp, deriv = NULL, vectorized = F)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/se_kernel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Squared Exponential Kernel — se_kernel","text":"x vector (matrix vectorized = T) inputs. y vector (matrix vectorized = T) inputs. hp tibble, data frame named vector, containing kernel's hyperparameters. Required columns: 'se_variance', 'se_lengthscale'. deriv character, indicating according hyper-parameter derivative computed. NULL (default), function simply returns evaluation kernel. vectorized logical value, indicating whether function provides vectorized version speeded-calculations. TRUE, x y arguments vector matrix containing inputs kernel evaluated pairs elements. FALSE, x y arguments simply two inputs.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/se_kernel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Squared Exponential Kernel — se_kernel","text":"scalar, corresponding evaluation kernel.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/se_kernel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Squared Exponential Kernel — se_kernel","text":"","code":"MagmaClustR:::se_kernel(   c(1, 0), c(0, 1),   tibble::tibble(se_variance = 1, se_lengthscale = 0.5) ) #> [1] 1.482114"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/select_nb_cluster.html","id":null,"dir":"Reference","previous_headings":"","what":"Select the optimal number of clusters — select_nb_cluster","title":"Select the optimal number of clusters — select_nb_cluster","text":"MagmaClust, clustering method, number K clusters provided hypothesis model. function implements model selection procedure, maximising variational BIC criterion, computed different values K. heuristic fast approximation procedure proposed well, although corresponding models properly trained.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/select_nb_cluster.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Select the optimal number of clusters — select_nb_cluster","text":"","code":"select_nb_cluster(   data,   fast_approx = TRUE,   grid_nb_cluster = 1:10,   ini_hp_k = NULL,   ini_hp_i = NULL,   kern_k = \"SE\",   kern_i = \"SE\",   plot = TRUE,   ... )"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/select_nb_cluster.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Select the optimal number of clusters — select_nb_cluster","text":"data tibble data frame. Columns required: ID, Input , Output. Additional columns covariates can specified. ID column contains unique names/codes used identify individual/task (batch data). Input column define variable used reference observations (e.g. time longitudinal data). Output column specifies observed values (response variable). data frame can also provide many covariates desired, constraints column names. covariates additional inputs (explanatory variables) models also observed reference Input. fast_approx boolean, indicating whether fast approximation used selecting number clusters. TRUE, Magma MagmaClust model perform one E-step training, using fixed values hyper-parameters (ini_hp_k ini_hp_i, random values provided) models. resulting models considered trained, approach provides convenient heuristic avoid cumbersome model selection procedure. grid_nb_cluster vector integer, corresponding grid values tested number clusters. ini_hp_k tibble data frame hyper-parameters associated kern_k. ini_hp_i tibble data frame hyper-parameters associated kern_i. kern_k kernel function associated mean processes. kern_i kernel function associated individuals/tasks. plot boolean indicating whether plot V-BIC values numbers clusters displayed. ... additional argument passed train_magmaclust.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/select_nb_cluster.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Select the optimal number of clusters — select_nb_cluster","text":"list, containing results model selection procedure selecting optimal number clusters thanks V-BIC criterion maximisation. elements list : best_k: integer, indicating resulting optimal number clusters seq_vbic: vector, corresponding sequence V-BIC values associated models trained provided cluster's number grid_nb_cluster. trained_models: list, named associated number clusters, Magma MagmaClust models trained (approximated fast_approx = T) model selection procedure.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/select_nb_cluster.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Select the optimal number of clusters — select_nb_cluster","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/simu_db.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate a dataset tailored for MagmaClustR — simu_db","title":"Simulate a dataset tailored for MagmaClustR — simu_db","text":"Simulate complete training dataset, may representative various applications. Several flexible arguments allow adjustment number individuals, observed inputs, values many parameters controlling data generation.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/simu_db.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate a dataset tailored for MagmaClustR — simu_db","text":"","code":"simu_db(   M = 10,   N = 10,   K = 1,   covariate = F,   grid = seq(0, 10, 0.05),   common_input = T,   common_hp = T,   add_hp = F,   add_clust = F,   int_mu_v = c(0, 2),   int_mu_l = c(0, 2),   int_i_v = c(0, 2),   int_i_l = c(0, 2),   int_i_sigma = c(0, 1),   m0_slope = c(-5, 5),   m0_intercept = c(-10, 10),   int_covariate = c(-5, 5) )"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/simu_db.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate a dataset tailored for MagmaClustR — simu_db","text":"M integer. number individual per cluster. N integer. number observations per individual. K integer. number underlying clusters. covariate logical value indicating whether dataset include additional input covariate named 'Covariate'. grid vector numbers defining grid observations (.e. reference inputs). common_input logical value indicating whether reference inputs common individual. common_hp logical value indicating whether hyper-parameters common individual. TRUE K>1, hyper-parameters remain different clusters. add_hp logical value indicating whether values hyper-parameters added columns dataset. add_clust logical value indicating whether name clusters added column dataset. int_mu_v vector 2 numbers, defining interval admissible values variance hyper-parameter mean process' kernel. int_mu_l vector 2 numbers, defining interval admissible values lengthscale hyper-parameter mean process' kernel. int_i_v vector 2 numbers, defining interval admissible values variance hyper-parameter individual process' kernel. int_i_l vector 2 numbers, defining interval admissible values lengthscale hyper-parameter individual process' kernel. int_i_sigma vector 2 numbers, defining interval admissible values noise hyper-parameter. m0_slope vector 2 numbers, defining interval admissible values slope m0. m0_intercept vector 2 numbers, defining interval admissible values intercept m0. int_covariate vector 2 numbers, defining interval admissible values covariate inputs.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/simu_db.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate a dataset tailored for MagmaClustR — simu_db","text":"full dataset simulated training data.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/simu_db.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate a dataset tailored for MagmaClustR — simu_db","text":"","code":"if (FALSE) { simu_db(M = 5, N = 3) simu_db(M = 5, N = 3, common_input = FALSE) simu_db(M = 5, N = 3, common_hp = FALSE, add_hp = TRUE) simu_db(M = 5, N = 3, common_input = FALSE, common_hp = FALSE) }"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/simu_indiv_se.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate a batch a data — simu_indiv_se","title":"Simulate a batch a data — simu_indiv_se","text":"Simulate batch output data, corresponding one individual, coming GP Squared Exponential kernel covariance structure, specified hyper-parameters input.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/simu_indiv_se.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate a batch a data — simu_indiv_se","text":"","code":"simu_indiv_se(ID, input, covariate, mean, v, l, sigma)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/simu_indiv_se.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate a batch a data — simu_indiv_se","text":"ID identification code, whether numeric character. input vector numbers. input variable used 'reference' input outputs. covariate vector numbers. additional input variable, observed along reference input. mean vector numbers. Prior mean values GP. v number. variance hyper-parameter SE kernel. l number. lengthscale hyper-parameter SE kernel. sigma number. noise hyper-parameter.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/simu_indiv_se.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate a batch a data — simu_indiv_se","text":"tibble containing batch output data along input additional information simulated individual.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/simu_indiv_se.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate a batch a data — simu_indiv_se","text":"","code":"MagmaClustR:::simu_indiv_se(\"A\", 1:10, 0, rep(0, 10), 2, 1, 0.5) #> # A tibble: 10 × 7 #>    ID    Output Input Covariate se_variance se_lengthscale noise #>    <chr>  <dbl> <int>     <dbl>       <dbl>          <dbl> <dbl> #>  1 A     -0.282     1         0           2              1   0.5 #>  2 A      0.923     2         0           2              1   0.5 #>  3 A      3.05      3         0           2              1   0.5 #>  4 A      0.518     4         0           2              1   0.5 #>  5 A     -1.65      5         0           2              1   0.5 #>  6 A     -1.23      6         0           2              1   0.5 #>  7 A      0.713     7         0           2              1   0.5 #>  8 A      1.63      8         0           2              1   0.5 #>  9 A     -0.709     9         0           2              1   0.5 #> 10 A     -2.14     10         0           2              1   0.5 MagmaClustR:::simu_indiv_se(\"B\", 1:10, 2:11, 3:12, 1, 1, 1) #> # A tibble: 10 × 7 #>    ID    Output Input Covariate se_variance se_lengthscale noise #>    <chr>  <dbl> <int>     <int>       <dbl>          <dbl> <dbl> #>  1 B       3.07     1         2           1              1     1 #>  2 B       6.45     2         3           1              1     1 #>  3 B       7.17     3         4           1              1     1 #>  4 B       9.97     4         5           1              1     1 #>  5 B      12.5      5         6           1              1     1 #>  6 B      12.3      6         7           1              1     1 #>  7 B      16.0      7         8           1              1     1 #>  8 B      20.3      8         9           1              1     1 #>  9 B      21.6      9        10           1              1     1 #> 10 B      24.1     10        11           1              1     1 MagmaClustR:::simu_indiv_se(\"C\", 1:10, 5, rep(0, 10), 2, 1, 0.5) #> # A tibble: 10 × 7 #>    ID    Output Input Covariate se_variance se_lengthscale noise #>    <chr>  <dbl> <int>     <dbl>       <dbl>          <dbl> <dbl> #>  1 C      1.62      1         5           2              1   0.5 #>  2 C      0.355     2         5           2              1   0.5 #>  3 C     -0.411     3         5           2              1   0.5 #>  4 C      2.11      4         5           2              1   0.5 #>  5 C      2.82      5         5           2              1   0.5 #>  6 C      1.24      6         5           2              1   0.5 #>  7 C     -1.64      7         5           2              1   0.5 #>  8 C      0.480     8         5           2              1   0.5 #>  9 C      1.39      9         5           2              1   0.5 #> 10 C      0.368    10         5           2              1   0.5"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/sum_logL_GP_clust.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute a mixture of Gaussian log-likelihoods — sum_logL_GP_clust","title":"Compute a mixture of Gaussian log-likelihoods — sum_logL_GP_clust","text":"prediction step MagmaClust, EM algorithm used compute maximum likelihood estimator hyper-parameters along mixture probabilities new individual/task. function implements quantity maximised (.e. sum Gaussian log-likelihoods, weighted mixture probabilities). can also used monitor EM algorithm providing 'prop_mixture' argument, proper penalisation full log-likelihood.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/sum_logL_GP_clust.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute a mixture of Gaussian log-likelihoods — sum_logL_GP_clust","text":"","code":"sum_logL_GP_clust(   hp,   db,   mixture,   mean,   kern,   post_cov,   prop_mixture = NULL,   pen_diag )"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/sum_logL_GP_clust.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute a mixture of Gaussian log-likelihoods — sum_logL_GP_clust","text":"hp tibble, data frame named vector hyper-parameters. db tibble containing data want evaluate logL . Required columns: Input, Output. Additional covariate columns allowed. mixture tibble data frame, indicating mixture probabilities cluster new individual/task. mean list hyper-posterior mean parameters clusters. kern kernel function. post_cov list hyper-posterior covariance parameters clusters. prop_mixture tibble named vector. name column element refer cluster. value associated cluster number 0 1, corresponding mixture proportions. pen_diag jitter term added covariance matrix avoid numerical issues inverting, cases nearly singular matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/sum_logL_GP_clust.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute a mixture of Gaussian log-likelihoods — sum_logL_GP_clust","text":"number, expectation mixture Gaussian log-likelihoods prediction step MagmaClust. quantity supposed increase step EM algorithm, can used monitoring procedure.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/sum_logL_GP_clust.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute a mixture of Gaussian log-likelihoods — sum_logL_GP_clust","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/train_gp.html","id":null,"dir":"Reference","previous_headings":"","what":"Learning hyper-parameters of a Gaussian Process — train_gp","title":"Learning hyper-parameters of a Gaussian Process — train_gp","text":"Learning hyper-parameters new individual/task Magma required prediction procedure. function can also used learn hyper-parameters simple GP (just let hyperpost argument set NULL, use prior_mean instead). using within Magma, providing data new individual/task, hyper-posterior mean covariance parameters, initialisation values hyper-parameters, function computes maximum likelihood estimates hyper-parameters.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/train_gp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Learning hyper-parameters of a Gaussian Process — train_gp","text":"","code":"train_gp(   data,   prior_mean = NULL,   ini_hp = NULL,   kern = \"SE\",   hyperpost = NULL,   pen_diag = 1e-08 )"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/train_gp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Learning hyper-parameters of a Gaussian Process — train_gp","text":"data tibble data frame. Required columns: Input, Output. Additional columns covariates can specified. Input column define variable used reference observations (e.g. time longitudinal data). Output column specifies observed values (response variable). data frame can also provide many covariates desired, constraints column names. covariates additional inputs (explanatory variables) models also observed reference Input. prior_mean Mean parameter GP. argument can specified various formats, : NULL (default). hyper-posterior mean set 0 everywhere. number. hyper-posterior mean constant function. vector length distinct Input values data argument. vector considered evaluation hyper-posterior mean function training Inputs. function. function defined hyper-posterior mean. tibble data frame. Required columns: Input, Output. Input values include least values data argument. ini_hp named vector, tibble data frame hyper-parameters associated kern new individual/task. columns named according hyper-parameters used kern. cases model includes noise term, ini_hp contain additional 'noise' column. NULL (default), random values used initialisation. kern kernel function, defining covariance structure GP. Several popular kernels (see Kernel Cookbook) already implemented can selected within following list: \"SE\": (default value) Squared Exponential Kernel (also called Radial Basis Function Gaussian kernel), \"LIN\": Linear kernel, \"PERIO\": Periodic kernel, \"RQ\": Rational Quadratic kernel. Compound kernels can created sums products kernels. combining kernels, simply provide formula character string elements separated whitespaces (e.g. \"SE + PERIO\"). ² elements treated sequentially left right, product operator '*' shall always used '+' operators (e.g. 'SE * LIN + RQ' valid whereas 'RQ + SE * LIN'  ). hyperpost list, containing elements 'mean' 'cov', parameters hyper-posterior distribution mean process. Typically, argument come previous learning using train_magma, hyperposterior function. hyperpost provided, likelihood maximised one involved Magma's prediction step, prior_mean argument ignored. classic GP training, leave hyperpost NULL. pen_diag number. jitter term, added diagonal prevent numerical issues inverting nearly singular matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/train_gp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Learning hyper-parameters of a Gaussian Process — train_gp","text":"tibble, containing trained hyper-parameters kernel new individual/task.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/train_gp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Learning hyper-parameters of a Gaussian Process — train_gp","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/train_gp_clust.html","id":null,"dir":"Reference","previous_headings":"","what":"Prediction in MagmaClust: learning new HPs and mixture probabilities — train_gp_clust","title":"Prediction in MagmaClust: learning new HPs and mixture probabilities — train_gp_clust","text":"Learning hyper-parameters mixture probabilities new individual/task required MagmaClust prediction procedure. providing data new individual/task, hyper-posterior mean covariance parameters, mixture proportions, initialisation values hyper-parameters, train_gp_clust uses EM algorithm compute maximum likelihood estimates hyper-parameters hyper-posterior mixture probabilities new individual/task.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/train_gp_clust.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prediction in MagmaClust: learning new HPs and mixture probabilities — train_gp_clust","text":"","code":"train_gp_clust(   data,   prop_mixture = NULL,   ini_hp = NULL,   kern = \"SE\",   hyperpost = NULL,   pen_diag = 1e-08,   n_iter_max = 25,   cv_threshold = 0.001 )"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/train_gp_clust.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prediction in MagmaClust: learning new HPs and mixture probabilities — train_gp_clust","text":"data tibble data frame. Required columns: Input, Output. Additional columns covariates can specified. Input column define variable used reference observations (e.g. time longitudinal data). Output column specifies observed values (response variable). data frame can also provide many covariates desired, constraints column names. covariates additional inputs (explanatory variables) models also observed reference Input. prop_mixture tibble named vector. name column element refer cluster. value associated cluster number 0 1, corresponding mixture proportions. ini_hp tibble data frame hyper-parameters associated kern, individual process kernel. kern kernel function, defining covariance structure GP. Several popular kernels (see Kernel Cookbook) already implemented can selected within following list: \"SE\": (default value) Squared Exponential Kernel (also called Radial Basis Function Gaussian kernel), \"LIN\": Linear kernel, \"PERIO\": Periodic kernel, \"RQ\": Rational Quadratic kernel. Compound kernels can created sums products kernels. combining kernels, simply provide formula character string elements separated whitespaces (e.g. \"SE + PERIO\"). ² elements treated sequentially left right, product operator '*' shall always used '+' operators (e.g. 'SE * LIN + RQ' valid whereas 'RQ + SE * LIN'  ). hyperpost list, containing elements mean, cov mixture parameters hyper-posterior distributions mean processes. Typically, argument come previous learning using train_magmaclust, previous prediction pred_magmaclust, argument get_hyperpost set TRUE. pen_diag number. jitter term, added diagonal prevent numerical issues inverting nearly singular matrices. n_iter_max number, indicating maximum number iterations EM algorithm proceed reaching convergence. cv_threshold number, indicating threshold likelihood gain EM algorithm stop.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/train_gp_clust.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prediction in MagmaClust: learning new HPs and mixture probabilities — train_gp_clust","text":"list, containing results EM algorithm used prediction step MagmaClust. elements list : hp: tibble optimal hyper-parameters new individual's GP. mixture: tibble mixture probabilities new individual.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/train_gp_clust.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Prediction in MagmaClust: learning new HPs and mixture probabilities — train_gp_clust","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/train_magma.html","id":null,"dir":"Reference","previous_headings":"","what":"Training Magma with an EM algorithm — train_magma","title":"Training Magma with an EM algorithm — train_magma","text":"hyper-parameters hyper-posterior distribution involved Magma can learned thanks EM algorithm implemented train_magma. providing dataset, model hypotheses (hyper-prior mean parameter covariance kernels) initialisation values hyper-parameters, function computes maximum likelihood estimates HPs well mean covariance parameters Gaussian hyper-posterior distribution mean process.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/train_magma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Training Magma with an EM algorithm — train_magma","text":"","code":"train_magma(   data,   prior_mean = NULL,   ini_hp_0 = NULL,   ini_hp_i = NULL,   kern_0 = \"SE\",   kern_i = \"SE\",   common_hp = T,   grid_inputs = NULL,   pen_diag = 1e-08,   n_iter_max = 25,   cv_threshold = 0.001,   fast_approx = FALSE )"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/train_magma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Training Magma with an EM algorithm — train_magma","text":"data tibble data frame. Required columns: ID, Input , Output. Additional columns covariates can specified. ID column contains unique names/codes used identify individual/task (batch data). Input column define variable used reference observations (e.g. time longitudinal data). Output column specifies observed values (response variable). data frame can also provide many covariates desired, constraints column names. covariates additional inputs (explanatory variables) models also observed reference Input. prior_mean Hyper-prior mean parameter (m_0) mean GP. argument can specified various formats, : NULL (default). hyper-prior mean set 0 everywhere. number. hyper-prior mean constant function. vector length distinct Input values data argument. vector considered evaluation hyper-prior mean function training Inputs. function. function defined hyper_prior mean. tibble data frame. Required columns: Input, Output. Input values include least values data argument. ini_hp_0 named vector, tibble data frame hyper-parameters associated kern_0, mean process' kernel. columns/elements named according hyper-parameters used kern_0. NULL (default), random values used initialisation. ini_hp_i tibble data frame hyper-parameters associated kern_i, individual processes' kernel. Required column : ID. ID column contains unique names/codes used identify individual/task. columns named according hyper-parameters used kern_i. Compared ini_hp_0 contain additional 'noise' column initialise noise hyper-parameter model. NULL (default), random values used initialisation. kern_0 kernel function, associated mean GP. Several popular kernels (see Kernel Cookbook) already implemented can selected within following list: \"SE\": (default value) Squared Exponential Kernel (also called Radial Basis Function Gaussian kernel), \"LIN\": Linear kernel, \"PERIO\": Periodic kernel, \"RQ\": Rational Quadratic kernel. Compound kernels can created sums products kernels. combining kernels, simply provide formula character string elements separated whitespaces (e.g. \"SE + PERIO\"). elements treated sequentially left right, product operator '*' shall always used '+' operators (e.g. 'SE * LIN + RQ' valid whereas 'RQ + SE * LIN'  ). kern_i kernel function, associated individual GPs. (\"SE\", \"PERIO\" \"RQ\" also available ). common_hp logical value, indicating whether set hyper-parameters assumed common individuals. grid_inputs vector, indicating grid additional reference inputs mean process' hyper-posterior evaluated. pen_diag number. jitter term, added diagonal prevent numerical issues inverting nearly singular matrices. n_iter_max number, indicating maximum number iterations EM algorithm proceed reaching convergence. cv_threshold number, indicating threshold likelihood gain EM algorithm stop. convergence condition defined difference likelihoods two consecutive steps, divided absolute value last one ( \\((LL_n - LL_n-1) / |LL_n|\\) ). fast_approx boolean, indicating whether EM algorithm stop one iteration E-step. advanced feature mainly used provide faster approximation model selection procedure, preventing optimisation hyper-parameters.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/train_magma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Training Magma with an EM algorithm — train_magma","text":"list, gathering results EM algorithm used training Magma. elements list : hp_0: tibble trained hyper-parameters mean process' kernel. hp_i: tibble trained hyper-parameters individual processes' kernels. hyperpost: sub-list gathering parameters mean processes' hyper-posterior distributions, namely: mean: tibble, hyper-posterior mean parameter (Output) evaluated training reference Input. cov: matrix, covariance parameter hyper-posterior distribution mean process. pred: tibble, predicted mean variance Input mean process' hyper-posterior distribution format allows direct visualisation GP prediction. ini_args: list containing initial function arguments values hyper-prior mean, hyper-parameters. particular, arguments set NULL, ini_args allows us retrieve (randomly chosen) initialisations used training. seq_loglikelihood: vector, containing sequence log-likelihood values associated iteration. converged: logical value indicated whether EM algorithm converged . training_time: Total running time complete training.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/train_magma.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Training Magma with an EM algorithm — train_magma","text":"user can specify custom kernel functions argument kern_0 kern_i. hyper-parameters used kernel explicit names, contained within hp argument. hp typically defined named vector data frame. Although mandatory train_magma function run, gradients can provided within kernel function definition. See example se_kernel create custom kernel function displaying adequate format used Magma.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/train_magma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Training Magma with an EM algorithm — train_magma","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/train_magmaclust.html","id":null,"dir":"Reference","previous_headings":"","what":"Training MagmaClust with a Variational EM algorithm — train_magmaclust","title":"Training MagmaClust with a Variational EM algorithm — train_magmaclust","text":"hyper-parameters hyper-posterior distributions involved MagmaClust can learned thanks VEM algorithm implemented train_magmaclust. providing dataset, model hypotheses (hyper-prior mean parameters, covariance kernels number clusters) initialisation values hyper-parameters, function computes maximum likelihood estimates HPs well mean covariance parameters Gaussian hyper-posterior distributions mean processes.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/train_magmaclust.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Training MagmaClust with a Variational EM algorithm — train_magmaclust","text":"","code":"train_magmaclust(   data,   nb_cluster = NULL,   prior_mean_k = NULL,   ini_hp_k = NULL,   ini_hp_i = NULL,   kern_k = \"SE\",   kern_i = \"SE\",   ini_mixture = NULL,   common_hp_k = T,   common_hp_i = T,   grid_inputs = NULL,   pen_diag = 1e-08,   n_iter_max = 25,   cv_threshold = 0.001,   fast_approx = FALSE )"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/train_magmaclust.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Training MagmaClust with a Variational EM algorithm — train_magmaclust","text":"data tibble data frame. Columns required: ID, Input , Output. Additional columns covariates can specified. ID column contains unique names/codes used identify individual/task (batch data). Input column define variable used reference observations (e.g. time longitudinal data). Output column specifies observed values (response variable). data frame can also provide many covariates desired, constraints column names. covariates additional inputs (explanatory variables) models also observed reference Input. nb_cluster number, indicating number clusters individuals/tasks assumed exist among dataset. prior_mean_k set hyper-prior mean parameters (m_k) K mean GPs, one value cluster. cluster. argument can specified various formats, : NULL (default). hyper-prior means set 0 everywhere. numerical vector length number clusters. number associated one cluster, considered hyper-prior mean parameter cluster (.e. constant function Input). list functions. function associated one cluster. functions evaluated Input values, provide specific hyper-prior mean vectors cluster. ini_hp_k tibble data frame hyper-parameters associated kern_k, mean process' kernel. Required column : ID. ID column contains unique names/codes used identify cluster. columns named according hyper-parameters used kern_k. ini_hp_i tibble data frame hyper-parameters associated kern_i, individual processes' kernel. Required column : ID. ID column contains unique names/codes used identify individual/task. columns named according hyper-parameters used kern_i. kern_k kernel function, associated mean GPs. Several popular kernels (see Kernel Cookbook) already implemented can selected within following list: \"SE\": (default value) Squared Exponential Kernel (also called Radial Basis Function Gaussian kernel), \"LIN\": Linear kernel, \"PERIO\": Periodic kernel, \"RQ\": Rational Quadratic kernel. Compound kernels can created sums products kernels. combining kernels, simply provide formula character string elements separated whitespaces (e.g. \"SE + PERIO\"). elements treated sequentially left right, product operator '*' shall always used '+' operators (e.g. 'SE * LIN + RQ' valid whereas 'RQ + SE * LIN'  ). kern_i kernel function, associated individual GPs. (See details kern_k). ini_mixture Initial values probability belong cluster individual (ini_mixture can used k-means initialisation. Used default NULL). common_hp_k boolean indicating whether hyper-parameters common among mean GPs. common_hp_i boolean indicating whether hyper-parameters common among individual GPs. grid_inputs vector, indicating grid additional reference inputs mean processes' hyper-posteriors evaluated. pen_diag number. jitter term, added diagonal prevent numerical issues inverting nearly singular matrices. n_iter_max number, indicating maximum number iterations VEM algorithm proceed reaching convergence. cv_threshold number, indicating threshold likelihood gain VEM algorithm stop. convergence condition defined difference elbo two consecutive steps, divided absolute value last one ( \\((ELBO_n - ELBO_{n-1}) / |ELBO_n| \\) ). fast_approx boolean, indicating whether VEM algorithm stop one iteration VE-step. advanced feature mainly used provide faster approximation model selection procedure, preventing optimisation hyper-parameters.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/train_magmaclust.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Training MagmaClust with a Variational EM algorithm — train_magmaclust","text":"list, containing results VEM algorithm used training step MagmaClust. elements list : hp_k: tibble containing trained hyper-parameters mean process' kernel mixture proportions cluster. hp_i: tibble containing trained hyper-parameters individual processes' kernels. hyperpost: sub-list containing parameters mean processes' hyper-posterior distribution, namely: mean: list tibbles containing, cluster, hyper-posterior mean parameters evaluated Input. cov: list matrices containing, cluster, hyper-posterior covariance parameter mean process. mixture: tibble, indicating mixture probabilities cluster individual. ini_args: list containing initial function arguments values hyper-prior means, hyper-parameters. particular, arguments set NULL, ini_args allows us retrieve (randomly chosen) initialisations used training. seq_elbo: vector, containing sequence ELBO values associated iteration. converged: logical value indicated whether algorithm converged. training_time: Total running time complete training.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/train_magmaclust.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Training MagmaClust with a Variational EM algorithm — train_magmaclust","text":"user can specify custom kernel functions argument kern_k kern_i. hyper-parameters used kernel explicit names, contained within hp argument. hp typically defined named vector data frame. Although mandatory train_magmaclust function run, gradients can provided within kernel function definition. See example se_kernel create custom kernel function displaying adequate format used MagmaClust.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/train_magmaclust.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Training MagmaClust with a Variational EM algorithm — train_magmaclust","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/update_mixture.html","id":null,"dir":"Reference","previous_headings":"","what":"Update the mixture probabilities for each individual and each cluster — update_mixture","title":"Update the mixture probabilities for each individual and each cluster — update_mixture","text":"Update mixture probabilities individual cluster","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/update_mixture.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update the mixture probabilities for each individual and each cluster — update_mixture","text":"","code":"update_mixture(db, mean_k, cov_k, hp, kern, prop_mixture, pen_diag)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/update_mixture.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update the mixture probabilities for each individual and each cluster — update_mixture","text":"db tibble data frame. Columns required: ID, Input, Output. Additional columns covariates can specified. mean_k list K hyper-posterior mean parameters. cov_k list K hyper-posterior covariance matrices. hp named vector, tibble data frame hyper-parameters associated kern, individual process' kernel. columns/elements named according hyper-parameters used kern. kern kernel function, defining covariance structure individual GPs. prop_mixture tibble containing hyper-parameters associated individual, indicating cluster belongs. pen_diag number. jitter term, added diagonal prevent numerical issues inverting nearly singular matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/update_mixture.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Update the mixture probabilities for each individual and each cluster — update_mixture","text":"Compute hyper-posterior multinomial distributions updating mixture probabilities.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/update_mixture.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Update the mixture probabilities for each individual and each cluster — update_mixture","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/ve_step.html","id":null,"dir":"Reference","previous_headings":"","what":"E-Step of the VEM algorithm — ve_step","title":"E-Step of the VEM algorithm — ve_step","text":"Expectation step Variational EM algorithm used compute parameters hyper-posteriors distributions mean processes mixture variables involved MagmaClust.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/ve_step.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"E-Step of the VEM algorithm — ve_step","text":"","code":"ve_step(db, m_k, kern_k, kern_i, hp_k, hp_i, old_mixture, pen_diag)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/ve_step.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"E-Step of the VEM algorithm — ve_step","text":"db tibble data frame. Columns required: ID, Input, Output. Additional columns covariates can specified. m_k named list vectors, corresponding prior mean parameters K mean GPs. kern_k kernel function, associated K mean GPs. kern_i kernel function, associated M individual GPs. hp_k named vector, tibble data frame hyper-parameters associated kern_k. hp_i named vector, tibble data frame hyper-parameters associated kern_i. old_mixture list mixture values previous iteration. pen_diag number. jitter term, added diagonal prevent numerical issues inverting nearly singular matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/ve_step.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"E-Step of the VEM algorithm — ve_step","text":"named list, containing elements mean, tibble containing Input associated Output hyper-posterior mean parameters, cov, hyper-posterior covariance matrices, mixture, probabilities belong cluster individual.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/ve_step.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"E-Step of the VEM algorithm — ve_step","text":"","code":"if (FALSE) { k <- seq_len(3) m_k <- c(\"K1\" = 0, \"K2\" = 0, \"K3\" = 0)  db <- simu_db(N = 10, common_input = TRUE) hp_k <- MagmaClustR:::hp(\"SE\", list_ID = names(m_k)) hp_i <- MagmaClustR:::hp(\"SE\", list_ID = unique(db$ID))  old_mixture <- MagmaClustR:::ini_mixture(   db = db, k = length(k),   nstart = 50 ) prop_mixture_1 <- old_mixture %>% dplyr::select(-.data$ID) hp_k[[\"prop_mixture\"]] <- sapply(prop_mixture_1, function(x) {   x %>%     unlist() %>%     mean() })  MagmaClustR:::ve_step(db, m_k, \"SE\", \"SE\", hp_k, hp_i, old_mixture, 0.001) }"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/vm_step.html","id":null,"dir":"Reference","previous_headings":"","what":"V-Step of the VEM algorithm — vm_step","title":"V-Step of the VEM algorithm — vm_step","text":"Maximization step Variational EM algorithm used compute hyper-parameters kernels involved MagmaClust.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/vm_step.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"V-Step of the VEM algorithm — vm_step","text":"","code":"vm_step(   db,   old_hp_k,   old_hp_i,   list_mu_param,   kern_k,   kern_i,   m_k,   common_hp_k,   common_hp_i,   pen_diag )"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/vm_step.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"V-Step of the VEM algorithm — vm_step","text":"db tibble data frame. Columns required: ID, Input, Output. Additional columns covariates can specified. old_hp_k named vector, tibble data frame, containing hyper-parameters previous M-step (initialisation) associated mean GPs. old_hp_i named vector, tibble data frame, containing hyper-parameters previous  M-step (initialisation) associated individual GPs. list_mu_param List parameters K mean GPs. kern_k kernel used compute covariance matrix mean GP corresponding timestamps. kern_i kernel used compute covariance matrix individuals GP corresponding timestamps. m_k named list prior mean parameters K mean GPs. Length = 1 nrow(unique(db$Input)) common_hp_k boolean indicating whether hp common among mean GPs (mu_k) common_hp_i boolean indicating whether hp common among individual GPs (y_i) pen_diag number. jitter term, added diagonal prevent numerical issues inverting nearly singular matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/vm_step.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"V-Step of the VEM algorithm — vm_step","text":"named list, containing elements hp_k, tibble containing hyper-parameters associated cluster, hp_i, tibble containing hyper-parameters associated individual GPs, prop_mixture_k, tibble containing hyper-parameters associated individual, indicating probabilities belong cluster.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/vm_step.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"V-Step of the VEM algorithm — vm_step","text":"","code":"if (FALSE) {  ## Common inputs across individuals & cluster and differents HPs ## across individuals & Cluster k <- seq_len(2) m_k <- c(\"K1\" = 0, \"K2\" = 0)  db <- simu_db(N = 10, common_input = FALSE) hp_k <- MagmaClustR:::hp(\"SE\", list_ID = names(m_k)) hp_i <- MagmaClustR:::hp(\"SE\", list_ID = unique(db$ID))  old_mixture <- MagmaClustR:::ini_mixture(   db = db, k = length(k),   nstart = 50 ) prop_mixture_1 <- old_mixture %>% dplyr::select(-.data$ID) hp_k[[\"prop_mixture\"]] <- sapply(prop_mixture_1, function(x) {   x %>%     unlist() %>%     mean() })  post <- MagmaClustR:::ve_step(   db, m_k, \"SE\", \"SE\", hp_k, hp_i, old_mixture,   0.001 )  MagmaClustR:::vm_step(db, hp_k, hp_i, post, \"SE\", \"SE\", m_k, FALSE, FALSE, 2)   ## Different inputs across individuals & cluster and common HPs k <- seq_len(4) m_k <- c(\"K1\" = 0, \"K2\" = 0, \"K3\" = 0, \"K4\" = 0) db <- simu_db(N = 10, common_input = FALSE) hp_k <- MagmaClustR:::hp(\"SE\", list_ID = names(m_k), common_hp = TRUE) hp_i <- MagmaClustR:::hp(\"SE\", list_ID = unique(db$ID), common_hp = TRUE)  old_mixture <- MagmaClustR:::ini_mixture(   db = db, k = length(k),   nstart = 50 ) prop_mixture_1 <- old_mixture %>% dplyr::select(-.data$ID) hp_k[[\"prop_mixture\"]] <- sapply(prop_mixture_1, function(x) {   x %>%     unlist() %>%     mean() })  post <- MagmaClustR:::ve_step(   db, m_k, \"SE\", \"SE\", hp_k, hp_i, old_mixture,   0.001 )  MagmaClustR:::vm_step(db, hp_k, hp_i, post, \"SE\", \"SE\", m_k, TRUE, TRUE, 0.1) }"}]
