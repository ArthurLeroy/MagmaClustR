[{"path":"https://arthurleroy.github.io/MagmaClustR/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2021 Arthur Leroy Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/articles/example-in-2D.html","id":"purpose","dir":"Articles","previous_headings":"","what":"Purpose","title":"Multi-dimensional inputs in Magma","text":"Magma MagmaClust vignettes, emphasised , processed within MagmaClustR, dataset must contain least 3 mandatory columns: ID, Input Output. However, let us point Magma MagmaClust can also handle multi-dimensional inputs. Notice constraints names additional input columns (except name Reference used internally code strictly avoided). Throughout following synthetic example, Magma algorithm applied tackle 2-dimensional forecasting problem. specifically, model trained dataset contains 2 input variables, namely Input Covariate.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/articles/example-in-2D.html","id":"data-generation","dir":"Articles","previous_headings":"","what":"Data generation","title":"Multi-dimensional inputs in Magma","text":"explore features Magma 2D, simulate synthetic dataset thanks simu_db() function. customise dataset, can specify several parameters, : number K underlying clusters dataset. Since assume group structures data, set K = 1 (default). number M individuals per cluster. Even Magma performances improve respect number training individuals, 30 enough get idea 2D version works. Thus, specify M = 31: 30 individuals training, 1 prediction. number N observations per individual. , set N = 10 data points. presence / absence additional input named Covariate. want handle multi-dimensional inputs, specify covariate = TRUE. fact individuals share common inputs (regular irregular measurements among individuals). , set common_input = FALSE define grid covers various regions input space (Input Covariate). Many additional arguments available, see simu_db() details. provide visual intuition values contained training set, can display raw data (using signature gradient colour MagmaClustR ;) ) following code:  Let us mention dataset MagmaClustR can regularised necessary (sense can modify input grid match specific format). end, regularize_data() function proposed, allowing us constrain number data points per input, specify ‘hand’ surrogate grid inputs project data. function takes arguments: data,corresponding database want regularise; size_grid, indicating many points axis grid must contain; grid_inputs, grid want project data. NULL (default), dedicated grid inputs defined: input column, regular sequence created min input values max, number equispaced points equal ‘size_grid’ argument. also project data specific grid_inputs (may come dedicated expand_grid_inputs() function; see Customise graphs details). grid necessarily number points along axes. summarise_fct, function used summarise data points several similar inputs associated different outputs. instance, want evaluate synthetic dataset \\(5 \\times 5\\) grid inputs summarise projected outputs according mean, call: Finally, split individuals training prediction sets.","code":"set.seed(3) data_dim2 <- simu_db(M = 31,                       N = 10,                       K = 1,                       covariate = TRUE,                      common_input = FALSE)  knitr::kable(head(data_dim2)) ggplot(data_dim2) +   geom_tile(aes(x = Input, y = Covariate, fill = Output)) +   theme_classic() +   scale_fill_gradientn(colours = c(     \"white\",     \"#FDE0DD\",     \"#FCC5C0\",     \"#FA9FB5\",     \"#F768A1\",     \"#DD3497\",     \"#AE017E\",     \"#7A0177\")) data_dim2_reg <- regularize_data(data = data_dim2,                              size_grid = 5,                              grid_inputs = NULL,                              summarise_fct = \"mean\")  knitr::kable(head(data_dim2_reg)) dim2_train <- data_dim2 %>% filter(ID %in% 1:30) dim2_pred <- data_dim2 %>% filter(ID == 31)"},{"path":"https://arthurleroy.github.io/MagmaClustR/articles/example-in-2D.html","id":"training-and-prediction-in-2-d","dir":"Articles","previous_headings":"","what":"Training and prediction in 2-D","title":"Multi-dimensional inputs in Magma","text":"overall process Magma remains identical 1-D case, can decomposed 3 main steps: training, prediction plotting results. refer Magma vignette complete description classical pipeline: - call train_magma() function train model: perform prediction new individual thanks pred_magma(). , specify grid_inputs argument; case, default grid automatically generated pred_magma(), ranging min max Input Covariate values dataset. However, want perform prediction specific 2-D area, provide specific grid_inputs; see Even prettier graphics section details. display results plot_gp(). step constitutes main evolution one-dimensional version, devote entire section discuss .","code":"set.seed(3) model_dim2 <- train_magma(data = dim2_train,                            kern_0 = \"SE\",                           kern_i = \"SE\",                           common_hp = TRUE) #> The 'prior_mean' argument has not been specified. The hyper_prior mean function is thus set to be 0 everywhere. #>   #> The 'ini_hp_0' argument has not been specified. Random values of hyper-parameters for the mean process are used as initialisation. #>   #> The 'ini_hp_i' argument has not been specified. Random values of hyper-parameters for the individal processes are used as initialisation. #>   #> EM algorithm, step 1: 9.19 seconds  #>   #> Value of the likelihood: -1113.45324 --- Convergence ratio = Inf #>   #> EM algorithm, step 2: 7.21 seconds  #>   #> Value of the likelihood: -1079.21656 --- Convergence ratio = 0.03172 #>   #> EM algorithm, step 3: 7.18 seconds  #>   #> Value of the likelihood: -1078.66572 --- Convergence ratio = 0.00051 #>   #> The EM algorithm successfully converged, training is completed.  #> pred_dim2  <- pred_magma(data = dim2_pred,                          trained_model = model_dim2,                          plot = FALSE) #> The hyper-posterior distribution of the mean process provided in 'hyperpost' argument isn't evaluated on the expected inputs. #>   #>  Start evaluating the hyper-posterior on the correct inputs... #>   #> The 'prior_mean' argument has not been specified. The hyper-prior mean function is thus set to be 0 everywhere. #>   #> Done! #>"},{"path":"https://arthurleroy.github.io/MagmaClustR/articles/example-in-2D.html","id":"display-of-results","dir":"Articles","previous_headings":"","what":"Display of results","title":"Multi-dimensional inputs in Magma","text":"plot_gp() function, can display predicted posterior mean values ID = 31. prediction represented 2-D heatmap probabilities : x-axis corresponds Input column dataset; y-axis, Covariate column; (x,y) couple inputs associated colour (colour gradient range) corresponding posterior mean value input. darker posterior mean, higher value; uncertainty represented graph transparency/opacity associated previous colour. narrower 95% Credible Interval, opaque associated colour. Unfortunately, 2-D inputs inevitably lead constraints comes visualisation, preventing us provide much information 1-D. particular, graph display mean process training data, able find appropriate representations (also surcharge graph).","code":"plot_gp(pred_gp = pred_dim2,         data = dim2_pred)"},{"path":[]},{"path":"https://arthurleroy.github.io/MagmaClustR/articles/example-in-2D.html","id":"with-a-specific-grid-of-inputs","dir":"Articles","previous_headings":"Display of results > Customise graphs","what":"With a specific grid of inputs","title":"Multi-dimensional inputs in Magma","text":"unidimensional version, can create grid inputs want perform prediction specific 2D area (potentially wider dataset one). Contrary unidimensional version, grid_inputs can longer simple sequence numbers prediction must performed, 2D grid containing : x-axis, sequence Input want perform prediction ; y-axis, sequence Covariate want perform prediction. create grid, use create_grid_inputs() function. specify sequence Input many covariates want. However, must also ensure generate much data points ; recall Magma cubic complexity, execution can extremely long depending number length sequences. Therefore, advise reduce length Inputs sequences want perform high dimensional prediction. Moreover, Input must name data base avoid errors prediction step.  , perform prediction grid_inputs wider one generated automatically pred_magma(). Input values higher dataset ones, observations available, neither ID = 31 training dataset. Magma behaves expected, slow drifting prior mean (, zero) highly increasing variance.","code":"grid_inputs_dim2 <- expand_grid_inputs(Input = seq(0,10,0.5), Covariate = seq(0,10,0.5))  pred_dim2  <- pred_magma(data = dim2_pred,                          trained_model = model_dim2,                          grid_inputs = grid_inputs_dim2,                          plot = TRUE) #> The hyper-posterior distribution of the mean process provided in 'hyperpost' argument isn't evaluated on the expected inputs. #>   #>  Start evaluating the hyper-posterior on the correct inputs... #>   #> The 'prior_mean' argument has not been specified. The hyper-prior mean function is thus set to be 0 everywhere. #>   #> Done! #>"},{"path":"https://arthurleroy.github.io/MagmaClustR/articles/example-in-2D.html","id":"create-a-2d-gif","dir":"Articles","previous_headings":"Display of results > Customise graphs","what":"Create a 2D GIF","title":"Multi-dimensional inputs in Magma","text":"1-D Magma, possible create animated representations thanks pred_gif() plot_gif(). functions offer dynamic plots generating GIFs thanks gganimate package. , can observe prediction evolves add data points prediction dataset. pred_gif() plot_gif() functions work pred_magma() plot_gp() 2D version. extra arguments can customized plot_gif(), like adjusting GIF speed, saving plotted GIF, etc…","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/articles/example-in-2D.html","id":"magma-2-d-vs-gp-2-d","dir":"Articles","previous_headings":"Display of results > Customise graphs > Create a 2D GIF","what":"Magma 2-D vs GP 2-D","title":"Multi-dimensional inputs in Magma","text":"MagmaClustR package also provides prediction classic GPs 2D; thus, can compare Magma classic GPs predictions. graphs correspond 2D dynamic prediction Magma (first one) classic GP (second one).   example highlights advantage sharing information across individuals: even seeing data, Magma provides already accurate mean process. add data individual interest, uncertainty predictions slightly decreases, although main trend remains mainly similar. hand, classic GP struggles find shape underlying process. unobserved regions graph, prediction remains far original process. expected, though, data add, better becomes prediction standard GP.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/articles/how-to-use-magma.html","id":"context","dir":"Articles","previous_headings":"","what":"Context","title":"How to use Magma","text":"explore different features Magma, use swimmers dataset provided French Swimming Federation (available , studied thoroughly ). dataset gathers competition results 100m freestyle events 2002 2016 1725 men 1731 women, total 38481 38351 performances, respectively. Throughout swimmers example, use Magma decision support tool detect promising young athletes, classical problem elite sport context. specifically, Magma used model swimmers progression curves forecast future performances. Indeed, multi-task GPs model offers new perspectives like probabilistic predictions, provides insights sport structures future decisions. generally, task train model large dataset predict new individual thanks shared information. get better idea swimmers dataset content, display performances 5 swimmers according age. swimmers progress , .e. pattern? successful young swimmers remain best get older? kind questions aim tackle following.  plot highlights sparsity irregularity functional data; swimmers performances observed irregularly, areas containing observations (particularly younger ages). Moreover, clearly appears different swimmer profiles, especially due different evolutions morphology teen years. Therefore, might important take account one wants improve quality talent detection strategies.","code":"ggplot2::ggplot(data=swimmers %>% filter(ID %in% 1:5),        mapping = ggplot2::aes(x=Age,y=Performance,colour=factor(ID)))+   ggplot2::geom_point(size=3) +   ggplot2::theme_classic() +   ggplot2::guides(colour=\"none\")"},{"path":"https://arthurleroy.github.io/MagmaClustR/articles/how-to-use-magma.html","id":"dataset-format","dir":"Articles","previous_headings":"Context","what":"Dataset format","title":"How to use Magma","text":"swimmers dataset contains 4 columns: ID, Age, Performance Gender. row represents performance realised swimmer given age. specifically, column contains: ID, identifying number associated swimmer; Age, age swimmer moment performance; Performance, chronometric performance 100m freestyle (seconds); Gender, number indicating competitive gender swimmer (1 corresponds men 2 women). new variables (weight, height, number training hours …) observed, additional column treated covariate, thus result model multi-dimensional inputs. starting use Magma, must ensure dataset contains least three following mandatory columns adequate type: - ID: character factor; - Input: numeric; - Output: numeric.","code":"knitr::kable(swimmers[1:5,])"},{"path":"https://arthurleroy.github.io/MagmaClustR/articles/how-to-use-magma.html","id":"classical-pipeline","dir":"Articles","previous_headings":"","what":"Classical pipeline","title":"How to use Magma","text":"overall process Magma algorithm can decomposed 3 main steps: training, prediction plotting results. corresponding functions : train_magma() pred_magma() plot_gp()","code":""},{"path":[]},{"path":"https://arthurleroy.github.io/MagmaClustR/articles/how-to-use-magma.html","id":"data-organisation","dir":"Articles","previous_headings":"Applying Magma on the swimmer dataset","what":"Data organisation","title":"How to use Magma","text":"sake consistency, split male female swimmers different datasets: swimmers_m swimmers_f. following study dedicated women performances thus focus swimmers_f dataset. addition, need change name input output columns indicated , remove Gender one. continue data management procedure, swimmers allocated two groups: use train model; one predict future performances; let’s give fictive name Michaela. limit computation time illustrative example, randomly select 20 swimmers training. Even performances Magma increase number training individuals, 20 enough get clear idea algorithm works.  triangles correspond Michaela’s performances, whereas coloured dots represent swimmers data use training.","code":"swimmers_m <- swimmers %>% filter(Gender == 1) %>%   select(-Gender) %>%    rename(Input = Age, Output = Performance)  swimmers_f <- swimmers %>% filter(Gender == 2) %>%   select(-Gender) %>%   rename(Input = Age, Output = Performance) set.seed(3) list_ID <- swimmers_f %>% pull(ID) %>% sample() swimmers_train <- swimmers_f %>% filter(ID %in% list_ID[1:20]) swimmers_pred <- swimmers_f %>% filter(ID == 1718) ggplot2::ggplot(data=swimmers_train,        mapping = ggplot2::aes(x=Input,y=Output,colour=factor(ID)))+   ggplot2::geom_point(size=1.5,alpha=0.3)+   ggplot2::geom_point(data = swimmers_pred,              size=3,              shape=17,              color=\"black\") +   ggplot2::theme_classic() +   ggplot2::guides(colour=\"none\")"},{"path":"https://arthurleroy.github.io/MagmaClustR/articles/how-to-use-magma.html","id":"training","dir":"Articles","previous_headings":"Applying Magma on the swimmer dataset","what":"Training","title":"How to use Magma","text":"’s now time train model thanks train_magma(), several arguments can specified: prior_mean: assume prior knowledge 100m freestyle, can decide leave default value parameter (.e. zero). However, want take expert advice account, can modify value prior_mean accordingly. kern: relationship observed data prediction targets can control covariance kernel. Therefore, order correctly fit data, need choose suitable covariance kernel. case swimmers, want smooth progression curve Michaela; therefore, specify kern = \"SE\". commonly used kernels properties discussed kernel cookbook. Details available kernels combine package available help(train_magma). common_hp: , assume set hyper-parameters common individuals. Thus, model context individuals represent different trajectories process, whereas different hyper-parameters indicate different covariance structures thus flexible model. GP method, initialisation hyper-parameters may influence final optimisation lead inadequate prediction pathological cases. Therefore, users may explicitly define specific initial values dedicated ini_hp argument. parameters can also specified; see help(train_magma) details.","code":"set.seed(3) model <- train_magma(data = swimmers_train,                      kern_0 = \"SE\",                      kern_i = \"SE\",                      common_hp = TRUE) #> The 'prior_mean' argument has not been specified. The hyper_prior mean function is thus set to be 0 everywhere. #>   #> The 'ini_hp_0' argument has not been specified. Random values of hyper-parameters for the mean process are used as initialisation. #>   #> The 'ini_hp_i' argument has not been specified. Random values of hyper-parameters for the individal processes are used as initialisation. #>   #> EM algorithm, step 1: 13.17 seconds  #>   #> Value of the likelihood: -1306.49373 --- Convergence ratio = Inf #>   #> EM algorithm, step 2: 8.02 seconds  #>   #> Value of the likelihood: -1240.07975 --- Convergence ratio = 0.05356 #>   #> EM algorithm, step 3: 4.5 seconds  #>   #> Value of the likelihood: -1228.43093 --- Convergence ratio = 0.00948 #>   #> EM algorithm, step 4: 5.73 seconds  #>   #> Value of the likelihood: -1225.32467 --- Convergence ratio = 0.00254 #>  #> Warning in train_magma(data = swimmers_train, kern_0 = \"SE\", kern_i = \"SE\", : #> The likelihood descreased. Possible numerical issues. #> EM algorithm, step 5: 5.76 seconds  #>   #> Value of the likelihood: -1225.33011 --- Convergence ratio = 0 #>   #> The EM algorithm successfully converged, training is completed.  #>"},{"path":"https://arthurleroy.github.io/MagmaClustR/articles/how-to-use-magma.html","id":"prediction-for-michaela","dir":"Articles","previous_headings":"Applying Magma on the swimmer dataset","what":"Prediction for Michaela","title":"How to use Magma","text":"Magma model trained, can now predict predict evolution Michaela’s performances. perform prediction, need specify two main parameters pred_magma() function: data: case, sub-dataset containing Michaela’s current performances; trained_model, corresponds model just trained 20 swimmers. Let us mention improvements swimming prominent young ages, thus aim predict evolution Michaela’s performances 10 20 years. Therefore, argument grid_inputs = seq(10,20,0.1) can set compute forecast interest.","code":"pred <- pred_magma(data = swimmers_pred,   trained_model = model,   grid_inputs = seq(10,20,0.1),   plot = FALSE) #> The hyper-posterior distribution of the mean process provided in 'hyperpost' argument isn't evaluated on the expected inputs. #>   #>  Start evaluating the hyper-posterior on the correct inputs... #>   #> The 'prior_mean' argument has not been specified. The hyper-prior mean function is thus set to be 0 everywhere. #>   #> Done! #>"},{"path":"https://arthurleroy.github.io/MagmaClustR/articles/how-to-use-magma.html","id":"plots","dir":"Articles","previous_headings":"Applying Magma on the swimmer dataset","what":"Plots","title":"How to use Magma","text":"plot_gp() function can used depict evolution Michaela’s predicted performances. figure, can observe: prediction curve (purple line) associated 95% credibility interval (pink band); training data points background (displayed data_train). colour corresponds one swimmer; trained mean process dashed black line coming prior_mean parameter.","code":"plot_gp(pred_gp = pred,         data = swimmers_pred,         prior_mean = model$hyperpost$mean,         data_train = swimmers_train)"},{"path":"https://arthurleroy.github.io/MagmaClustR/articles/how-to-use-magma.html","id":"magma-vs-classic-gp","dir":"Articles","previous_headings":"Applying Magma on the swimmer dataset > Plots","what":"Magma VS classic GP","title":"How to use Magma","text":"MagmaClustR package also provides implementation standard GP regression, can compare Magma example. details fit single GP, see Vignette GPs. graphs correspond predictions Michaela’s performances 10 23 years, according Magma (left) standard GP (right).  visual comparison, 3 distinct phases can highlighted: first phase: close Michaela’s observed data (\\(t \\[ 11, 14 ]\\)), two processes behave similarly. note slight increase variance Magma, logical since prediction also takes uncertainty mean GP account; second phase: intervals unobserved timestamps containing data points training dataset (\\(t \\[ 14, 20 ]\\)), Magma prediction guided information coming individuals mean GP. Thus, mean trajectory remains coherent uncertainty increases slightly. contrary, simple GP quickly drifts prior zero mean soon data lack, uncertainty increases significantly. third phase: observations available, neither new individual training dataset (\\(t > 20\\)), Magma behaves expected, slow drift prior mean, highly increasing variance. Therefore, main improvement prediction brought Magma lies second phase thanks information shared across individuals. Overall, multi-task framework provides reliable probabilistic predictions new swimmer wider range timestamps, potentially outside usual scope GPs. Furthermore, uncertainty provided predictive posterior distribution offers adequate degree caution decision-making process.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/articles/how-to-use-magma.html","id":"comparison-of-individuals","dir":"Articles","previous_headings":"Applying Magma on the swimmer dataset > Plots","what":"Comparison of individuals","title":"How to use Magma","text":"compare evolution genders, display progression curves predicted Magma fictive male swimmer, called Michael (right) randomly selected within swimmers_m, along one Michaela (left).  can note genders present similar patterns progression: quick improvement performances young ages, slowdown progress can even leads stagnation afterwards. However, performances roughly similar mean trend age 14, start differentiate afterwards converge average times approximately 5sec gap. Interestingly, difference men women world records swimming 100m freestyle competitions currently 4.8sec (46.91 versus 51.71), consistent difference convergence times two mean processes.","code":"## Draw a random subset for training and an individual for prediction set.seed(9) list_ID_m <- swimmers_m %>% pull(ID) %>% unique() %>% sample() swimmers_train_m <- swimmers_m %>% filter(ID %in% list_ID_m[1:20]) swimmers_pred_m <- swimmers_m %>% filter(ID %in% list_ID_m[24])  ## Train Magma on the male swimmers sub-dataset model_m <- train_magma(data = swimmers_train_m,                         kern_0 = \"SE\",                         kern_i = \"SE\",                         common_hp = TRUE) #> The 'prior_mean' argument has not been specified. The hyper_prior mean function is thus set to be 0 everywhere. #>   #> The 'ini_hp_0' argument has not been specified. Random values of hyper-parameters for the mean process are used as initialisation. #>   #> The 'ini_hp_i' argument has not been specified. Random values of hyper-parameters for the individal processes are used as initialisation. #>   #> EM algorithm, step 1: 14.98 seconds  #>   #> Value of the likelihood: -1429.85339 --- Convergence ratio = Inf #>   #> EM algorithm, step 2: 4.8 seconds  #>   #> Value of the likelihood: -1411.45109 --- Convergence ratio = 0.01304 #>   #> EM algorithm, step 3: 5.8 seconds  #>   #> Value of the likelihood: -1409.66547 --- Convergence ratio = 0.00127 #>   #> EM algorithm, step 4: 6.01 seconds  #>   #> Value of the likelihood: -1409.69392 --- Convergence ratio = -2e-05 #>   #> The EM algorithm successfully converged, training is completed.  #>   ## Compute a prediction for Michael  pred_m <- pred_magma(data = swimmers_pred_m,   trained_model = model_m,   grid_inputs = seq(10,20,0.1),   plot = FALSE) #> The hyper-posterior distribution of the mean process provided in 'hyperpost' argument isn't evaluated on the expected inputs. #>   #>  Start evaluating the hyper-posterior on the correct inputs... #>   #> The 'prior_mean' argument has not been specified. The hyper-prior mean function is thus set to be 0 everywhere. #>   #> Done! #>"},{"path":[]},{"path":"https://arthurleroy.github.io/MagmaClustR/articles/how-to-use-magma.html","id":"with-plot_gp","dir":"Articles","previous_headings":"Customise graphs","what":"With plot_gp()","title":"How to use Magma","text":"case 1-dimensional inputs, can depict Michaela’s prediction graphs thanks plot_gp() function. Indeed, setting argument heatmap = TRUE, can display heatmap probabilities instead using 95% credibility interval. , get thorough visual quantification dispersion predicted values confidence may grant .","code":"plot_gp(pred_gp = pred_f,         data = swimmers_pred,         data_train = swimmers_train,         prior_mean = model$hyperpost$mean,         heatmap = TRUE)"},{"path":"https://arthurleroy.github.io/MagmaClustR/articles/how-to-use-magma.html","id":"create-a-gif","dir":"Articles","previous_headings":"Customise graphs","what":"Create a GIF","title":"How to use Magma","text":"want create animated representations, please use pred_gif() plot_gif() functions, instead pred_magma() plot_gp(). functions offer dynamic plots generating GIFs thanks gganimate package. graphs exhibit GP prediction evolves observe data points. pred_gif() plot_gif() functions work pred_magma() plot_gp() (except plot argument required pred_gif()). extra arguments can customized plot_gif(), like adjusting GIF speed, saving plotted GIF (see ?gganimate details)","code":"pred_gif  <- pred_gif(data = swimmers_pred,   trained_model = model,   grid_inputs = seq(10,20,0.1)) #>  => 1 => 2 => 3 => 4 => 5 => 6 => 7 => 8 => 9 => 10 => 11 => 12 => 13 => 14 => 15 => 16 => 17 plot_gif(pred_gp = pred_gif,          data = swimmers_pred,          data_train = swimmers_train,          prior_mean = model$hyperpost$mean,          alpha_data_train = 0.3)"},{"path":"https://arthurleroy.github.io/MagmaClustR/articles/how-to-use-magma.html","id":"reference","dir":"Articles","previous_headings":"","what":"Reference","title":"How to use Magma","text":"example highlights interest using multi-task GP predict swimmers performances. However, results restricted illustrative study. details, complete derivation algorithm experiments published available MAGMA: inference prediction using multi-task Gaussian processes common mean.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/articles/how-to-use-magma.html","id":"to-go-further-from-magma-to-magmaclust","dir":"Articles","previous_headings":"","what":"To go further: from Magma to MagmaClust","title":"How to use Magma","text":"underline main limitation Magma, now propose predict performances elite female swimmer dataset (60sec) instead Michaela’s.  Due high level swimmer, performances far mean GP. Thus, try predict future evolution, may actually underestimate potential; indeed, progression curve increases significantly data left, reaches mean process. Although, behaviour expected since prediction guided information coming individuals (mean process) less successful , method benefit accounting differences individual training dataset. enabling cluster-specific mean processes take account different swimmers profiles relevant extension. enhancement Magma corresponds MagmaClust algorithm; see corresponding vignette information.","code":""},{"path":[]},{"path":"https://arthurleroy.github.io/MagmaClustR/articles/how-to-use-magmaclust.html","id":"context","dir":"Articles","previous_headings":"Data and purpose","what":"Context","title":"How to use MagmaClust","text":"explore features MagmaClust, use weight dataset available , coming GUSTO cohort study (https://www.gusto.sg/) thoroughly studied ). dataset contains 3629 weight measurements Singaporean children (174 boys 168 girls, respectively). Throughout example, use MagmaClust model forecast evolution children’s weight early childhood. extension Magma model proposed take account presence group structures within data (similar vignette Magma available ) enhance predictions. generally, aim train model dataset containing multiple individuals predict new individual’s weight thanks shared information within clusters. get better idea weight dataset content, display illustration observed data 5 children. children’s weights evolve , .e. pattern? Can identify group structures data, define appropriate clusters? kind questions aim tackle following.  plot underlines regularity functional data. values weight observed ages children, measurements collected context standardised cohort study. Let us note MagmaClust can also used case irregular input grids without change. Overall, can notice differences children profiles; plump birth weight gain slows quickly, others may born slightly thinner grow faster. Therefore, might important take profiles account one wants improve quality weight predictions.","code":"set.seed(10) list_ID <- weight %>% pull(ID) %>%  sample()  ggplot2::ggplot(data=weight %>% filter(ID %in% list_ID[1:5]),                 ggplot2::aes(x=Input,y=Output,colour=factor(ID)))+   ggplot2::geom_point(size=3) +   ggplot2::theme_classic() +   ggplot2::guides(colour=\"none\")"},{"path":"https://arthurleroy.github.io/MagmaClustR/articles/how-to-use-magmaclust.html","id":"data-formatting","dir":"Articles","previous_headings":"Data and purpose","what":"Data formatting","title":"How to use MagmaClust","text":"weight dataset contains 4 columns: ID, sex, Input Output. row corresponds weight measured child given age. specifically, column contains: - ID, identifying number associated child; - sex, factor indicating biological gender child (Male Female); - Input, age child (months); - Output, weight child (kilograms). new variables (height, morphology, percentage muscle mass …) observed, additional column treated covariate, thus result model multi-dimensional inputs. starting use MagmaClust, must ensure dataset contains least three following mandatory columns adequate type: - ID: character factor; - Input: numeric; - Output: numeric. Since children weight particularly affected gender 0 5 years old, chose maintain individuals dataset. Therefore, sex column removed simplicity.","code":"knitr::kable(head(weight)) weight <- weight %>% select(-sex)"},{"path":"https://arthurleroy.github.io/MagmaClustR/articles/how-to-use-magmaclust.html","id":"classical-pipeline","dir":"Articles","previous_headings":"","what":"Classical pipeline","title":"How to use MagmaClust","text":"overall process MagmaClust algorithm can decomposed 3 main steps: training, prediction display results. corresponding functions : train_magmaclust() pred_magmaclust() plot_magmaclust()","code":""},{"path":[]},{"path":"https://arthurleroy.github.io/MagmaClustR/articles/how-to-use-magmaclust.html","id":"data-organisation","dir":"Articles","previous_headings":"Apply MagmaClust on the weight database","what":"Data organisation","title":"How to use MagmaClust","text":"data organisation step done, randomly select two types children: use train model; one predict future performances; let’s give fictive name James. limit computation time illustrative example, randomly select 20 children training. Even performances MagmaClust increase number training individuals, 20 enough get clear idea algorithm works.  triangles correspond James’ weight different ages, whereas coloured dots children’ data use training.","code":"weight_train <- weight %>% filter(ID %in% list_ID[1:20]) weight_pred <- weight %>% filter(ID == list_ID[261]) %>% filter(Input<20) weight_test <- weight %>% filter(ID == list_ID[261]) %>% filter(Input>20) ggplot2::ggplot(data = weight_train,        mapping = ggplot2::aes(x=Input,y=Output,colour=factor(ID)))+   ggplot2::geom_point(size=1.5,alpha=0.3)+   ggplot2::geom_point(data = weight_pred,              size=3,              shape=17,              col=\"black\") +   ggplot2::theme_classic() +   ggplot2::guides(colour=\"none\")"},{"path":"https://arthurleroy.github.io/MagmaClustR/articles/how-to-use-magmaclust.html","id":"training","dir":"Articles","previous_headings":"Apply MagmaClust on the weight database","what":"Training","title":"How to use MagmaClust","text":"’s now time train model thanks train_magmaclust(), several arguments can specified: nb_cluster: clustering method, provide number K clusters hypothesis model. illustration purposes, arbitrarily set \\(K = 3\\) following example. However, dedicated model selection method based maximising VBIC criterion provided package select_nb_clusters(). kern: relationship observed data prediction targets can control covariance kernel. Therefore, order correctly fit data, need choose suitable covariance kernel. case swimmers, want smooth progression curve James; therefore, specify kern = \"SE\". commonly used kernels properties discussed kernel cookbook. Details available kernels combine available help(train_magma). common_hp_k: , assume set hyper-parameters cluster setting common_hp_k = TRUE. Thus, suppose clusters share covariance structure. property implies shapes variations curves assumed roughly identical one cluster another; differentiation mainly due mean values. common_hp_i: want share information across children, specify common_hp_i = TRUE. assumption may appear restrictive first glance, actually offers valuable way share common patterns tasks. GP method, initialisation HP may influence final optimisation leads inadequate prediction pathological cases. Therefore, users may explicitly define specific initial values dedicated arguments: ini_hp_k ini_hp_i. parameters can also specified; see help (train_magmaclust) details.","code":"set.seed(10) model_clust <- train_magmaclust(data = weight_train,                         nb_cluster = 3,                         kern_k = \"SE\",                         kern_i = \"SE\",                         common_hp_k = TRUE,                         common_hp_i = TRUE) #> The 'ini_hp_i' argument has not been specified. Random values of hyper-parameters for the individual processes are used as initialisation. #>   #> The 'ini_hp_k' argument has not been specified. Random values of hyper-parameters for the mean processes are used as initialisation. #>   #> The 'prior_mean' argument has not been specified. The hyper_prior mean function is thus set to be 0 everywhere. #>   #> VEM algorithm, step 1: 17.33 seconds  #>   #> Value of the elbo: -614.01449 --- Convergence ratio = Inf #>   #> VEM algorithm, step 2: 9.63 seconds  #>   #> Value of the elbo: -490.95276 --- Convergence ratio = 0.25066 #>   #> VEM algorithm, step 3: 13.24 seconds  #>   #> Value of the elbo: -431.92637 --- Convergence ratio = 0.13666 #>   #> VEM algorithm, step 4: 10.3 seconds  #>   #> Value of the elbo: -399.90849 --- Convergence ratio = 0.08006 #>   #> VEM algorithm, step 5: 8.65 seconds  #>   #> Value of the elbo: -392.73377 --- Convergence ratio = 0.01827 #>   #> VEM algorithm, step 6: 10.25 seconds  #>   #> Value of the elbo: -389.33247 --- Convergence ratio = 0.00874 #>   #> VEM algorithm, step 7: 7.07 seconds  #>   #> Value of the elbo: -387.01608 --- Convergence ratio = 0.00599 #>   #> VEM algorithm, step 8: 7.17 seconds  #>   #> Value of the elbo: -385.18784 --- Convergence ratio = 0.00475 #>   #> VEM algorithm, step 9: 7.09 seconds  #>   #> Value of the elbo: -383.4405 --- Convergence ratio = 0.00456 #>   #> VEM algorithm, step 10: 7.13 seconds  #>   #> Value of the elbo: -381.78493 --- Convergence ratio = 0.00434 #>   #> VEM algorithm, step 11: 7.12 seconds  #>   #> Value of the elbo: -380.30595 --- Convergence ratio = 0.00389 #>   #> VEM algorithm, step 12: 7.08 seconds  #>   #> Value of the elbo: -379.03158 --- Convergence ratio = 0.00336 #>   #> VEM algorithm, step 13: 7.06 seconds  #>   #> Value of the elbo: -378.03565 --- Convergence ratio = 0.00263 #>   #> VEM algorithm, step 14: 7.12 seconds  #>   #> Value of the elbo: -377.25119 --- Convergence ratio = 0.00208 #>   #> VEM algorithm, step 15: 7.09 seconds  #>   #> Value of the elbo: -376.71268 --- Convergence ratio = 0.00143 #>   #> VEM algorithm, step 16: 7.1 seconds  #>   #> Value of the elbo: -376.31286 --- Convergence ratio = 0.00106 #>   #> VEM algorithm, step 17: 7.18 seconds  #>   #> Value of the elbo: -376.05438 --- Convergence ratio = 0.00069 #>   #> The EM algorithm successfully converged, training is completed.  #>"},{"path":"https://arthurleroy.github.io/MagmaClustR/articles/how-to-use-magmaclust.html","id":"prediction-for-james","dir":"Articles","previous_headings":"Apply MagmaClust on the weight database","what":"Prediction for James","title":"How to use MagmaClust","text":"MagmaClust model trained, can now predict evolution James’ weight. perform prediction, need specify two main parameters pred_magmaclust() function: data, case, sub-dataset containing James’ past weight; trained_model, corresponds model just trained 20 children Let us mention aim study weight curves early childhood, compare predictions true values observed dataset. Therefore, evolution James’ weight predicted 0 6 years (72 months), using weight data 0 20 months. Therefore, argument grid_inputs = seq(0,72,0.1). specified get_hyperpost = TRUE (return hyper-posterior distribution mean processes) allow us plot average GP cluster plot_magmaclust() function. However, need merely need display prediction individual.","code":"pred_clust <- pred_magmaclust(data = weight_pred,                               trained_model = model_clust,                               grid_inputs = seq(0,72,0.1),                               plot = FALSE,                               get_hyperpost = TRUE) #> The hyper-posterior distribution of the mean process provided in 'hyperpost' argument isn't evaluated on the expected inputs. Start evaluating the hyper-posterior on the correct inputs... #>   #> The 'prior_mean_k' argument has not been specified. The hyper-prior  mean functions are thus set to be 0 everywhere. #>   #> Done! #>"},{"path":"https://arthurleroy.github.io/MagmaClustR/articles/how-to-use-magmaclust.html","id":"plots","dir":"Articles","previous_headings":"Apply MagmaClust on the weight database","what":"Plots","title":"How to use MagmaClust","text":"plot_magmaclust() function, can display prediction evolution James’ weight time.  figure, can observe: James’ evolution curve (purple line) expressed mixture GPs; training data points background (displayed data_train). colour corresponds one child; trained mean processes dashed (blue, red green) lines coming prior_mean parameter.","code":"plot_magmaclust(pred = pred_clust,                 data = weight_pred,                 prior_mean = pred_clust$hyperpost$mean,                 data_train = weight_train,                 size_data = 5)"},{"path":"https://arthurleroy.github.io/MagmaClustR/articles/how-to-use-magmaclust.html","id":"customise-graphs","dir":"Articles","previous_headings":"","what":"Customise graphs","title":"How to use MagmaClust","text":"order customise graphical representations results, first need distinguish 2 cases: James belongs one clusters probability 1 (really close). can display mean curve along associated 95% credibility interval; James non-null probabilities several clusters; therefore, evolution curve defined Gaussian mixture (unimodal general). case, define associated credibility interval. However, uncertainty quantification can still displayed using heatmap probabilities. control colour pixel ratio heatmap, one can define appropriate vector y_grid argument. can also display training individuals colour probable cluster using data_allocate_cluster() function beforehand, specifying following arguments: data_train = data_train_with_clust col_clust = TRUE. order evaluate quality prediction, can also represent (grey ) true observations individual, didn’t use algorithm kept weight_test variable testing purposes.","code":"data_train_with_clust = data_allocate_cluster(model_clust)  plot_magmaclust(pred = pred_clust,                 cluster = \"all\",                 data = weight_pred,                 data_train = data_train_with_clust,                 prior_mean = pred_clust$hyperpost$mean,                 heatmap = TRUE,                 y_grid = seq(0,37,0.1),                 col_clust = TRUE,                 size_data = 5) +    ggplot2::geom_point(data = weight_test,                       ggplot2::aes(x = Input, y = Output),                       color = 'grey', size = 3)"},{"path":"https://arthurleroy.github.io/MagmaClustR/articles/how-to-use-magmaclust.html","id":"magmaclust-vs-magma","dir":"Articles","previous_headings":"Customise graphs","what":"MagmaClust vs Magma","title":"How to use MagmaClust","text":"MagmaClustR package also provides implementation Magma algorithm, allowing us compare MagmaClust Magma predictions. details Magma, see dedicated vignette. graphs correspond James’ weight prediction MagmaClust (left) Magma (right).  intervals unobserved timestamps containing data points training dataset (\\(t \\]20, 72]\\)), Magma takes advantage multi-task component share knowledge across individuals estimating unique mean process. However, unique mean process appears unable recover accurately evolution trend. example, MagmaClust offers significant improvement long term (4 years ahead) forecasting task. leveraging group structures among children, algorithm shares knowledge across individual similar, resulting precise specific predictions based mixture GPs.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/articles/how-to-use-magmaclust.html","id":"reference","dir":"Articles","previous_headings":"","what":"Reference","title":"How to use MagmaClust","text":"Overall, multi-task framework combined clustering component provided MagmaClust offers reliable probabilistic predictions new individual (child example) wide range timestamps. Moreover, uncertainty quantification inherent GP-based methods allows practitioners maintain adequate degree caution decision making process. details, complete derivation algorithm experiments published available Cluster-Specific Predictions Multi-Task Gaussian Processes.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/articles/standard-GP.html","id":"classical-pipeline","dir":"Articles","previous_headings":"","what":"Classical pipeline","title":"Gaussian Process regression","text":"overall pipeline standard GP regression MagmaClustR can decomposed 3 main steps: training, prediction plotting results. corresponding functions : train_gp() pred_gp() plot_gp()","code":""},{"path":[]},{"path":"https://arthurleroy.github.io/MagmaClustR/articles/standard-GP.html","id":"dataset-format","dir":"Articles","previous_headings":"Data","what":"Dataset format","title":"Gaussian Process regression","text":"using train_gp(), dataset present particular format. must contains 2 columns: Input: numeric, Output: numeric. fail ensure dataset satisfies conditions, algorithm return error. data frame can also provide many covariates (.e. additional columns) desired, constraints column names (except name ‘Reference’ always avoided, used inside internal functions algorithm). covariates treated additional input dimensions.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/articles/standard-GP.html","id":"example-with-swimming-data","dir":"Articles","previous_headings":"Data","what":"Example with swimming data","title":"Gaussian Process regression","text":"explore features standard GP MagmaClustR, use swimmers dataset provided French Swimming Federation (available , studied thoroughly ). goal model progression curves swimmers order forecast future performances. Thus, randomly select female swimmer dataset; let’s give fictive name Michaela sake illustration. swimmers dataset contains 4 columns: ID, Age, Performance Gender. Therefore, first need change name type columns, remove Gender using train_gp(). display Michaela’s performances according age visualise progression raw data.","code":"Michaela <- swimmers %>% filter(ID == 1718) %>%    select(-Gender) %>%    rename(Input = Age, Output = Performance) ggplot() +   geom_point(data = Michaela,        mapping = aes(x=Input,y=Output),        size = 3,        colour = \"black\") +   theme_classic()"},{"path":[]},{"path":"https://arthurleroy.github.io/MagmaClustR/articles/standard-GP.html","id":"training","dir":"Articles","previous_headings":"Fit a GP on Michaela’s data points","what":"Training","title":"Gaussian Process regression","text":"obtain GP best fits data, must specify parameters: prior_mean: assume prior knowledge 100m freestyle, can decide leave default value parameter (.e. zero). However, want take expert advice account, can modify value prior_mean accordingly. kern: relationship observed data prediction targets can control covariance kernel. Therefore, order correctly fit data, need choose suitable covariance kernel. case swimmers, want smooth progression curve Michaela; therefore, specify kern = \"SE\". commonly used kernels properties covered kernel cookbook. Details available kernels combine MagmaClustR available help(train_gp). Thanks train_gp(), learn model hyper-parameters data, can used make prediction Michaela’s performances.","code":"set.seed(2) model_gp <- train_gp(data = Michaela,                      kern = \"SE\",                      prior_mean = 0) #> The provided 'prior_mean' argument is of length 1. Thus, the hyper-posterior mean function has set to be constant everywhere.  #>   #> The 'ini_hp' argument has not been specified. Random values of hyper-parameters are used as initialisation. #>"},{"path":"https://arthurleroy.github.io/MagmaClustR/articles/standard-GP.html","id":"gp-prediction","dir":"Articles","previous_headings":"Fit a GP on Michaela’s data points","what":"GP prediction","title":"Gaussian Process regression","text":"arguments kern mean remain . now need specify: hyper-parameters obtained train_gp() hp; input values want evaluate GP grid_inputs. , want predict Michaela’s performances 15/16 years old, set grid_inputs = seq(11, 15.5, 0.1). See help(pred_gp) get information optional arguments. Let us note called pred_gp() function directly data. didn’t use train_gp() function beforehand, possible omit hp parameter; pred_gp() automatically learn hyperparameters default settings us make predictions afterwards.","code":"pred_gp <- pred_gp(data = Michaela,                    kern = \"SE\",                    hp = model_gp,                    grid_inputs = seq(11,15.5,0.1),                    plot = FALSE)  #> The 'mean' argument has not been specified. The  mean function is thus set to be 0 everywhere. #>"},{"path":"https://arthurleroy.github.io/MagmaClustR/articles/standard-GP.html","id":"plotting-the-results","dir":"Articles","previous_headings":"Fit a GP on Michaela’s data points","what":"Plotting the results","title":"Gaussian Process regression","text":"Finally, display Michaela’s prediction curve 95% associated credibility interval thanks plot_gp() function. want get prettier graphic, specify heatmap = TRUE create heatmap probabilities instead (note longer display evaluating fine grids).  Close Michaela’s observed data (\\(t \\[ 10, 14 ]\\)), standard GP prediction behaves expected: accurately fits data points confidence interval narrow. However, soon move away observed points, GP drifts prior mean uncertainty increases significantly.","code":"plot_gp(pred_gp = pred_gp,         data = Michaela)"},{"path":"https://arthurleroy.github.io/MagmaClustR/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Arthur Leroy. Author, maintainer. Pierre Latouche. Author. Pierre Pathé. Contributor. Alexia Grenouillat. Contributor. Hugo Lelievre. Contributor.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Leroy , Latouche P (2023). MagmaClustR: Clustering Prediction using Multi-Task Gaussian Processes Common Mean. https://github.com/ArthurLeroy/MagmaClustR, https://arthurleroy.github.io/MagmaClustR/.","code":"@Manual{,   title = {MagmaClustR: Clustering and Prediction using Multi-Task Gaussian Processes with Common Mean},   author = {Arthur Leroy and Pierre Latouche},   year = {2023},   note = {https://github.com/ArthurLeroy/MagmaClustR, https://arthurleroy.github.io/MagmaClustR/}, }"},{"path":"https://arthurleroy.github.io/MagmaClustR/index.html","id":"magmaclustr-","dir":"","previous_headings":"","what":"Clustering and Prediction using Multi-Task Gaussian Processes with\n    Common Mean","title":"Clustering and Prediction using Multi-Task Gaussian Processes with\n    Common Mean","text":"MagmaClustR package implements two main algorithms, called Magma (Leroy et al., 2022) MagmaClust (Leroy et al., 2020), using multi-task Gaussian processes (GP) model perform predictions supervised learning problems. Applications involving functional data, multiple time series, particularly well-handled. Theses approaches leverage learning cluster-specific mean processes, common across similar tasks, provide enhanced prediction performances (even far data points) linear computational cost (number tasks). MagmaClust generalisation Magma tasks simultaneously clustered groups, associated specific mean process. User-oriented functions package decomposed training, prediction plotting functions. basic features standard GPs also implemented. Leroy, ., Latouche, P., Guedj, B., Gey, S. MAGMA: inference prediction using multi-task Gaussian processes common mean. Mach Learn 111, 1821–1849 (2022). https://doi.org/10.1007/s10994-022-06172-1 Leroy, ., Latouche, P., Guedj, B., & Gey, S. Cluster-Specific Predictions Multi-Task Gaussian Processes. JMLR 24(5):1−49, (2023). https://www.jmlr.org/papers/v24/20-1321.html","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Clustering and Prediction using Multi-Task Gaussian Processes with\n    Common Mean","text":"can install released version MagmaClustR CRAN : development version GitHub :","code":"install.packages(\"MagmaClustR\") # install.packages(\"devtools\") devtools::install_github(\"ArthurLeroy/MagmaClustR\")"},{"path":"https://arthurleroy.github.io/MagmaClustR/index.html","id":"example-magma","dir":"","previous_headings":"","what":"Example: Magma","title":"Clustering and Prediction using Multi-Task Gaussian Processes with\n    Common Mean","text":"basic example simulate dataset adequate format, train Magma model use perform predictions.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/index.html","id":"data-generation","dir":"","previous_headings":"Example: Magma","what":"Data generation","title":"Clustering and Prediction using Multi-Task Gaussian Processes with\n    Common Mean","text":"displayed , dataset processed MagmaClustR provide columns named ID, Input, Output. additional column treated covariate (thus define multi-dimensional inputs).","code":"library(MagmaClustR) ## Simulate a dataset with 11 individuals, each observed at 10 input locations set.seed(17) data_magma <- simu_db(M = 11, N = 10, common_input = FALSE) ## Split individuals into training and prediction sets, and define test points magma_train <- data_magma %>% subset(ID %in% 1:10) magma_pred <- data_magma %>% subset(ID == 11) %>% head(7) magma_test <- data_magma %>% subset(ID == 11) %>% tail(3)  data_magma #> # A tibble: 110 x 3 #>    ID    Input Output #>    <chr> <dbl>  <dbl> #>  1 1      1.3  -20.7  #>  2 1      2.65 -24.2  #>  3 1      2.8  -24.4  #>  4 1      3.3  -25.6  #>  5 1      3.8  -23.9  #>  6 1      5    -11.4  #>  7 1      6.1   -4.97 #>  8 1      6.35  -4.35 #>  9 1      7.55  -6.63 #> 10 1      9.8   -8.68 #> # i 100 more rows"},{"path":"https://arthurleroy.github.io/MagmaClustR/index.html","id":"training-and-prediction-with-magma","dir":"","previous_headings":"Example: Magma","what":"Training and prediction with Magma","title":"Clustering and Prediction using Multi-Task Gaussian Processes with\n    Common Mean","text":"Note common_hp grid_inputs arguments optional. respectively indicate specific set hyper-parameters trained curve, control grid values prediction performed.","code":"model <- train_magma(data = magma_train, common_hp = F) #> The 'prior_mean' argument has not been specified. The hyper_prior mean function is thus set to be 0 everywhere. #>   #> The 'ini_hp_0' argument has not been specified. Random values of hyper-parameters for the mean process are used as initialisation. #>   #> The 'ini_hp_i' argument has not been specified. Random values of hyper-parameters for the individal processes are used as initialisation. #>   #> EM algorithm, step 1: 7.86 seconds  #>   #> Value of the likelihood: -313.47546 --- Convergence ratio = Inf #>   #> EM algorithm, step 2: 4.38 seconds  #>   #> Value of the likelihood: -303.47668 --- Convergence ratio = 0.03295 #>   #> EM algorithm, step 3: 3.1 seconds  #>   #> Value of the likelihood: -302.84575 --- Convergence ratio = 0.00208 #>   #> EM algorithm, step 4: 2.9 seconds  #>   #> Value of the likelihood: -302.56379 --- Convergence ratio = 0.00093 #>   #> The EM algorithm successfully converged, training is completed.  #>   pred  <- pred_magma(data = magma_pred,                     trained_model = model,                      grid_inputs = seq(0,10, 0.01)) #> The hyper-posterior distribution of the mean process provided in 'hyperpost' argument isn't evaluated on the expected inputs. #>   #>  Start evaluating the hyper-posterior on the correct inputs... #>   #> The 'prior_mean' argument has not been specified. The hyper-prior mean function is thus set to be 0 everywhere. #>   #> Done! #>   #> The 'hp' argument has not been specified. The 'train_gp()' function (with random initialisation) has been used to learn ML estimators for the hyper-parameters associated with the 'kern' argument. #>"},{"path":"https://arthurleroy.github.io/MagmaClustR/index.html","id":"display-the-resulting-predictions","dir":"","previous_headings":"Example: Magma","what":"Display the resulting predictions","title":"Clustering and Prediction using Multi-Task Gaussian Processes with\n    Common Mean","text":"Several arguments available dedicated plotting functions offer extended options display results. instance, GP predictions can represented heatmap probabilities:  Additionally, also possible create animated representations using functions generate GIFs. instance, , true testing points represented red dots can observe prediction evolves add data points prediction dataset.","code":"plot_gp(pred_gp = pred,         data = magma_pred,         data_train = magma_train,         prior_mean = model$hyperpost$mean,         heatmap = TRUE) pred_gif  <- pred_gif(data = magma_pred,                       trained_model = model,                       grid_inputs = seq(0, 10, 0.01)) #>  => 1 => 2 => 3 => 4 => 5 => 6 => 7  plot_gif(pred_gp = pred_gif,          data = magma_pred,          data_train = magma_train,          prior_mean = model$hyperpost$mean) +    ggplot2::geom_point(data = magma_test,                       ggplot2::aes(x = Input, y = Output),                       color = 'red', size = 2)"},{"path":"https://arthurleroy.github.io/MagmaClustR/index.html","id":"example-magmaclust","dir":"","previous_headings":"","what":"Example: MagmaClust","title":"Clustering and Prediction using Multi-Task Gaussian Processes with\n    Common Mean","text":"basic example simulate dataset adequate format, train MagmaClust model use perform simultaneous clustering predictions.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/index.html","id":"data-generation-1","dir":"","previous_headings":"Example: MagmaClust","what":"Data generation","title":"Clustering and Prediction using Multi-Task Gaussian Processes with\n    Common Mean","text":"","code":"## Simulate a dataset containing 3 clusters of 4 individuals, each observed at 10 input locations set.seed(4)  data_magmaclust <- simu_db(M = 4, N = 10, K = 3, common_input = FALSE)  ## Split individuals into training and prediction sets, and define test points list_ID = unique(data_magmaclust$ID) magmaclust_train <- data_magmaclust %>% subset(ID %in% list_ID[1:11]) magmaclust_pred <- data_magmaclust %>% subset(ID == list_ID[12]) %>% head(5) magmaclust_test <- data_magmaclust %>% subset(ID == list_ID[12]) %>% tail(5)  data_magmaclust #> # A tibble: 120 x 3 #>    ID         Input Output #>    <chr>      <dbl>  <dbl> #>  1 ID1-Clust1  0.2   32.4  #>  2 ID1-Clust1  0.7   28.8  #>  3 ID1-Clust1  2.05   6.62 #>  4 ID1-Clust1  2.1    5.46 #>  5 ID1-Clust1  3.15  -5.44 #>  6 ID1-Clust1  5.3  -16.5  #>  7 ID1-Clust1  6.4  -24.7  #>  8 ID1-Clust1  7.35 -31.4  #>  9 ID1-Clust1  7.5  -32.4  #> 10 ID1-Clust1  8.95 -42.7  #> # i 110 more rows"},{"path":"https://arthurleroy.github.io/MagmaClustR/index.html","id":"training-and-prediction-with-magmaclust","dir":"","previous_headings":"Example: MagmaClust","what":"Training and prediction with MagmaClust","title":"Clustering and Prediction using Multi-Task Gaussian Processes with\n    Common Mean","text":"","code":"model_clust <- train_magmaclust(data = magmaclust_train) #> The number of cluster argument has not been specified. There will be 3 cluster by default.  #>   #> The 'ini_hp_i' argument has not been specified. Random values of hyper-parameters for the individual processes are used as initialisation. #>   #> The 'ini_hp_k' argument has not been specified. Random values of hyper-parameters for the mean processes are used as initialisation. #>   #> The 'prior_mean' argument has not been specified. The hyper_prior mean function is thus set to be 0 everywhere. #>   #> VEM algorithm, step 1: 20.35 seconds  #>   #> Value of the elbo: -712.16808 --- Convergence ratio = Inf #>   #> VEM algorithm, step 2: 11.52 seconds  #>   #> Value of the elbo: -635.70636 --- Convergence ratio = 0.12028 #>   #> VEM algorithm, step 3: 19.46 seconds  #>   #> Value of the elbo: -623.0371 --- Convergence ratio = 0.02033 #>   #> VEM algorithm, step 4: 9.89 seconds  #>   #> Value of the elbo: -619.56266 --- Convergence ratio = 0.00561 #>   #> VEM algorithm, step 5: 7.93 seconds  #>   #> Value of the elbo: -618.50147 --- Convergence ratio = 0.00172 #>   #> VEM algorithm, step 6: 7.68 seconds  #>   #> Value of the elbo: -617.95297 --- Convergence ratio = 0.00089 #>   #> The EM algorithm successfully converged, training is completed.  #>   pred_clust  <- pred_magmaclust(data = magmaclust_pred,                                trained_model = model_clust,                                grid_inputs = seq(0, 10, 0.01),                                 plot = FALSE) #> The hyper-posterior distribution of the mean process provided in 'hyperpost' argument isn't evaluated on the expected inputs. Start evaluating the hyper-posterior on the correct inputs... #>   #> The 'prior_mean_k' argument has not been specified. The hyper-prior  mean functions are thus set to be 0 everywhere. #>   #> Done! #>"},{"path":"https://arthurleroy.github.io/MagmaClustR/index.html","id":"display-the-resulting-predictions-1","dir":"","previous_headings":"Example: MagmaClust","what":"Display the resulting predictions","title":"Clustering and Prediction using Multi-Task Gaussian Processes with\n    Common Mean","text":", specific plotting function provided. MagmaClust, advise use heatmap representation priority, mixture GPs may unimodal general (thus prevents definition Credible Interval).","code":"## Allocate individuals to their most probable cluster to colour them by clusters afterwards data_train_with_clust = data_allocate_cluster(model_clust)  plot_magmaclust(pred = pred_clust,                 cluster = \"all\",                 data = magmaclust_pred,                 data_train = data_train_with_clust,                 col_clust = TRUE,                 prior_mean = model_clust$hyperpost$mean,                 y_grid = seq(10, 55, 0.5),                 heatmap = TRUE)  #> The mixture probability of the cluster K1 is 1. Therefore, the predictive distribution is Gaussian and the associated credible interval can be displayed."},{"path":"https://arthurleroy.github.io/MagmaClustR/index.html","id":"example-in-2-dimensions","dir":"","previous_headings":"","what":"Example: in 2-dimensions","title":"Clustering and Prediction using Multi-Task Gaussian Processes with\n    Common Mean","text":"Although unidimensional-input problems easier visualise, Magma MagmaClust can also applied many covariates desired model.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/index.html","id":"data-generation-2","dir":"","previous_headings":"Example: in 2-dimensions","what":"Data generation","title":"Clustering and Prediction using Multi-Task Gaussian Processes with\n    Common Mean","text":"","code":"## Dataset with 11 individuals, 10 reference input locations and a covariate set.seed(5)  data_dim2 <- simu_db(M = 11, N = 10, covariate = TRUE)  ## Split individuals into training and prediction sets, and define test points dim2_train <- data_dim2 %>% subset(ID %in% 1:10) dim2_pred <- data_dim2 %>% subset(ID == 11)  data_dim2 #> # A tibble: 110 x 4 #>    ID    Input Covariate Output #>    <chr> <dbl>     <dbl>  <dbl> #>  1 1      1.85       4.5  21.3  #>  2 1      2.85       8.5   5.21 #>  3 1      2          4    24.8  #>  4 1      3.25       7    12.3  #>  5 1      3.5        2.5  37.0  #>  6 1      5.3        5.5  20.0  #>  7 1      6.5        5    20.8  #>  8 1      6          2    34.1  #>  9 1      7.3        9.5   5.18 #> 10 1      9.2        7.5   7.20 #> # i 100 more rows"},{"path":"https://arthurleroy.github.io/MagmaClustR/index.html","id":"training-and-prediction-with-magma-1","dir":"","previous_headings":"Example: in 2-dimensions","what":"Training and prediction with Magma","title":"Clustering and Prediction using Multi-Task Gaussian Processes with\n    Common Mean","text":"","code":"model_dim2 <- train_magma(data = dim2_train) #> The 'prior_mean' argument has not been specified. The hyper_prior mean function is thus set to be 0 everywhere. #>   #> The 'ini_hp_0' argument has not been specified. Random values of hyper-parameters for the mean process are used as initialisation. #>   #> The 'ini_hp_i' argument has not been specified. Random values of hyper-parameters for the individal processes are used as initialisation. #>   #> EM algorithm, step 1: 6.02 seconds  #>   #> Value of the likelihood: -247.66608 --- Convergence ratio = Inf #>   #> EM algorithm, step 2: 5.71 seconds  #>   #> Value of the likelihood: -217.29028 --- Convergence ratio = 0.13979 #>   #> EM algorithm, step 3: 3.44 seconds  #>   #> Value of the likelihood: -216.11346 --- Convergence ratio = 0.00545 #>   #> EM algorithm, step 4: 3.59 seconds  #>   #> Value of the likelihood: -216.02699 --- Convergence ratio = 4e-04 #>   #> The EM algorithm successfully converged, training is completed.  #>   pred_dim2  <- pred_magma(data = dim2_pred,                          trained_model = model_dim2) #> The hyper-posterior distribution of the mean process provided in 'hyperpost' argument isn't evaluated on the expected inputs. #>   #>  Start evaluating the hyper-posterior on the correct inputs... #>   #> The 'prior_mean' argument has not been specified. The hyper-prior mean function is thus set to be 0 everywhere. #>   #> Done! #>"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/MagmaClustR.html","id":null,"dir":"Reference","previous_headings":"","what":"MagmaClustR : Clustering and Prediction using Multi-Task Gaussian Processes — MagmaClustR","title":"MagmaClustR : Clustering and Prediction using Multi-Task Gaussian Processes — MagmaClustR","text":"MagmaClustR package implements two main algorithms, called Magma MagmaClust, using multi-task GPs model perform predictions supervised learning problems. Theses approaches leverage learning cluster-specific mean processes, common across similar tasks, provide enhanced prediction performances (even far data) linear computational cost (number tasks). MagmaClust generalisation Magma tasks simultaneously clustered groups, associated specific mean process. User-oriented functions package decomposed training, prediction plotting functions. basic features standard GPs also implemented.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/MagmaClustR.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"MagmaClustR : Clustering and Prediction using Multi-Task Gaussian Processes — MagmaClustR","text":"quick introduction MagmaClustR, please refer README https://github.com/ArthurLeroy/MagmaClustR","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/MagmaClustR.html","id":"author-s-","dir":"Reference","previous_headings":"","what":"Author(s)","title":"MagmaClustR : Clustering and Prediction using Multi-Task Gaussian Processes — MagmaClustR","text":"Arthur Leroy, Pierre Pathe Pierre Latouche  Maintainer: Arthur Leroy - arthur.leroy.pro@gmail.com","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/MagmaClustR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"MagmaClustR : Clustering and Prediction using Multi-Task Gaussian Processes — MagmaClustR","text":"Arthur Leroy, Pierre Latouche, Benjamin Guedj, Servane Gey.  MAGMA: Inference Prediction Multi-Task Gaussian Processes. Machine Learning, 2022, https://link.springer.com/article/10.1007/s10994-022-06172-1 Arthur Leroy, Pierre Latouche, Benjamin Guedj, Servane Gey.  Cluster-Specific Predictions Multi-Task Gaussian Processes. Journal Machine Learning Research, 2023, https://jmlr.org/papers/v24/20-1321.html","code":""},{"path":[]},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/MagmaClustR.html","id":"simulate-a-dataset-train-and-predict-with-magma-","dir":"Reference","previous_headings":"","what":"Simulate a dataset, train and predict with Magma","title":"MagmaClustR : Clustering and Prediction using Multi-Task Gaussian Processes — MagmaClustR","text":"set.seed(4242)  data_magma <- simu_db(M = 11, N = 10, K = 1)  magma_train <- data_magma %>% subset(ID %% 1:10)  magma_test <- data_magma %>% subset(ID == 11) %>% head(7) magma_model <- train_magma(data = magma_train)  magma_pred  <- pred_magma(data = magma_test, trained_model = magma_model, grid_inputs = seq(0, 10, 0.01))","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/MagmaClustR.html","id":"simulate-a-dataset-train-and-predict-with-magmaclust-","dir":"Reference","previous_headings":"","what":"Simulate a dataset, train and predict with MagmaClust","title":"MagmaClustR : Clustering and Prediction using Multi-Task Gaussian Processes — MagmaClustR","text":"set.seed(4242)  data_magmaclust <- simu_db(M = 4, N = 10, K = 3)  list_ID = unique(data_magmaclust$ID)  magmaclust_train <- data_magmaclust %>% subset(ID %% list_ID[1:11])  magmaclust_test <- data_magmaclust %>% subset(ID == list_ID[12]) %>% head(5) magmaclust_model <- train_magmaclust(data = magmaclust_train)  magmaclust_pred  <- pred_magmaclust(data = magmaclust_test,  trained_model = magmaclust_model, grid_inputs = seq(0, 10, 0.01))","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/chol_inv_jitter.html","id":null,"dir":"Reference","previous_headings":"","what":"Inverse a matrix using an adaptive jitter term — chol_inv_jitter","title":"Inverse a matrix using an adaptive jitter term — chol_inv_jitter","text":"Inverse matrix Choleski decomposition. (nearly-)singular, increase order magnitude jitter term added diagonal matrix becomes non-singular.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/chol_inv_jitter.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Inverse a matrix using an adaptive jitter term — chol_inv_jitter","text":"","code":"chol_inv_jitter(mat, pen_diag)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/chol_inv_jitter.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Inverse a matrix using an adaptive jitter term — chol_inv_jitter","text":"mat matrix, possibly singular. pen_diag number, jitter term add diagonal.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/chol_inv_jitter.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Inverse a matrix using an adaptive jitter term — chol_inv_jitter","text":"matrix, inverse mat plus adaptive jitter term added diagonal.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/chol_inv_jitter.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Inverse a matrix using an adaptive jitter term — chol_inv_jitter","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/data_allocate_cluster.html","id":null,"dir":"Reference","previous_headings":"","what":"Allocate training data into the most probable cluster — data_allocate_cluster","title":"Allocate training data into the most probable cluster — data_allocate_cluster","text":"Allocate training data probable cluster","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/data_allocate_cluster.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Allocate training data into the most probable cluster — data_allocate_cluster","text":"","code":"data_allocate_cluster(trained_model)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/data_allocate_cluster.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Allocate training data into the most probable cluster — data_allocate_cluster","text":"trained_model list, containing  information coming MagmaClust model, previously trained using train_magmaclust function.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/data_allocate_cluster.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Allocate training data into the most probable cluster — data_allocate_cluster","text":"original dataset used train MagmaClust model, additional 'Cluster' associated 'Proba' columns, indicating probable cluster individual/task end training procedure.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/data_allocate_cluster.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Allocate training data into the most probable cluster — data_allocate_cluster","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/dmnorm.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the Multivariate Gaussian likelihood — dmnorm","title":"Compute the Multivariate Gaussian likelihood — dmnorm","text":"Modification function dmvnorm() package mvtnorm, providing implementation Multivariate Gaussian likelihood. version uses inverse covariance function argument instead traditional covariance.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/dmnorm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the Multivariate Gaussian likelihood — dmnorm","text":"","code":"dmnorm(x, mu, inv_Sigma, log = FALSE)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/dmnorm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the Multivariate Gaussian likelihood — dmnorm","text":"x vector, containing values likelihood evaluated . mu vector matrix, specifying mean parameter. inv_Sigma matrix, specifying inverse covariance parameter. log logical value, indicating whether return log-likelihood.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/dmnorm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the Multivariate Gaussian likelihood — dmnorm","text":"number, corresponding Multivariate Gaussian log-likelihood.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/dmnorm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute the Multivariate Gaussian likelihood — dmnorm","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/draw.html","id":null,"dir":"Reference","previous_headings":"","what":"Draw a number — draw","title":"Draw a number — draw","text":"Draw uniformly number within specified interval","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/draw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Draw a number — draw","text":"","code":"draw(int)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/draw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Draw a number — draw","text":"int interval values want draw uniformly .","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/draw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Draw a number — draw","text":"2-decimals-rounded random number","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/draw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Draw a number — draw","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/e_step.html","id":null,"dir":"Reference","previous_headings":"","what":"E-Step of the EM algorithm — e_step","title":"E-Step of the EM algorithm — e_step","text":"Expectation step EM algorithm compute parameters hyper-posterior Gaussian distribution mean process Magma.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/e_step.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"E-Step of the EM algorithm — e_step","text":"","code":"e_step(db, m_0, kern_0, kern_i, hp_0, hp_i, pen_diag)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/e_step.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"E-Step of the EM algorithm — e_step","text":"db tibble data frame. Columns required: ID, Input, Output. Additional columns covariates can specified. m_0 vector, corresponding prior mean mean GP. kern_0 kernel function, associated mean GP. kern_i kernel function, associated individual GPs. hp_0 named vector, tibble data frame hyper-parameters associated kern_0. hp_i tibble data frame hyper-parameters associated kern_i. pen_diag number. jitter term, added diagonal prevent numerical issues inverting nearly singular matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/e_step.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"E-Step of the EM algorithm — e_step","text":"named list, containing elements mean, tibble containing Input associated Output hyper-posterior's mean parameter, cov, hyper-posterior's covariance matrix.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/e_step.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"E-Step of the EM algorithm — e_step","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/elbo_GP_mod_common_hp_k.html","id":null,"dir":"Reference","previous_headings":"","what":"Penalised elbo for multiple mean GPs with common HPs — elbo_GP_mod_common_hp_k","title":"Penalised elbo for multiple mean GPs with common HPs — elbo_GP_mod_common_hp_k","text":"Penalised elbo multiple mean GPs common HPs","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/elbo_GP_mod_common_hp_k.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Penalised elbo for multiple mean GPs with common HPs — elbo_GP_mod_common_hp_k","text":"","code":"elbo_GP_mod_common_hp_k(hp, db, mean, kern, post_cov, pen_diag)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/elbo_GP_mod_common_hp_k.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Penalised elbo for multiple mean GPs with common HPs — elbo_GP_mod_common_hp_k","text":"hp tibble, data frame named vector containing hyper-parameters. db tibble containing values want compute elbo . Required columns: Input, Output. Additional covariate columns allowed. mean list K mean GPs union observed timestamps. kern kernel function used compute covariance matrix corresponding timestamps. post_cov List K posterior covariance mean GP (mu_k). Used compute correction term (cor_term). pen_diag jitter term added covariance matrix avoid numerical issues inverting, cases nearly singular matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/elbo_GP_mod_common_hp_k.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Penalised elbo for multiple mean GPs with common HPs — elbo_GP_mod_common_hp_k","text":"value penalised Gaussian elbo sum k mean GPs common HPs.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/elbo_GP_mod_common_hp_k.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Penalised elbo for multiple mean GPs with common HPs — elbo_GP_mod_common_hp_k","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/elbo_clust_multi_GP.html","id":null,"dir":"Reference","previous_headings":"","what":"Evidence Lower Bound for a mixture of GPs — elbo_clust_multi_GP","title":"Evidence Lower Bound for a mixture of GPs — elbo_clust_multi_GP","text":"Evidence Lower Bound mixture GPs","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/elbo_clust_multi_GP.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evidence Lower Bound for a mixture of GPs — elbo_clust_multi_GP","text":"","code":"elbo_clust_multi_GP(hp, db, hyperpost, kern, pen_diag)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/elbo_clust_multi_GP.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evidence Lower Bound for a mixture of GPs — elbo_clust_multi_GP","text":"hp tibble, data frame named vector containing hyper-parameters. db tibble containing values want compute elbo . Required columns: Input, Output. Additional covariate columns allowed. hyperpost List parameters K mean GPs. kern kernel function used compute covariance matrix corresponding timestamps. pen_diag jitter term added covariance matrix avoid numerical issues inverting, cases nearly singular matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/elbo_clust_multi_GP.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evidence Lower Bound for a mixture of GPs — elbo_clust_multi_GP","text":"value penalised Gaussian elbo mixture GPs","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/elbo_clust_multi_GP.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Evidence Lower Bound for a mixture of GPs — elbo_clust_multi_GP","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/elbo_clust_multi_GP_common_hp_i.html","id":null,"dir":"Reference","previous_headings":"","what":"Penalised elbo for multiple individual GPs with common HPs — elbo_clust_multi_GP_common_hp_i","title":"Penalised elbo for multiple individual GPs with common HPs — elbo_clust_multi_GP_common_hp_i","text":"Penalised elbo multiple individual GPs common HPs","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/elbo_clust_multi_GP_common_hp_i.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Penalised elbo for multiple individual GPs with common HPs — elbo_clust_multi_GP_common_hp_i","text":"","code":"elbo_clust_multi_GP_common_hp_i(hp, db, hyperpost, kern, pen_diag)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/elbo_clust_multi_GP_common_hp_i.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Penalised elbo for multiple individual GPs with common HPs — elbo_clust_multi_GP_common_hp_i","text":"hp tibble, data frame named vector containing hyper-parameters. db tibble containing values want compute elbo . Required columns: Input, Output. Additional covariate columns allowed. hyperpost List parameters K mean Gaussian processes. kern kernel function used compute covariance matrix corresponding timestamps. pen_diag jitter term added covariance matrix avoid numerical issues inverting, cases nearly singular matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/elbo_clust_multi_GP_common_hp_i.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Penalised elbo for multiple individual GPs with common HPs — elbo_clust_multi_GP_common_hp_i","text":"value penalised Gaussian elbo sum M individual GPs common HPs.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/elbo_clust_multi_GP_common_hp_i.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Penalised elbo for multiple individual GPs with common HPs — elbo_clust_multi_GP_common_hp_i","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/elbo_monitoring_VEM.html","id":null,"dir":"Reference","previous_headings":"","what":"Evidence Lower Bound maximised in MagmaClust — elbo_monitoring_VEM","title":"Evidence Lower Bound maximised in MagmaClust — elbo_monitoring_VEM","text":"Evidence Lower Bound maximised MagmaClust","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/elbo_monitoring_VEM.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evidence Lower Bound maximised in MagmaClust — elbo_monitoring_VEM","text":"","code":"elbo_monitoring_VEM(hp_k, hp_i, db, kern_i, kern_k, hyperpost, m_k, pen_diag)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/elbo_monitoring_VEM.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evidence Lower Bound maximised in MagmaClust — elbo_monitoring_VEM","text":"hp_k tibble, data frame named vector hyper-parameters clusters. hp_i tibble, data frame named vector hyper-parameters individuals. db tibble containing values want compute elbo . Required columns: Input, Output. Additional covariate columns allowed. kern_i Kernel used compute covariance matrix individuals GPs corresponding inputs. kern_k Kernel used compute covariance matrix mean GPs corresponding inputs. hyperpost list parameters variational distributions K mean GPs. m_k Prior value mean parameter mean GPs (mu_k). Length = 1 nrow(db). pen_diag jitter term added covariance matrix avoid numerical issues inverting, cases nearly singular matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/elbo_monitoring_VEM.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evidence Lower Bound maximised in MagmaClust — elbo_monitoring_VEM","text":"Value elbo maximised VEM algorithm used training MagmaClust.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/elbo_monitoring_VEM.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Evidence Lower Bound maximised in MagmaClust — elbo_monitoring_VEM","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/expand_grid_inputs.html","id":null,"dir":"Reference","previous_headings":"","what":"Expand a grid of inputs — expand_grid_inputs","title":"Expand a grid of inputs — expand_grid_inputs","text":"Expand grid inputs","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/expand_grid_inputs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Expand a grid of inputs — expand_grid_inputs","text":"","code":"expand_grid_inputs(Input, ...)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/expand_grid_inputs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Expand a grid of inputs — expand_grid_inputs","text":"Input vector inputs. ... many vector covariates desired. advise give explicit names using function.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/expand_grid_inputs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Expand a grid of inputs — expand_grid_inputs","text":"tibble containing combination values parameters.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/expand_grid_inputs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Expand a grid of inputs — expand_grid_inputs","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_GP.html","id":null,"dir":"Reference","previous_headings":"","what":"Gradient of the logLikelihood of a Gaussian Process — gr_GP","title":"Gradient of the logLikelihood of a Gaussian Process — gr_GP","text":"Gradient logLikelihood Gaussian Process","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_GP.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gradient of the logLikelihood of a Gaussian Process — gr_GP","text":"","code":"gr_GP(hp, db, mean, kern, post_cov, pen_diag)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_GP.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gradient of the logLikelihood of a Gaussian Process — gr_GP","text":"hp tibble, data frame named vector containing hyper-parameters. db tibble containing values want compute logL . Required columns: Input, Output. Additional covariate columns allowed. mean vector, specifying mean GP reference inputs. kern kernel function. post_cov (optional) matrix, corresponding covariance parameter hyper-posterior. Used compute hyper-prior distribution new individual Magma. pen_diag jitter term added covariance matrix avoid numerical issues inverting, cases nearly singular matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_GP.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gradient of the logLikelihood of a Gaussian Process — gr_GP","text":"named vector, corresponding value hyper-parameters gradients Gaussian log-Likelihood (covariance can sum individual hyper-posterior's mean process covariances).","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_GP.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gradient of the logLikelihood of a Gaussian Process — gr_GP","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_GP_mod.html","id":null,"dir":"Reference","previous_headings":"","what":"Gradient of the modified logLikelihood for GPs in Magma — gr_GP_mod","title":"Gradient of the modified logLikelihood for GPs in Magma — gr_GP_mod","text":"Gradient modified logLikelihood GPs Magma","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_GP_mod.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gradient of the modified logLikelihood for GPs in Magma — gr_GP_mod","text":"","code":"gr_GP_mod(hp, db, mean, kern, post_cov, pen_diag)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_GP_mod.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gradient of the modified logLikelihood for GPs in Magma — gr_GP_mod","text":"hp tibble, data frame named vector containing hyper-parameters. db tibble containing values want compute logL . Required columns: Input, Output. Additional covariate columns allowed. mean vector, specifying mean GPs reference inputs. kern kernel function. post_cov matrix, covariance parameter hyper-posterior. Used compute correction term. pen_diag jitter term added covariance matrix avoid numerical issues inverting, cases nearly singular matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_GP_mod.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gradient of the modified logLikelihood for GPs in Magma — gr_GP_mod","text":"named vector, corresponding value hyper-parameters gradients modified Gaussian log-Likelihood involved Magma.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_GP_mod.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gradient of the modified logLikelihood for GPs in Magma — gr_GP_mod","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_GP_mod_common_hp.html","id":null,"dir":"Reference","previous_headings":"","what":"Gradient of the modified logLikelihood with common HPs for GPs in Magma — gr_GP_mod_common_hp","title":"Gradient of the modified logLikelihood with common HPs for GPs in Magma — gr_GP_mod_common_hp","text":"Gradient modified logLikelihood common HPs GPs Magma","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_GP_mod_common_hp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gradient of the modified logLikelihood with common HPs for GPs in Magma — gr_GP_mod_common_hp","text":"","code":"gr_GP_mod_common_hp(hp, db, mean, kern, post_cov, pen_diag)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_GP_mod_common_hp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gradient of the modified logLikelihood with common HPs for GPs in Magma — gr_GP_mod_common_hp","text":"hp tibble data frame containing hyper-parameters individuals. db tibble containing values want compute logL . Required columns: ID, Input, Output. Additional covariate columns allowed. mean vector, specifying mean GPs reference inputs. kern kernel function. post_cov matrix, covariance parameter hyper-posterior. Used compute correction term. pen_diag jitter term added covariance matrix avoid numerical issues inverting, cases nearly singular matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_GP_mod_common_hp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gradient of the modified logLikelihood with common HPs for GPs in Magma — gr_GP_mod_common_hp","text":"named vector, corresponding value hyper-parameters' gradients modified Gaussian log-Likelihood involved Magma 'common HP' setting.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_GP_mod_common_hp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gradient of the modified logLikelihood with common HPs for GPs in Magma — gr_GP_mod_common_hp","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_GP_mod_common_hp_k.html","id":null,"dir":"Reference","previous_headings":"","what":"Gradient of the penalised elbo for multiple mean GPs with common HPs — gr_GP_mod_common_hp_k","title":"Gradient of the penalised elbo for multiple mean GPs with common HPs — gr_GP_mod_common_hp_k","text":"Gradient penalised elbo multiple mean GPs common HPs","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_GP_mod_common_hp_k.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gradient of the penalised elbo for multiple mean GPs with common HPs — gr_GP_mod_common_hp_k","text":"","code":"gr_GP_mod_common_hp_k(hp, db, mean, kern, post_cov, pen_diag)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_GP_mod_common_hp_k.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gradient of the penalised elbo for multiple mean GPs with common HPs — gr_GP_mod_common_hp_k","text":"hp tibble, data frame named vector containing hyper-parameters. db tibble containing values want compute elbo . Required columns: Input, Output. Additional covariate columns allowed. mean list k means GPs union observed timestamps. kern kernel function post_cov list k posterior covariance mean GP (mu_k). Used compute correction term (cor_term) pen_diag jitter term added covariance matrix avoid numerical issues inverting, cases nearly singular matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_GP_mod_common_hp_k.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gradient of the penalised elbo for multiple mean GPs with common HPs — gr_GP_mod_common_hp_k","text":"gradient penalised Gaussian elbo sum k mean GPs common HPs.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_GP_mod_common_hp_k.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gradient of the penalised elbo for multiple mean GPs with common HPs — gr_GP_mod_common_hp_k","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_clust_multi_GP.html","id":null,"dir":"Reference","previous_headings":"","what":"Gradient of the elbo for a mixture of GPs — gr_clust_multi_GP","title":"Gradient of the elbo for a mixture of GPs — gr_clust_multi_GP","text":"Gradient elbo mixture GPs","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_clust_multi_GP.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gradient of the elbo for a mixture of GPs — gr_clust_multi_GP","text":"","code":"gr_clust_multi_GP(hp, db, hyperpost, kern, pen_diag)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_clust_multi_GP.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gradient of the elbo for a mixture of GPs — gr_clust_multi_GP","text":"hp tibble, data frame named vector containing hyper-parameters. db tibble containing values want compute elbo . Required columns: Input, Output. Additional covariate columns allowed. hyperpost List parameters K mean Gaussian processes. kern kernel function. pen_diag jitter term added covariance matrix avoid numerical issues inverting, cases nearly singular matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_clust_multi_GP.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gradient of the elbo for a mixture of GPs — gr_clust_multi_GP","text":"gradient penalised Gaussian elbo mixture GPs","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_clust_multi_GP.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gradient of the elbo for a mixture of GPs — gr_clust_multi_GP","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_clust_multi_GP_common_hp_i.html","id":null,"dir":"Reference","previous_headings":"","what":"Gradient of the penalised elbo for multiple individual GPs with common HPs — gr_clust_multi_GP_common_hp_i","title":"Gradient of the penalised elbo for multiple individual GPs with common HPs — gr_clust_multi_GP_common_hp_i","text":"Gradient penalised elbo multiple individual GPs common HPs","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_clust_multi_GP_common_hp_i.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gradient of the penalised elbo for multiple individual GPs with common HPs — gr_clust_multi_GP_common_hp_i","text":"","code":"gr_clust_multi_GP_common_hp_i(hp, db, hyperpost, kern, pen_diag = NULL)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_clust_multi_GP_common_hp_i.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gradient of the penalised elbo for multiple individual GPs with common HPs — gr_clust_multi_GP_common_hp_i","text":"hp tibble, data frame name vector hyper-parameters. db tibble containing values want compute elbo . Required columns: Input, Output. Additional covariate columns allowed. hyperpost List parameters K mean Gaussian processes. kern kernel function used compute covariance matrix corresponding timestamps. pen_diag jitter term added covariance matrix avoid numerical issues inverting, cases nearly singular matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_clust_multi_GP_common_hp_i.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gradient of the penalised elbo for multiple individual GPs with common HPs — gr_clust_multi_GP_common_hp_i","text":"gradient penalised Gaussian elbo sum M individual GPs common HPs.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_clust_multi_GP_common_hp_i.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gradient of the penalised elbo for multiple individual GPs with common HPs — gr_clust_multi_GP_common_hp_i","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_sum_logL_GP_clust.html","id":null,"dir":"Reference","previous_headings":"","what":"Gradient of the mixture of Gaussian likelihoods — gr_sum_logL_GP_clust","title":"Gradient of the mixture of Gaussian likelihoods — gr_sum_logL_GP_clust","text":"Compute gradient sum Gaussian log-likelihoods, weighted mixture probabilities.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_sum_logL_GP_clust.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gradient of the mixture of Gaussian likelihoods — gr_sum_logL_GP_clust","text":"","code":"gr_sum_logL_GP_clust(hp, db, mixture, mean, kern, post_cov, pen_diag)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_sum_logL_GP_clust.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gradient of the mixture of Gaussian likelihoods — gr_sum_logL_GP_clust","text":"hp tibble, data frame named vector hyper-parameters. db tibble containing data want evaluate logL . Required columns: Input, Output. Additional covariate columns allowed. mixture tibble data frame, indicating mixture probabilities cluster new individual/task. mean list hyper-posterior mean parameters clusters. kern kernel function. post_cov list hyper-posterior covariance parameters clusters. pen_diag jitter term added covariance matrix avoid numerical issues inverting, cases nearly singular matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_sum_logL_GP_clust.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gradient of the mixture of Gaussian likelihoods — gr_sum_logL_GP_clust","text":"named vector, corresponding value hyper-parameters' gradients mixture Gaussian log-likelihoods involved prediction step MagmaClust.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/gr_sum_logL_GP_clust.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gradient of the mixture of Gaussian likelihoods — gr_sum_logL_GP_clust","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/hp.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate random hyper-parameters — hp","title":"Generate random hyper-parameters — hp","text":"Generate set random hyper-parameters, specific chosen type kernel, format used Magma.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/hp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate random hyper-parameters — hp","text":"","code":"hp(   kern = \"SE\",   list_ID = NULL,   list_hp = NULL,   noise = FALSE,   common_hp = FALSE )"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/hp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate random hyper-parameters — hp","text":"kern function, character string indicating chosen type kernel among: \"SE\": Squared Exponential kernel, \"LIN\": Linear kernel, \"PERIO\": Periodic kernel, \"RQ\": Rational Quadratic kernel. Compound kernels can created sums products kernels. combining kernels, simply provide formula character string elements separated whitespaces (e.g. \"SE + PERIO\"). elements treated sequentially left right, product operator '*' shall always used '+' operators (e.g. 'SE * LIN + RQ' valid whereas 'RQ + SE * LIN'  ). case custom kernel function, argument list_hp provided well, designing tibble correct names hyper-parameters. list_ID vector, associating ID value individual hyper-parameters generated. NULL (default) one set hyper-parameters return without ID column. list_hp vector characters, providing name hyper-parameter, case kern custom kernel function. noise logical value, indicating whether 'noise' hyper-parameter included. common_hp logical value, indicating whether set hyper-parameters assumed common individuals.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/hp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate random hyper-parameters — hp","text":"tibble, providing set random hyper-parameters associated kernel specified argument kern.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/hp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate random hyper-parameters — hp","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/hyperposterior.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the hyper-posterior distribution in Magma — hyperposterior","title":"Compute the hyper-posterior distribution in Magma — hyperposterior","text":"Compute parameters hyper-posterior Gaussian distribution mean process Magma (similarly expectation step EM algorithm used learning). hyper-posterior distribution, evaluated grid inputs provided grid_inputs argument, key component making prediction Magma, required function pred_magma.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/hyperposterior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the hyper-posterior distribution in Magma — hyperposterior","text":"","code":"hyperposterior(   trained_model = NULL,   data = NULL,   hp_0 = NULL,   hp_i = NULL,   kern_0 = NULL,   kern_i = NULL,   prior_mean = NULL,   grid_inputs = NULL,   pen_diag = 1e-10 )"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/hyperposterior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the hyper-posterior distribution in Magma — hyperposterior","text":"trained_model list, containing  information coming Magma model, previously trained using train_magma function. trained_model provided, arguments data, hp_0, hp_i, kern_0, kern_i required. data tibble data frame. Required columns: 'Input', 'Output'. Additional columns covariates can specified. 'Input' column define variable used reference observations (e.g. time longitudinal data). 'Output' column specifies observed values (response variable). data frame can also provide many covariates desired, constraints column names. covariates additional inputs (explanatory variables) models also observed reference 'Input'. Recovered trained_model provided. hp_0 named vector, tibble data frame hyper-parameters associated kern_0. Recovered trained_model provided. hp_i tibble data frame hyper-parameters associated kern_i. Recovered trained_model provided. kern_0 kernel function, associated mean GP. Several popular kernels (see Kernel Cookbook) already implemented can selected within following list: \"SE\": (default value) Squared Exponential Kernel (also called Radial Basis Function Gaussian kernel), \"LIN\": Linear kernel, \"PERIO\": Periodic kernel, \"RQ\": Rational Quadratic kernel. Compound kernels can created sums products kernels. combining kernels, simply provide formula character string elements separated whitespaces (e.g. \"SE + PERIO\"). elements treated sequentially left right, product operator '*' shall always used '+' operators (e.g. 'SE * LIN + RQ' valid whereas 'RQ + SE * LIN'  ). Recovered trained_model provided. kern_i kernel function, associated individual GPs. (\"SE\", \"PERIO\" \"RQ\" aso available ). Recovered trained_model provided. prior_mean Hyper-prior mean parameter mean GP. argument, can specified various formats, : NULL (default). hyper-prior mean set 0 everywhere. number. hyper-prior mean constant function. vector length distinct Input values data argument. vector considered evaluation hyper-prior mean function training Inputs. function. function defined hyper-prior mean. tibble data frame. Required columns: Input, Output. Input values include least values data argument. grid_inputs vector data frame, indicating grid additional reference inputs mean process' hyper-posterior evaluated. pen_diag number. jitter term, added diagonal prevent numerical issues inverting nearly singular matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/hyperposterior.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the hyper-posterior distribution in Magma — hyperposterior","text":"list gathering parameters mean processes' hyper-posterior distributions, namely: mean: tibble, hyper-posterior mean parameter evaluated training Input. cov: matrix, covariance parameter hyper-posterior distribution mean process. pred: tibble, predicted mean variance Input mean process' hyper-posterior distribution format allows direct visualisation GP prediction.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/hyperposterior.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute the hyper-posterior distribution in Magma — hyperposterior","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/hyperposterior_clust.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the hyper-posterior distribution for each cluster in MagmaClust — hyperposterior_clust","title":"Compute the hyper-posterior distribution for each cluster in MagmaClust — hyperposterior_clust","text":"Recompute E-step VEM algorithm MagmaClust new set reference Input. training completed, can necessary evaluate hyper-posterior distributions mean processes specific locations, want make predictions. process directly implemented pred_magmaclust function user might want use hyperpost_clust tailored control prediction procedure.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/hyperposterior_clust.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the hyper-posterior distribution for each cluster in MagmaClust — hyperposterior_clust","text":"","code":"hyperposterior_clust(   trained_model = NULL,   data = NULL,   mixture = NULL,   hp_k = NULL,   hp_i = NULL,   kern_k = NULL,   kern_i = NULL,   prior_mean_k = NULL,   grid_inputs = NULL,   pen_diag = 1e-10 )"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/hyperposterior_clust.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the hyper-posterior distribution for each cluster in MagmaClust — hyperposterior_clust","text":"trained_model list, containing  information coming Magma model, previously trained using train_magma function. trained_model provided, arguments data, mixture, hp_k, hp_i, kern_k, kern_i required. data tibble data frame. Required columns: ID, Input , Output. Additional columns covariates can specified. ID column contains unique names/codes used identify individual/task (batch data). Input column define variable used reference observations (e.g. time longitudinal data). Output column specifies observed values (response variable). data frame can also provide many covariates desired, constraints column names. covariates additional inputs (explanatory variables) models also observed reference Input. Recovered trained_model provided. mixture tibble data frame, indicating mixture probabilities cluster individual. Required column: ID. Recovered trained_model provided. hp_k tibble data frame hyper-parameters associated kern_k. Recovered trained_model provided. hp_i tibble data frame hyper-parameters associated kern_i. Recovered trained_model provided. kern_k kernel function, associated mean GPs. Several popular kernels (see Kernel Cookbook) already implemented can selected within following list: \"SE\": (default value) Squared Exponential Kernel (also called Radial Basis Function Gaussian kernel), \"LIN\": Linear kernel, \"PERIO\": Periodic kernel, \"RQ\": Rational Quadratic kernel. Compound kernels can created sums products kernels. combining kernels, simply provide formula character string elements separated whitespaces (e.g. \"SE + PERIO\"). elements treated sequentially left right, product operator '*' shall always used '+' operators (e.g. 'SE * LIN + RQ' valid whereas 'RQ + SE * LIN'  ). Recovered trained_model provided. kern_i kernel function, associated individual GPs. (\"SE\", \"LIN\", PERIO\" \"RQ\" also available ). Recovered trained_model provided. prior_mean_k set hyper-prior mean parameters (m_k) K mean GPs, one value cluster. cluster. argument can specified various formats, : NULL (default). hyper-prior means set 0 everywhere. numerical vector length number clusters. number associated one cluster, considered hyper-prior mean parameter cluster (.e. constant function Input). list functions. function associated one cluster. functions evaluated Input values, provide specific hyper-prior mean vectors cluster. grid_inputs vector data frame, indicating grid additional reference inputs mean process' hyper-posterior evaluated. pen_diag number. jitter term, added diagonal prevent numerical issues inverting nearly singular matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/hyperposterior_clust.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the hyper-posterior distribution for each cluster in MagmaClust — hyperposterior_clust","text":"list containing parameters mean processes' hyper-posterior distribution, namely: mean: list tibbles containing, cluster, hyper-posterior mean parameters evaluated Input. cov: list matrices containing, cluster, hyper-posterior covariance parameter mean process. mixture: tibble, indicating mixture probabilities cluster individual.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/hyperposterior_clust.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute the hyper-posterior distribution for each cluster in MagmaClust — hyperposterior_clust","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/ini_kmeans.html","id":null,"dir":"Reference","previous_headings":"","what":"Run a k-means algorithm to initialise clusters' allocation — ini_kmeans","title":"Run a k-means algorithm to initialise clusters' allocation — ini_kmeans","text":"Run k-means algorithm initialise clusters' allocation","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/ini_kmeans.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run a k-means algorithm to initialise clusters' allocation — ini_kmeans","text":"","code":"ini_kmeans(data, k, nstart = 50, summary = FALSE)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/ini_kmeans.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run a k-means algorithm to initialise clusters' allocation — ini_kmeans","text":"data tibble containing common Input associated Output values cluster. k number clusters assumed running kmeans algorithm. nstart number, indicating many re-starts kmeans set. summary boolean, indicating whether want outcome summary","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/ini_kmeans.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run a k-means algorithm to initialise clusters' allocation — ini_kmeans","text":"tibble containing initial clustering obtained kmeans.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/ini_kmeans.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run a k-means algorithm to initialise clusters' allocation — ini_kmeans","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/ini_mixture.html","id":null,"dir":"Reference","previous_headings":"","what":"Mixture initialisation with kmeans — ini_mixture","title":"Mixture initialisation with kmeans — ini_mixture","text":"Provide initial kmeans allocation individuals/tasks dataset definite number clusters, return associated mixture probabilities.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/ini_mixture.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mixture initialisation with kmeans — ini_mixture","text":"","code":"ini_mixture(data, k, name_clust = NULL, nstart = 50)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/ini_mixture.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Mixture initialisation with kmeans — ini_mixture","text":"data tibble data frame. Required columns: ID, Input , Output. k number, indicating number clusters. name_clust vector characters. element correspond name one cluster. nstart number restart used underlying kmeans algorithm","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/ini_mixture.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Mixture initialisation with kmeans — ini_mixture","text":"tibble indicating ID cluster belongs kmeans initialisation.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/ini_mixture.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Mixture initialisation with kmeans — ini_mixture","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/kern_to_cov.html","id":null,"dir":"Reference","previous_headings":"","what":"Create covariance matrix from a kernel — kern_to_cov","title":"Create covariance matrix from a kernel — kern_to_cov","text":"kern_to_cov() creates covariance matrix input values (either scalars vectors) evaluated within kernel function, characterised specified hyper-parameters. matrix finite-dimensional evaluation infinite-dimensional covariance structure GP, defined thanks kernel.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/kern_to_cov.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create covariance matrix from a kernel — kern_to_cov","text":"","code":"kern_to_cov(input, kern = \"SE\", hp, deriv = NULL, input_2 = NULL)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/kern_to_cov.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create covariance matrix from a kernel — kern_to_cov","text":"input vector, matrix, data frame tibble containing inputs one individual. vector, elements used reference, otherwise , one column named 'Input' indicate represents reference (e.g. 'Input' contain timestamps time-series applications). columns considered covariates. column named 'Input', first one used default. kern kernel function. Several popular kernels (see Kernel Cookbook) already implemented can selected within following list: \"SE\": (default value) Squared Exponential Kernel (also called Radial Basis Function Gaussian kernel), \"LIN\": Linear kernel, \"PERIO\": Periodic kernel, \"RQ\": Rational Quadratic kernel. Compound kernels can created sums products kernels. combining kernels, simply provide formula character string elements separated whitespaces (e.g. \"SE + PERIO\"). elements treated sequentially left right, product operator '*' shall always used '+' operators (e.g. 'SE * LIN + RQ' valid whereas 'RQ + SE * LIN'  ). hp list, data frame tibble containing hyper-parameters used kernel. name elements (columns) correspond exactly used kernel definition. hp contains element column 'Noise', value added diagonal covariance matrix. deriv character, indicating according hyper-parameter derivative computed. NULL (default), function simply returns covariance matrix. input_2 (optional) vector, matrix, data frame tibble format input. argument used kernel needs evaluated two different sets inputs, typically resulting non-square matrix.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/kern_to_cov.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create covariance matrix from a kernel — kern_to_cov","text":"covariance matrix, elements evaluations associated kernel pair reference inputs.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/kern_to_cov.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create covariance matrix from a kernel — kern_to_cov","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/kern_to_inv.html","id":null,"dir":"Reference","previous_headings":"","what":"Create inverse of a covariance matrix from a kernel — kern_to_inv","title":"Create inverse of a covariance matrix from a kernel — kern_to_inv","text":"kern_to_inv() creates inverse covariance matrix input values (either scalars vectors) evaluated within kernel function, characterised specified hyper-parameters. matrix finite-dimensional evaluation infinite-dimensional covariance structure GP, defined thanks kernel.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/kern_to_inv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create inverse of a covariance matrix from a kernel — kern_to_inv","text":"","code":"kern_to_inv(input, kern, hp, pen_diag = 1e-10, deriv = NULL)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/kern_to_inv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create inverse of a covariance matrix from a kernel — kern_to_inv","text":"input vector, matrix, data frame tibble containing inputs one individual. vector, elements used reference, otherwise ,one column named 'Input' indicate represents reference (e.g. 'Input' contain timestamps time-series applications). columns considered covariates. column named 'Input', first one used default. kern kernel function. Several popular kernels (see Kernel Cookbook) already implemented can selected within following list: \"SE\": (default value) Squared Exponential Kernel (also called Radial Basis Function Gaussian kernel), \"LIN\": Linear kernel, \"PERIO\": Periodic kernel, \"RQ\": Rational Quadratic kernel. Compound kernels can created sums products kernels. combining kernels, simply provide formula character string elements separated whitespaces (e.g. \"SE + PERIO\"). elements treated sequentially left right, product operator '*' shall always used '+' operators (e.g. 'SE * LIN + RQ' valid whereas 'RQ + SE * LIN'  ). hp list, data frame tibble containing hyper-parameters used kernel. name elements (columns) correspond exactly used kernel definition. pen_diag jitter term added covariance matrix avoid numerical issues inverting, cases nearly singular matrices. deriv character, indicating according hyper-parameter derivative computed. NULL (default), function simply returns inverse covariance matrix.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/kern_to_inv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create inverse of a covariance matrix from a kernel — kern_to_inv","text":"inverse covariance matrix, elements evaluations associated kernel pair reference inputs.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/kern_to_inv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create inverse of a covariance matrix from a kernel — kern_to_inv","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/lin_kernel.html","id":null,"dir":"Reference","previous_headings":"","what":"Linear Kernel — lin_kernel","title":"Linear Kernel — lin_kernel","text":"Linear Kernel","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/lin_kernel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Linear Kernel — lin_kernel","text":"","code":"lin_kernel(x, y, hp, deriv = NULL, vectorized = FALSE)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/lin_kernel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Linear Kernel — lin_kernel","text":"x vector (matrix vectorized = T) inputs. y vector (matrix vectorized = T) inputs. hp tibble, data frame named vector, containing kernel's hyperparameters. Required columns: 'lin_slope' 'lin_offset'. deriv character, indicating according hyper-parameter derivative computed. NULL (default), function simply returns evaluation kernel. vectorized logical value, indicating whether function provides vectorized version speeded-calculations. TRUE, x y arguments vector matrix containing inputs kernel evaluated pairs elements. FALSE, x y arguments simply two inputs.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/lin_kernel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Linear Kernel — lin_kernel","text":"scalar, corresponding evaluation kernel.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/lin_kernel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Linear Kernel — lin_kernel","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/list_kern_to_cov.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute a covariance matrix for multiple individuals — list_kern_to_cov","title":"Compute a covariance matrix for multiple individuals — list_kern_to_cov","text":"Compute covariance matrices associated individuals database, taking account specific inputs hyper-parameters.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/list_kern_to_cov.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute a covariance matrix for multiple individuals — list_kern_to_cov","text":"","code":"list_kern_to_cov(data, kern, hp, deriv = NULL)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/list_kern_to_cov.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute a covariance matrix for multiple individuals — list_kern_to_cov","text":"data tibble data frame input data. Required column: 'ID'. Suggested column: 'Input' (indicating reference input). kern kernel function. hp tibble data frame, containing hyper-parameters associated individual. deriv character, indicating according hyper-parameter derivative computed. NULL (default), function simply returns list covariance matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/list_kern_to_cov.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute a covariance matrix for multiple individuals — list_kern_to_cov","text":"named list containing inverse covariance matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/list_kern_to_cov.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute a covariance matrix for multiple individuals — list_kern_to_cov","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/list_kern_to_inv.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute an inverse covariance matrix for multiple individuals — list_kern_to_inv","title":"Compute an inverse covariance matrix for multiple individuals — list_kern_to_inv","text":"Compute inverse covariance matrices associated individuals database, taking account specific inputs hyper-parameters.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/list_kern_to_inv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute an inverse covariance matrix for multiple individuals — list_kern_to_inv","text":"","code":"list_kern_to_inv(db, kern, hp, pen_diag, deriv = NULL)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/list_kern_to_inv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute an inverse covariance matrix for multiple individuals — list_kern_to_inv","text":"db tibble data frame input data. Required column: 'ID'. Suggested column: 'Input' (indicating reference input). kern kernel function. hp tibble data frame, containing hyper-parameters associated individual. pen_diag number. jitter term, added diagonal prevent numerical issues inverting nearly singular matrices. deriv character, indicating according hyper-parameter derivative computed. NULL (default), function simply returns list covariance matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/list_kern_to_inv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute an inverse covariance matrix for multiple individuals — list_kern_to_inv","text":"named list containing inverse covariance matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/list_kern_to_inv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute an inverse covariance matrix for multiple individuals — list_kern_to_inv","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/logL_GP.html","id":null,"dir":"Reference","previous_headings":"","what":"Log-Likelihood function of a Gaussian Process — logL_GP","title":"Log-Likelihood function of a Gaussian Process — logL_GP","text":"Log-Likelihood function Gaussian Process","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/logL_GP.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log-Likelihood function of a Gaussian Process — logL_GP","text":"","code":"logL_GP(hp, db, mean, kern, post_cov, pen_diag)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/logL_GP.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log-Likelihood function of a Gaussian Process — logL_GP","text":"hp tibble, data frame named vector containing hyper-parameters. db tibble containing values want compute logL . Required columns: Input, Output. Additional covariate columns allowed. mean vector, specifying mean GP reference inputs. kern kernel function. post_cov (optional) matrix, corresponding covariance parameter hyper-posterior. Used compute hyper-prior distribution new individual Magma. pen_diag jitter term added covariance matrix avoid numerical issues inverting, cases nearly singular matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/logL_GP.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Log-Likelihood function of a Gaussian Process — logL_GP","text":"number, corresponding value Gaussian log-Likelihood (covariance can sum individual hyper-posterior's mean process covariances).","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/logL_GP.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Log-Likelihood function of a Gaussian Process — logL_GP","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/logL_GP_mod.html","id":null,"dir":"Reference","previous_headings":"","what":"Modified log-Likelihood function for GPs — logL_GP_mod","title":"Modified log-Likelihood function for GPs — logL_GP_mod","text":"Log-Likelihood function involved Magma maximisation step training. log-Likelihood defined simple Gaussian likelihood added correction trace term.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/logL_GP_mod.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Modified log-Likelihood function for GPs — logL_GP_mod","text":"","code":"logL_GP_mod(hp, db, mean, kern, post_cov, pen_diag)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/logL_GP_mod.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Modified log-Likelihood function for GPs — logL_GP_mod","text":"hp tibble, data frame named vector hyper-parameters. db tibble containing values want compute logL . Required columns: Input, Output. Additional covariate columns allowed. mean vector, specifying mean GP reference inputs. kern kernel function. post_cov matrix, covariance parameter hyper-posterior. Used compute correction term. pen_diag jitter term added covariance matrix avoid numerical issues inverting, cases nearly singular matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/logL_GP_mod.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Modified log-Likelihood function for GPs — logL_GP_mod","text":"number, corresponding value modified Gaussian log-Likelihood defined Magma.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/logL_GP_mod.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Modified log-Likelihood function for GPs — logL_GP_mod","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/logL_GP_mod_common_hp.html","id":null,"dir":"Reference","previous_headings":"","what":"Modified log-Likelihood function with common HPs for GPs — logL_GP_mod_common_hp","title":"Modified log-Likelihood function with common HPs for GPs — logL_GP_mod_common_hp","text":"Log-Likelihood function involved Magma maximisation step training, particular case hyper-parameters shared individuals. log-Likelihood defined sum individuals Gaussian likelihoods added correction trace terms.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/logL_GP_mod_common_hp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Modified log-Likelihood function with common HPs for GPs — logL_GP_mod_common_hp","text":"","code":"logL_GP_mod_common_hp(hp, db, mean, kern, post_cov, pen_diag)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/logL_GP_mod_common_hp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Modified log-Likelihood function with common HPs for GPs — logL_GP_mod_common_hp","text":"hp tibble, data frame hyper-parameters. db tibble containing values want compute logL . Required columns: ID, Input, Output. Additional covariate columns allowed. mean vector, specifying mean GP reference inputs. kern kernel function. post_cov matrix, covariance parameter hyper-posterior. Used compute correction term. pen_diag jitter term added covariance matrix avoid numerical issues inverting, cases nearly singular matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/logL_GP_mod_common_hp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Modified log-Likelihood function with common HPs for GPs — logL_GP_mod_common_hp","text":"number, corresponding value modified Gaussian log-Likelihood common hyper-parameters defined Magma.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/logL_GP_mod_common_hp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Modified log-Likelihood function with common HPs for GPs — logL_GP_mod_common_hp","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/logL_monitoring.html","id":null,"dir":"Reference","previous_headings":"","what":"Log-Likelihood for monitoring the EM algorithm in Magma — logL_monitoring","title":"Log-Likelihood for monitoring the EM algorithm in Magma — logL_monitoring","text":"Log-Likelihood monitoring EM algorithm Magma","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/logL_monitoring.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log-Likelihood for monitoring the EM algorithm in Magma — logL_monitoring","text":"","code":"logL_monitoring(   hp_0,   hp_i,   db,   m_0,   kern_0,   kern_i,   post_mean,   post_cov,   pen_diag )"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/logL_monitoring.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log-Likelihood for monitoring the EM algorithm in Magma — logL_monitoring","text":"hp_0 named vector, tibble data frame, containing hyper-parameters associated mean GP. hp_i tibble data frame, containing hyper-parameters individual GPs. db tibble data frame. Columns required: ID, Input, Output. Additional columns covariates can specified. m_0 vector, corresponding prior mean mean GP. kern_0 kernel function, associated mean GP. kern_i kernel function, associated individual GPs. post_mean tibble, coming E step, containing Input associated Output hyper-posterior mean parameter. post_cov matrix, coming E step, hyper-posterior covariance parameter. pen_diag jitter term added covariance matrix avoid numerical issues inverting, cases nearly singular matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/logL_monitoring.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Log-Likelihood for monitoring the EM algorithm in Magma — logL_monitoring","text":"number, expectation joint log-likelihood model. quantity supposed increase step EM algorithm, thus used monitoring procedure.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/logL_monitoring.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Log-Likelihood for monitoring the EM algorithm in Magma — logL_monitoring","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/m_step.html","id":null,"dir":"Reference","previous_headings":"","what":"M-Step of the EM algorithm — m_step","title":"M-Step of the EM algorithm — m_step","text":"Maximisation step EM algorithm compute hyper-parameters kernels involved Magma.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/m_step.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"M-Step of the EM algorithm — m_step","text":"","code":"m_step(   db,   m_0,   kern_0,   kern_i,   old_hp_0,   old_hp_i,   post_mean,   post_cov,   common_hp,   pen_diag )"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/m_step.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"M-Step of the EM algorithm — m_step","text":"db tibble data frame. Columns required: ID, Input, Output. Additional columns covariates can specified. m_0 vector, corresponding prior mean mean GP. kern_0 kernel function, associated mean GP. kern_i kernel function, associated individual GPs. old_hp_0 named vector, tibble data frame, containing hyper-parameters previous M-step (initialisation) associated mean GP. old_hp_i tibble data frame, containing hyper-parameters previous M-step (initialisation) associated individual GPs. post_mean tibble, coming E step, containing Input associated Output hyper-posterior mean parameter. post_cov matrix, coming E step, hyper-posterior covariance parameter. common_hp logical value, indicating whether set hyper-parameters assumed common indiviuals. pen_diag number. jitter term, added diagonal prevent numerical issues inverting nearly singular matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/m_step.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"M-Step of the EM algorithm — m_step","text":"named list, containing elements hp_0, tibble containing hyper-parameters associated mean GP, hp_i, tibble containing hyper-parameters associated individual GPs.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/m_step.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"M-Step of the EM algorithm — m_step","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/perio_kernel.html","id":null,"dir":"Reference","previous_headings":"","what":"Periodic Kernel — perio_kernel","title":"Periodic Kernel — perio_kernel","text":"Periodic Kernel","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/perio_kernel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Periodic Kernel — perio_kernel","text":"","code":"perio_kernel(x, y, hp, deriv = NULL, vectorized = FALSE)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/perio_kernel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Periodic Kernel — perio_kernel","text":"x vector (matrix vectorized = T) inputs. y vector (matrix vectorized = T) inputs. hp tibble, data frame named vector, containing kernel's hyperparameters. Required columns: 'perio_variance', 'perio_lengthscale', 'period'. deriv character, indicating according hyper-parameter derivative computed. NULL (default), function simply returns evaluation kernel. vectorized logical value, indicating whether function provides vectorized version speeded-calculations. TRUE, x y arguments vector matrix containing inputs kernel evaluated pairs elements. FALSE, x y arguments simply two inputs.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/perio_kernel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Periodic Kernel — perio_kernel","text":"scalar, corresponding evaluation kernel.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/perio_kernel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Periodic Kernel — perio_kernel","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/pipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipe operator — %>%","text":"lhs value magrittr placeholder. rhs function call using magrittr semantics.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/pipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipe operator — %>%","text":"result calling rhs(lhs).","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/plot_db.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot smoothed curves of raw data — plot_db","title":"Plot smoothed curves of raw data — plot_db","text":"Display raw data Magma format smoothed curves.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/plot_db.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot smoothed curves of raw data — plot_db","text":"","code":"plot_db(data, cluster = FALSE, legend = FALSE)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/plot_db.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot smoothed curves of raw data — plot_db","text":"data data frame tibble format : ID, Input, Output. cluster boolean indicating whether data coloured cluster. Requires column named 'Cluster'. legend boolean indicating whether legend displayed.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/plot_db.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot smoothed curves of raw data — plot_db","text":"Graph smoothed curves raw data.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/plot_db.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot smoothed curves of raw data — plot_db","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/plot_gif.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a GIF of Magma or GP predictions — plot_gif","title":"Create a GIF of Magma or GP predictions — plot_gif","text":"Create GIF animation displaying Magma classic GP predictions evolve improve number data points increase.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/plot_gif.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a GIF of Magma or GP predictions — plot_gif","text":"","code":"plot_gif(   pred_gp,   x_input = NULL,   data = NULL,   data_train = NULL,   prior_mean = NULL,   y_grid = NULL,   heatmap = FALSE,   prob_CI = 0.95,   size_data = 3,   size_data_train = 1,   alpha_data_train = 0.5,   export_gif = FALSE,   path = \"gif_gp.gif\",   ... )"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/plot_gif.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a GIF of Magma or GP predictions — plot_gif","text":"pred_gp tibble, typically coming pred_gif function. Required columns: 'Input', 'Mean', 'Var' 'Index'. x_input vector character strings, indicating input displayed. NULL(default) 'Input' column used x-axis. providing 2-dimensional vector, corresponding columns used x-axis y-axis. data (Optional) tibble data frame. Required columns: 'Input', 'Output'. Additional columns covariates can specified. 'Input' column define variable used reference observations (e.g. time longitudinal data). 'Output' column specifies observed values (response variable). data frame can also provide many covariates desired, constraints column names. covariates additional inputs (explanatory variables) models also observed reference 'Input'. data_train (Optional) tibble data frame, containing training data Magma model. data set format data argument additional column 'ID' identifying different individuals/tasks. provided, data displayed backward colourful points (colour corresponding one individual/task). prior_mean (Optional) tibble data frame, containing 'Input' associated 'Output' prior mean parameter GP prediction. y_grid vector, indicating grid values y-axis probabilities computed heatmaps 1-dimensional predictions. NULL (default), vector length 50 defined, ranging min max 'Output' values contained pred_gp. heatmap logical value indicating whether GP prediction represented heatmap probabilities 1-dimensional inputs. FALSE (default), mean curve associated 95% CI displayed. prob_CI number 0 1 (default 0.95), indicating level Credible Interval associated posterior mean curve. size_data number, controlling size data points. size_data_train number, controlling size data_train points. alpha_data_train number, 0 1, controlling transparency data_train points. export_gif logical value indicating whether animation exported .gif file. path character string defining path GIF file exported. ... additional parameters can passed function transition_states gganimate package.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/plot_gif.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a GIF of Magma or GP predictions — plot_gif","text":"Visualisation Magma GP prediction (optional: display data points, training data points prior mean function), data points added sequentially visualising changes prediction information increases.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/plot_gif.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a GIF of Magma or GP predictions — plot_gif","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/plot_gp.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Magma or GP predictions — plot_gp","title":"Plot Magma or GP predictions — plot_gp","text":"Display Magma classic GP predictions. According dimension inputs, graph may mean curve + Credible Interval heatmap probabilities.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/plot_gp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Magma or GP predictions — plot_gp","text":"","code":"plot_gp(   pred_gp,   x_input = NULL,   data = NULL,   data_train = NULL,   prior_mean = NULL,   y_grid = NULL,   heatmap = FALSE,   prob_CI = 0.95,   size_data = 3,   size_data_train = 1,   alpha_data_train = 0.5 )"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/plot_gp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Magma or GP predictions — plot_gp","text":"pred_gp tibble data frame, typically coming pred_magma pred_gp functions. Required columns: 'Input', 'Mean', 'Var'. Additional covariate columns may present case multi-dimensional inputs. x_input vector character strings, indicating input displayed. NULL (default) 'Input' column used x-axis. providing 2-dimensional vector, corresponding columns used x-axis y-axis. data (Optional) tibble data frame. Required columns: 'Input', 'Output'. Additional columns covariates can specified. argument corresponds raw data prediction performed. data_train (Optional) tibble data frame, containing training data Magma model. data set format data argument additional required column 'ID' identifying different individuals/tasks. provided, data displayed backward colourful points (colour corresponding one individual/task). prior_mean (Optional) tibble data frame, containing 'Input' associated 'Output' prior mean parameter GP prediction. y_grid vector, indicating grid values y-axis probabilities computed heatmaps 1-dimensional predictions. NULL (default), vector length 50 defined, ranging min max 'Output' values contained pred_gp. heatmap logical value indicating whether GP prediction represented heatmap probabilities 1-dimensional inputs. FALSE (default), mean curve associated Credible Interval displayed. prob_CI number 0 1 (default 0.95), indicating level Credible Interval associated posterior mean curve. argument set 1, Credible Interval displayed. size_data number, controlling size data points. size_data_train number, controlling size data_train points. alpha_data_train number, 0 1, controlling transparency data_train points.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/plot_gp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Magma or GP predictions — plot_gp","text":"Visualisation Magma GP prediction (optional: display data points, training data points prior mean function). 1-D inputs, prediction represented mean curve associated 95%  Credible Interval, heatmap probabilities heatmap = TRUE. 2-D inputs, prediction represented heatmap, couple inputs x-axis y-axis associated gradient colours posterior mean values, whereas uncertainty indicated transparency (narrower Credible Interval, opaque associated colour, vice versa)","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/plot_gp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Magma or GP predictions — plot_gp","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/plot_magmaclust.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot MagmaClust predictions — plot_magmaclust","title":"Plot MagmaClust predictions — plot_magmaclust","text":"Display MagmaClust predictions. According dimension inputs, graph may mean curve (dim inputs = 1) heatmap (dim inputs = 2) probabilities. Moreover, MagmaClust can provide credible intervals visualising cluster-specific predictions (e.g. probable cluster). visualising full mixture--GPs prediction, can multimodal, user choose simple mean function full heatmap probabilities (informative slower).","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/plot_magmaclust.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot MagmaClust predictions — plot_magmaclust","text":"","code":"plot_magmaclust(   pred_clust,   cluster = \"all\",   x_input = NULL,   data = NULL,   data_train = NULL,   col_clust = FALSE,   prior_mean = NULL,   y_grid = NULL,   heatmap = FALSE,   prob_CI = 0.95,   size_data = 3,   size_data_train = 1,   alpha_data_train = 0.5 )"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/plot_magmaclust.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot MagmaClust predictions — plot_magmaclust","text":"pred_clust list predictions, typically coming pred_magmaclust. Required elements: pred, mixture, mixture_pred. cluster character string, indicating cluster plot . '' (default) mixture GPs prediction displayed mean curve (1-D inputs) mean heatmap (2-D inputs). Alternatively, name one cluster provided, classic mean curve + credible interval displayed (1-D inputs), heatmap colour gradient mean transparency gradient Credible Interval (2-D inputs). x_input vector character strings, indicating input displayed. NULL (default) 'Input' column used x-axis. providing 2-dimensional vector, corresponding columns used x-axis y-axis. data (Optional) tibble data frame. Required columns: Input , Output. Additional columns covariates can specified. argument corresponds raw data prediction performed. data_train (Optional) tibble data frame, containing training data MagmaClust model. data set format data argument additional required column ID identifying different individuals/tasks. provided, data displayed backward colourful points (colour corresponding one individual cluster, see col_clust ). col_clust boolean indicating whether backward points coloured according individuals probable cluster. one wants colour clusters, column Cluster shall present data_train. advise use data_allocate_cluster automatically creating well-formatted dataset trained MagmaClust model. prior_mean (Optional) list providing, cluster, tibble containing prior mean parameters prediction. argument typically comes outcome hyperpost$mean, available train_magmaclust, pred_magmaclust functions. y_grid vector, indicating grid values y-axis probabilities computed heatmaps 1-dimensional predictions. NULL (default), vector length 50 defined, ranging min max 'Output' values contained pred. heatmap logical value indicating whether GP prediction represented heatmap probabilities 1-dimensional inputs. FALSE (default), mean curve (associated Credible Interval available) displayed. prob_CI number 0 1 (default 0.95), indicating level Credible Interval associated posterior mean curve. argument set 1, Credible Interval displayed. size_data number, controlling size data points. size_data_train number, controlling size data_train points. alpha_data_train number, 0 1, controlling transparency data_train points.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/plot_magmaclust.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot MagmaClust predictions — plot_magmaclust","text":"Visualisation MagmaClust prediction (optional: display data points, training data points prior mean functions). 1-D inputs, prediction represented mean curve (associated 95% Credible Interval cluster-specific predictions), heatmap probabilities heatmap = TRUE. case MagmaClust, heatmap representation preferred clarity, although default display remains mean curve quicker execution. 2-D inputs, prediction represented heatmap, couple inputs x-axis y-axis associated gradient colours posterior mean values, whereas uncertainty indicated transparency (narrower Credible Interval, opaque associated colour, vice versa). 1-D inputs, Credible Interval information available cluster-specific predictions.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/plot_magmaclust.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot MagmaClust predictions — plot_magmaclust","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/pred_gif.html","id":null,"dir":"Reference","previous_headings":"","what":"Magma prediction for ploting GIFs — pred_gif","title":"Magma prediction for ploting GIFs — pred_gif","text":"Generate Magma classic GP prediction format compatible GIF visualisation results. Magma prediction, either trained_model hyperpost argument required. Otherwise, classic GP prediction applied prior mean can specified mean argument.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/pred_gif.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Magma prediction for ploting GIFs — pred_gif","text":"","code":"pred_gif(   data,   trained_model = NULL,   grid_inputs = NULL,   hyperpost = NULL,   mean = NULL,   hp = NULL,   kern = \"SE\",   pen_diag = 1e-10 )"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/pred_gif.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Magma prediction for ploting GIFs — pred_gif","text":"data tibble data frame. Required columns: 'Input', 'Output'. Additional columns covariates can specified. 'Input' column define variable used reference observations (e.g. time longitudinal data). 'Output' column specifies observed values (response variable). data frame can also provide many covariates desired, constraints column names. covariates additional inputs (explanatory variables) models also observed reference 'Input'. trained_model list, containing  information coming Magma model, previously trained using train_magma function. grid_inputs grid inputs (reference Input covariates) values GP evaluated. Ideally, argument tibble data frame, providing columns data, except 'Output'. Nonetheless, cases data provides one 'Input' column, grid_inputs argument can NULL (default) vector. vector used reference input prediction NULL, vector length 500 defined, ranging min max Input values data. hyperpost list, containing elements 'mean' 'cov', parameters hyper-posterior distribution mean process. Typically, argument previous learning using train_magma, previous prediction pred_magma, argument get_hyperpost set TRUE. 'mean' element data frame two columns 'Input' 'Output'. 'cov' element covariance matrix colnames rownames corresponding 'Input' 'mean'. cases, column 'Input' contain values appearing 'Input' column data grid_inputs. mean Mean parameter GP. argument can specified various formats, : NULL (default). mean set 0 everywhere. number. mean constant function. function. function defined mean. tibble data frame. Required columns: Input, Output. Input values include least values data argument. hp named vector, tibble data frame hyper-parameters associated kern. columns/elements named according hyper-parameters used kern. function train_gp can used learn maximum-likelihood estimators hyper-parameters, kern kernel function, defining covariance structure GP. Several popular kernels (see Kernel Cookbook) already implemented can selected within following list: \"SE\": (default value) Squared Exponential Kernel (also called Radial Basis Function Gaussian kernel), \"LIN\": Linear kernel, \"PERIO\": Periodic kernel, \"RQ\": Rational Quadratic kernel. Compound kernels can created sums products kernels. combining kernels, simply provide formula character string elements separated whitespaces (e.g. \"SE + PERIO\"). elements treated sequentially left right, product operator '*' shall always used '+' operators (e.g. 'SE * LIN + RQ' valid whereas 'RQ + SE * LIN'  ). pen_diag number. jitter term, added diagonal prevent numerical issues inverting nearly singular matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/pred_gif.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Magma prediction for ploting GIFs — pred_gif","text":"tibble, representing Magma GP predictions two column 'Mean' 'Var', evaluated grid_inputs. column 'Input' additional covariates columns associated predicted values. additional 'Index' column created sake GIF creation using function plot_gif","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/pred_gif.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Magma prediction for ploting GIFs — pred_gif","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/pred_gp.html","id":null,"dir":"Reference","previous_headings":"","what":"Gaussian Process prediction — pred_gp","title":"Gaussian Process prediction — pred_gp","text":"Compute posterior distribution standard GP, using formalism Magma. providing observed data, prior mean covariance matrix (defining kernel associated hyper-parameters), mean covariance parameters posterior distribution computed grid inputs specified. predictive distribution can evaluated arbitrary inputs since GP infinite-dimensional object.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/pred_gp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gaussian Process prediction — pred_gp","text":"","code":"pred_gp(   data,   grid_inputs = NULL,   mean = NULL,   hp = NULL,   kern = \"SE\",   get_full_cov = FALSE,   plot = TRUE,   pen_diag = 1e-10 )"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/pred_gp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gaussian Process prediction — pred_gp","text":"data tibble data frame. Required columns: 'Input', 'Output'. Additional columns covariates can specified. 'Input' column define variable used reference observations (e.g. time longitudinal data). 'Output' column specifies observed values (response variable). data frame can also provide many covariates desired, constraints column names. covariates additional inputs (explanatory variables) models also observed reference 'Input'. grid_inputs grid inputs (reference Input covariates) values GP evaluated. Ideally, argument tibble data frame, providing columns data, except 'Output'. Nonetheless, cases data provides one 'Input' column, grid_inputs argument can NULL (default) vector. vector used reference input prediction NULL, vector length 500 defined, ranging min max Input values data. mean Mean parameter GP. argument can specified various formats, : NULL (default). mean set 0 everywhere. number. mean constant function. function. function defined mean. tibble data frame. Required columns: Input, Output. Input values include least values data argument. hp named vector, tibble data frame hyper-parameters associated kern. columns/elements named according hyper-parameters used kern. NULL (default), function train_gp called random initial values learning maximum-likelihood estimators hyper-parameters associated kern. kern kernel function, defining covariance structure GP. Several popular kernels (see Kernel Cookbook) already implemented can selected within following list: \"SE\": (default value) Squared Exponential Kernel (also called Radial Basis Function Gaussian kernel), \"LIN\": Linear kernel, \"PERIO\": Periodic kernel, \"RQ\": Rational Quadratic kernel. Compound kernels can created sums products kernels. combining kernels, simply provide formula character string elements separated whitespaces (e.g. \"SE + PERIO\"). elements treated sequentially left right, product operator '*' shall always used '+' operators (e.g. 'SE * LIN + RQ' valid whereas 'RQ + SE * LIN'  ). get_full_cov logical value, indicating whether full posterior covariance matrix returned. plot logical value, indicating whether plot results automatically displayed. pen_diag number. jitter term, added diagonal prevent numerical issues inverting nearly singular matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/pred_gp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gaussian Process prediction — pred_gp","text":"tibble, representing GP predictions two column 'Mean' 'Var', evaluated grid_inputs. column 'Input' additional covariates columns associated predicted values. get_full_cov argument TRUE, function returns list, tibble described defined 'pred' full posterior covariance matrix defined 'cov'.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/pred_gp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gaussian Process prediction — pred_gp","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/pred_magma.html","id":null,"dir":"Reference","previous_headings":"","what":"Magma prediction — pred_magma","title":"Magma prediction — pred_magma","text":"Compute posterior predictive distribution Magma. Providing data new individual/task, trained hyper-parameters previously trained Magma model, predictive distribution evaluated arbitrary inputs specified 'grid_inputs' argument.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/pred_magma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Magma prediction — pred_magma","text":"","code":"pred_magma(   data,   trained_model = NULL,   grid_inputs = NULL,   hp = NULL,   kern = \"SE\",   hyperpost = NULL,   get_hyperpost = FALSE,   get_full_cov = FALSE,   plot = TRUE,   pen_diag = 1e-10 )"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/pred_magma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Magma prediction — pred_magma","text":"data tibble data frame. Required columns: 'Input', 'Output'. Additional columns covariates can specified. 'Input' column define variable used reference observations (e.g. time longitudinal data). 'Output' column specifies observed values (response variable). data frame can also provide many covariates desired, constraints column names. covariates additional inputs (explanatory variables) models also observed reference 'Input'. trained_model list, containing  information coming Magma model, previously trained using train_magma function. grid_inputs grid inputs (reference Input covariates) values GP evaluated. Ideally, argument tibble data frame, providing columns data, except 'Output'. Nonetheless, cases data provides one 'Input' column, grid_inputs argument can NULL (default) vector. vector used reference input prediction NULL, vector length 500 defined, ranging min max Input values data. hp named vector, tibble data frame hyper-parameters associated kern. columns/elements named according hyper-parameters used kern. function train_gp can used learn maximum-likelihood estimators hyper-parameters. kern kernel function, defining covariance structure GP. Several popular kernels (see Kernel Cookbook) already implemented can selected within following list: \"SE\": (default value) Squared Exponential Kernel (also called Radial Basis Function Gaussian kernel), \"LIN\": Linear kernel, \"PERIO\": Periodic kernel, \"RQ\": Rational Quadratic kernel. Compound kernels can created sums products kernels. combining kernels, simply provide formula character string elements separated whitespaces (e.g. \"SE + PERIO\"). elements treated sequentially left right, product operator '*' shall always used '+' operators (e.g. 'SE * LIN + RQ' valid whereas 'RQ + SE * LIN'  ). hyperpost list, containing elements 'mean' 'cov', parameters hyper-posterior distribution mean process. Typically, argument come previous learning using train_magma, previous prediction pred_magma, argument get_hyperpost set TRUE. 'mean' element data frame two columns 'Input' 'Output'. 'cov' element covariance matrix colnames rownames corresponding 'Input' 'mean'. cases, column 'Input' contain values appearing 'Input' column data grid_inputs. get_hyperpost logical value, indicating whether hyper-posterior distribution mean process returned. can useful planning perform several predictions grid inputs, since recomputation hyper-posterior can prohibitive high dimensional grids. get_full_cov logical value, indicating whether full posterior covariance matrix returned. plot logical value, indicating whether plot results automatically displayed. pen_diag number. jitter term, added diagonal prevent numerical issues inverting nearly singular matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/pred_magma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Magma prediction — pred_magma","text":"tibble, representing Magma predictions two column 'Mean' 'Var', evaluated grid_inputs. column 'Input' additional covariates columns associated predicted values. get_full_cov get_hyperpost arguments TRUE, function returns list, tibble described defined 'pred_gp' full posterior covariance matrix defined 'cov', hyper-posterior distribution mean process defined 'hyperpost'.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/pred_magma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Magma prediction — pred_magma","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/pred_magmaclust.html","id":null,"dir":"Reference","previous_headings":"","what":"MagmaClust prediction — pred_magmaclust","title":"MagmaClust prediction — pred_magmaclust","text":"Compute posterior predictive distribution MagmaClust. Providing data new individual/task, trained hyper-parameters previously trained MagmaClust model, multi-task posterior distribution evaluated arbitrary inputs specified 'grid_inputs' argument. Due nature model, prediction defined mixture Gaussian distributions. Therefore present function computes parameters predictive distribution associated cluster, well posterior mixture probabilities new individual/task.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/pred_magmaclust.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"MagmaClust prediction — pred_magmaclust","text":"","code":"pred_magmaclust(   data,   trained_model = NULL,   grid_inputs = NULL,   mixture = NULL,   hp = NULL,   kern = \"SE\",   hyperpost = NULL,   prop_mixture = NULL,   get_hyperpost = FALSE,   get_full_cov = FALSE,   plot = TRUE,   pen_diag = 1e-10 )"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/pred_magmaclust.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"MagmaClust prediction — pred_magmaclust","text":"data tibble data frame. Required columns: Input, Output. Additional columns covariates can specified. Input column define variable used reference observations (e.g. time longitudinal data). Output column specifies observed values (response variable). data frame can also provide many covariates desired, constraints column names. covariates additional inputs (explanatory variables) models also observed reference 'Input'. trained_model list, containing  information coming MagmaClust model, previously trained using train_magmaclust function. trained_model set NULL, hyperpost prop_mixture arguments mandatory perform required re-computations prediction succeed. grid_inputs grid inputs (reference Input covariates) values GP evaluated. Ideally, argument tibble data frame, providing columns data, except 'Output'. Nonetheless, cases data provides one 'Input' column, grid_inputs argument can NULL (default) vector. vector used reference input prediction NULL, vector length 500 defined, ranging min max Input values data. mixture tibble data frame, indicating mixture probabilities cluster new individual/task. NULL, train_gp_clust function used compute posterior probabilities according data. hp named vector, tibble data frame hyper-parameters associated kern. columns/elements named according hyper-parameters used kern. train_gp_clust function can used learn maximum-likelihood estimators hyper-parameters. kern kernel function, defining covariance structure GP. Several popular kernels (see Kernel Cookbook) already implemented can selected within following list: \"SE\": (default value) Squared Exponential Kernel (also called Radial Basis Function Gaussian kernel), \"LIN\": Linear kernel, \"PERIO\": Periodic kernel, \"RQ\": Rational Quadratic kernel. Compound kernels can created sums products kernels. combining kernels, simply provide formula character string elements separated whitespaces (e.g. \"SE + PERIO\"). elements treated sequentially left right, product operator '*' shall always used '+' operators (e.g. 'SE * LIN + RQ' valid whereas 'RQ + SE * LIN'  ). hyperpost list, containing elements mean, cov mixture parameters hyper-posterior distributions mean processes. Typically, argument come previous learning using train_magmaclust, previous prediction pred_magmaclust, argument get_hyperpost set TRUE. prop_mixture tibble named vector mixture proportions. name column element refer cluster. value associated cluster number 0 1. mixture trained_model set NULL, argument allows recompute mixture probabilities, thanks hyperpost argument train_gp_clust function. get_hyperpost logical value, indicating whether hyper-posterior distributions mean processes returned. can useful planning perform several predictions grid inputs, since recomputation hyper-posterior can prohibitive high dimensional grids. get_full_cov logical value, indicating whether full posterior covariance matrices returned. plot logical value, indicating whether plot results automatically displayed. pen_diag number. jitter term, added diagonal prevent numerical issues inverting nearly singular matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/pred_magmaclust.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"MagmaClust prediction — pred_magmaclust","text":"list GP prediction results composed : pred: sub-list containing, cluster: pred_gp: tibble, representing GP predictions two column Mean Var, evaluated grid_inputs. column Input additional covariates columns associated predicted values. proba: number, posterior probability associated cluster. cov (get_full_cov = TRUE): matrix, full posterior covariance matrix associated cluster. mixture: tibble, indicating mixture probabilities cluster predicted individual/task. hyperpost (get_hyperpost = TRUE): list, containing hyper-posterior distributions information useful visualisation purposes.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/pred_magmaclust.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"MagmaClust prediction — pred_magmaclust","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/proba_max_cluster.html","id":null,"dir":"Reference","previous_headings":"","what":"Indicates the most probable cluster — proba_max_cluster","title":"Indicates the most probable cluster — proba_max_cluster","text":"Indicates probable cluster","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/proba_max_cluster.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Indicates the most probable cluster — proba_max_cluster","text":"","code":"proba_max_cluster(mixture)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/proba_max_cluster.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Indicates the most probable cluster — proba_max_cluster","text":"mixture tibble data frame containing mixture probabilities.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/proba_max_cluster.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Indicates the most probable cluster — proba_max_cluster","text":"tibble, retaining probable cluster. column Cluster indicates cluster's name whereas Proba refers associated probability. ID initially column mixture (optional), function returns probable cluster different ID values.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/proba_max_cluster.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Indicates the most probable cluster — proba_max_cluster","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/regularize_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Regularise a grid of inputs in a dataset — regularize_data","title":"Regularise a grid of inputs in a dataset — regularize_data","text":"Modify original grid inputs make 'regular' (sense interval observation constant, corresponds specific pattern defined user). particular, function can also used summarise several data points one, specific location. case, output values averaged according 'summarise_fct' argument.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/regularize_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Regularise a grid of inputs in a dataset — regularize_data","text":"","code":"regularize_data(   data,   size_grid = 30,   grid_inputs = NULL,   summarise_fct = base::mean )  regularise_data(   data,   size_grid = 30,   grid_inputs = NULL,   summarise_fct = base::mean )"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/regularize_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Regularise a grid of inputs in a dataset — regularize_data","text":"data tibble data frame. Required columns: ID, Output. ID column contains unique names/codes used identify individual/task (batch data). Output column specifies observed values (response variable). data frame can also provide many inputs desired, constraints column names. size_grid integer, indicates number equispaced points column must contain. original input value collapsed closest point new regular grid, associated outputs averaged using 'summarise_fct' function. argument used 'grid_inputs' left 'NULL'. Default value 30. grid_inputs data frame, corresponding pre-defined grid inputs according want regularise dataset (instance, want data point year 0 10, can define grid_inputs = seq(0, 10, 1)). NULL (default), dedicated grid inputs defined: input column, regular sequence created min input values max, number equispaced points equal 'size_grid' argument. summarise_fct character string function. several similar inputs associated different outputs, user can choose summarising function output among following: min, max, mean, median. custom function can defined necessary. Default \"mean\".","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/regularize_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Regularise a grid of inputs in a dataset — regularize_data","text":"data frame, input columns regularised desired.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/regularize_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Regularise a grid of inputs in a dataset — regularize_data","text":"","code":"data = tibble::tibble(ID = 1, Input = 0:100, Output = -50:50)  ## Define a 1D input grid of 10 points regularize_data(data, size_grid = 10) #> # A tibble: 10 × 3 #>       ID Input Output #>    <dbl> <dbl>  <dbl> #>  1     1   0    -47.5 #>  2     1  11.1  -39   #>  3     1  22.2  -28   #>  4     1  33.3  -17   #>  5     1  44.4   -5.5 #>  6     1  55.6    6   #>  7     1  66.7   17   #>  8     1  77.8   28   #>  9     1  88.9   39   #> 10     1 100     47.5  ## Define a 1D custom grid my_grid = tibble::tibble(Input = c(5, 10, 25, 50, 100)) regularize_data(data, grid_inputs = my_grid) #> # A tibble: 5 × 3 #>      ID Input Output #>   <dbl> <dbl>  <dbl> #> 1     1     5  -46.5 #> 2     1    10  -37.5 #> 3     1    25  -22.5 #> 4     1    50    6   #> 5     1   100   37.5  ## Define a 2D input grid of 5x5 points data_2D = cbind(ID = 1, expand.grid(Input=1:10, Input2=1:10), Output = 1:100) regularize_data(data_2D, size_grid = 5) #> # A tibble: 25 × 4 #>       ID Input Input2 Output #>    <dbl> <dbl>  <dbl>  <dbl> #>  1     1  0      0       1   #>  2     1  0      2.25   16   #>  3     1  0      4.5    36   #>  4     1  0      6.75   56   #>  5     1  0      9      81   #>  6     1  2.25   0       2.5 #>  7     1  2.25   2.25   17.5 #>  8     1  2.25   4.5    37.5 #>  9     1  2.25   6.75   57.5 #> 10     1  2.25   9      82.5 #> # ℹ 15 more rows  ## Define a 2D custom input grid my_grid_2D = MagmaClustR::expand_grid_inputs(c(2, 4, 8), 'Input2' = c(3, 5)) regularize_data(data_2D, grid_inputs = my_grid_2D) #> # A tibble: 6 × 4 #>      ID Input Input2 Output #>   <dbl> <dbl>  <dbl>  <dbl> #> 1     1     2      3   11.5 #> 2     1     2      5   61.5 #> 3     1     4      3   14   #> 4     1     4      5   64   #> 5     1     8      3   18   #> 6     1     8      5   68"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/rq_kernel.html","id":null,"dir":"Reference","previous_headings":"","what":"Rational Quadratic Kernel — rq_kernel","title":"Rational Quadratic Kernel — rq_kernel","text":"Rational Quadratic Kernel","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/rq_kernel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rational Quadratic Kernel — rq_kernel","text":"","code":"rq_kernel(x, y, hp, deriv = NULL, vectorized = FALSE)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/rq_kernel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rational Quadratic Kernel — rq_kernel","text":"x vector (matrix vectorized = T) inputs. y vector (matrix vectorized = T) inputs. hp tibble, data frame named vector, containing kernel's hyperparameters. Required columns: 'rq_variance', 'rq_lengthscale', 'rq_scale'. deriv character, indicating according hyper-parameter derivative computed. NULL (default), function simply returns evaluation kernel. vectorized logical value, indicating whether function provides vectorized version speeded-calculations. TRUE, x y arguments vector matrix containing inputs kernel evaluated pairs elements. FALSE, x y arguments simply two inputs.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/rq_kernel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Rational Quadratic Kernel — rq_kernel","text":"scalar, corresponding evaluation kernel.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/rq_kernel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Rational Quadratic Kernel — rq_kernel","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/sample_gp.html","id":null,"dir":"Reference","previous_headings":"","what":"Display realisations from a posterior GP — sample_gp","title":"Display realisations from a posterior GP — sample_gp","text":"realisation posterior GP distribution drawn displayed. According dimension inputs, graph may curve heatmap.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/sample_gp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Display realisations from a posterior GP — sample_gp","text":"","code":"sample_gp(   pred_gp,   nb_samples = 5,   x_input = NULL,   data = NULL,   data_train = NULL,   prior_mean = NULL,   size_data = 3,   size_data_train = 1,   alpha_data_train = 0.5 )"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/sample_gp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Display realisations from a posterior GP — sample_gp","text":"pred_gp tibble data frame, typically coming pred_magma pred_gp functions. Required columns: 'Input', 'Mean', 'Var'. Additional covariate columns may present case multi-dimensional inputs. nb_samples number, indicating number samples drawn predictive posterior distribution. two-dimensional graphs, one sample can displayed. x_input vector character strings, indicating input displayed. NULL(default) 'Input' column used x-axis. providing 2-dimensional vector, corresponding columns used x-axis y-axis. data (Optional) tibble data frame, containing data used GP prediction. data_train (Optional) tibble data frame, containing training data Magma model. data set format data argument additional column 'ID' identifying different individuals/tasks. provided, data displayed backward colourful points (colour corresponding one individual/task). prior_mean (Optional) tibble data frame, containing 'Input' associated 'Output' prior mean parameter GP prediction. size_data number, controlling size data points. size_data_train number, controlling size data_train points. alpha_data_train number, 0 1, controlling transparency data_train points.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/sample_gp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Display realisations from a posterior GP — sample_gp","text":"Draw visualise posterior distribution Magma GP prediction (optional: display data points, training data points prior mean function).","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/sample_gp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Display realisations from a posterior GP — sample_gp","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/se_kernel.html","id":null,"dir":"Reference","previous_headings":"","what":"Squared Exponential Kernel — se_kernel","title":"Squared Exponential Kernel — se_kernel","text":"Squared Exponential Kernel","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/se_kernel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Squared Exponential Kernel — se_kernel","text":"","code":"se_kernel(x, y, hp, deriv = NULL, vectorized = FALSE)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/se_kernel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Squared Exponential Kernel — se_kernel","text":"x vector (matrix vectorized = T) inputs. y vector (matrix vectorized = T) inputs. hp tibble, data frame named vector, containing kernel's hyperparameters. Required columns: 'se_variance', 'se_lengthscale'. deriv character, indicating according hyper-parameter derivative computed. NULL (default), function simply returns evaluation kernel. vectorized logical value, indicating whether function provides vectorized version speeded-calculations. TRUE, x y arguments vector matrix containing inputs kernel evaluated pairs elements. FALSE, x y arguments simply two inputs.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/se_kernel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Squared Exponential Kernel — se_kernel","text":"scalar, corresponding evaluation kernel.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/se_kernel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Squared Exponential Kernel — se_kernel","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/select_nb_cluster.html","id":null,"dir":"Reference","previous_headings":"","what":"Select the optimal number of clusters — select_nb_cluster","title":"Select the optimal number of clusters — select_nb_cluster","text":"MagmaClust, clustering method, number K clusters provided hypothesis model. function implements model selection procedure, maximising variational BIC criterion, computed different values K. heuristic fast approximation procedure proposed well, although corresponding models properly trained.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/select_nb_cluster.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Select the optimal number of clusters — select_nb_cluster","text":"","code":"select_nb_cluster(   data,   fast_approx = TRUE,   grid_nb_cluster = 1:10,   ini_hp_k = NULL,   ini_hp_i = NULL,   kern_k = \"SE\",   kern_i = \"SE\",   plot = TRUE,   ... )"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/select_nb_cluster.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Select the optimal number of clusters — select_nb_cluster","text":"data tibble data frame. Columns required: ID, Input , Output. Additional columns covariates can specified. ID column contains unique names/codes used identify individual/task (batch data). Input column define variable used reference observations (e.g. time longitudinal data). Output column specifies observed values (response variable). data frame can also provide many covariates desired, constraints column names. covariates additional inputs (explanatory variables) models also observed reference Input. fast_approx boolean, indicating whether fast approximation used selecting number clusters. TRUE, Magma MagmaClust model perform one E-step training, using fixed values hyper-parameters (ini_hp_k ini_hp_i, random values provided) models. resulting models considered trained, approach provides convenient heuristic avoid cumbersome model selection procedure. grid_nb_cluster vector integer, corresponding grid values tested number clusters. ini_hp_k tibble data frame hyper-parameters associated kern_k. ini_hp_i tibble data frame hyper-parameters associated kern_i. kern_k kernel function associated mean processes. kern_i kernel function associated individuals/tasks. plot boolean indicating whether plot V-BIC values numbers clusters displayed. ... additional argument passed train_magmaclust.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/select_nb_cluster.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Select the optimal number of clusters — select_nb_cluster","text":"list, containing results model selection procedure selecting optimal number clusters thanks V-BIC criterion maximisation. elements list : best_k: integer, indicating resulting optimal number clusters seq_vbic: vector, corresponding sequence V-BIC values associated models trained provided cluster's number grid_nb_cluster. trained_models: list, named associated number clusters, Magma MagmaClust models trained (approximated fast_approx = T) model selection procedure.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/select_nb_cluster.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Select the optimal number of clusters — select_nb_cluster","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/simu_db.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate a dataset tailored for MagmaClustR — simu_db","title":"Simulate a dataset tailored for MagmaClustR — simu_db","text":"Simulate complete training dataset, may representative various applications. Several flexible arguments allow adjustment number individuals, observed inputs, values many parameters controlling data generation.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/simu_db.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate a dataset tailored for MagmaClustR — simu_db","text":"","code":"simu_db(   M = 10,   N = 10,   K = 1,   covariate = FALSE,   grid = seq(0, 10, 0.05),   grid_cov = seq(0, 10, 0.5),   common_input = TRUE,   common_hp = TRUE,   add_hp = FALSE,   add_clust = FALSE,   int_mu_v = c(4, 5),   int_mu_l = c(0, 1),   int_i_v = c(1, 2),   int_i_l = c(0, 1),   int_i_sigma = c(0, 0.2),   lambda_int = c(30, 40),   m_int = c(0, 10),   lengthscale_int = c(30, 40),   m0_slope = c(-5, 5),   m0_intercept = c(-50, 50) )"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/simu_db.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate a dataset tailored for MagmaClustR — simu_db","text":"M integer. number individual per cluster. N integer. number observations per individual. K integer. number underlying clusters. covariate logical value indicating whether dataset include additional input covariate named 'Covariate'. grid vector numbers defining grid observations (.e. reference inputs). grid_cov vector numbers defining grid observations (.e. covariate reference inputs). common_input logical value indicating whether reference inputs common individual. common_hp logical value indicating whether hyper-parameters common individual. TRUE K>1, hyper-parameters remain different clusters. add_hp logical value indicating whether values hyper-parameters added columns dataset. add_clust logical value indicating whether name clusters added column dataset. int_mu_v vector 2 numbers, defining interval admissible values variance hyper-parameter mean process' kernel. int_mu_l vector 2 numbers, defining interval admissible values lengthscale hyper-parameter mean process' kernel. int_i_v vector 2 numbers, defining interval admissible values variance hyper-parameter individual process' kernel. int_i_l vector 2 numbers, defining interval admissible values lengthscale hyper-parameter individual process' kernel. int_i_sigma vector 2 numbers, defining interval admissible values noise hyper-parameter. lambda_int vector 2 numbers, defining interval admissible values lambda parameter 2D exponential. m_int vector 2 numbers, defining interval admissible values mean 2D exponential. lengthscale_int vector 2 numbers, defining interval admissible values lengthscale parameter 2D exponential. m0_slope vector 2 numbers, defining interval admissible values slope m0. m0_intercept vector 2 numbers, defining interval admissible values intercept m0.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/simu_db.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate a dataset tailored for MagmaClustR — simu_db","text":"full dataset simulated training data.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/simu_db.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate a dataset tailored for MagmaClustR — simu_db","text":"","code":"## Generate a dataset with 3 clusters of 4 individuals, observed at 10 inputs data = simu_db(M = 4, N = 10, K = 3)  ## Generate a 2-D dataset with an additional input 'Covariate' data = simu_db(covariate = TRUE)  ## Generate a dataset where input locations are different among individuals data = simu_db(common_input = FALSE)  ## Generate a dataset with an additional column indicating the true clusters data = simu_db(K = 3, add_clust = TRUE)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/simu_indiv_se.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate a batch of data — simu_indiv_se","title":"Simulate a batch of data — simu_indiv_se","text":"Simulate batch output data, corresponding one individual, coming GP Squared Exponential kernel covariance structure, specified hyper-parameters input.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/simu_indiv_se.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate a batch of data — simu_indiv_se","text":"","code":"simu_indiv_se(ID, input, mean, v, l, sigma)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/simu_indiv_se.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate a batch of data — simu_indiv_se","text":"ID identification code, whether numeric character. input vector numbers. input variable used 'reference' input outputs. mean vector numbers. Prior mean values GP. v number. variance hyper-parameter SE kernel. l number. lengthscale hyper-parameter SE kernel. sigma number. noise hyper-parameter.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/simu_indiv_se.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate a batch of data — simu_indiv_se","text":"tibble containing batch output data along input additional information simulated individual.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/simu_indiv_se.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate a batch of data — simu_indiv_se","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/sum_logL_GP_clust.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute a mixture of Gaussian log-likelihoods — sum_logL_GP_clust","title":"Compute a mixture of Gaussian log-likelihoods — sum_logL_GP_clust","text":"prediction step MagmaClust, EM algorithm used compute maximum likelihood estimator hyper-parameters along mixture probabilities new individual/task. function implements quantity maximised (.e. sum Gaussian log-likelihoods, weighted mixture probabilities). can also used monitor EM algorithm providing 'prop_mixture' argument, proper penalisation full log-likelihood.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/sum_logL_GP_clust.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute a mixture of Gaussian log-likelihoods — sum_logL_GP_clust","text":"","code":"sum_logL_GP_clust(   hp,   db,   mixture,   mean,   kern,   post_cov,   prop_mixture = NULL,   pen_diag )"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/sum_logL_GP_clust.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute a mixture of Gaussian log-likelihoods — sum_logL_GP_clust","text":"hp tibble, data frame named vector hyper-parameters. db tibble containing data want evaluate logL . Required columns: Input, Output. Additional covariate columns allowed. mixture tibble data frame, indicating mixture probabilities cluster new individual/task. mean list hyper-posterior mean parameters clusters. kern kernel function. post_cov list hyper-posterior covariance parameters clusters. prop_mixture tibble named vector. name column element refer cluster. value associated cluster number 0 1, corresponding mixture proportions. pen_diag jitter term added covariance matrix avoid numerical issues inverting, cases nearly singular matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/sum_logL_GP_clust.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute a mixture of Gaussian log-likelihoods — sum_logL_GP_clust","text":"number, expectation mixture Gaussian log-likelihoods prediction step MagmaClust. quantity supposed increase step EM algorithm, can used monitoring procedure.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/sum_logL_GP_clust.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute a mixture of Gaussian log-likelihoods — sum_logL_GP_clust","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/swimmers.html","id":null,"dir":"Reference","previous_headings":"","what":"French swimmers performances data on 100m freestyle events — swimmers","title":"French swimmers performances data on 100m freestyle events — swimmers","text":"subset data reported performances French swimmers 100m freestyle competitions 2002 2016. See https://link.springer.com/article/10.1007/s10994-022-06172-1 https://www.mdpi.com/2076-3417/8/10/1766 dedicated description analysis.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/swimmers.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"French swimmers performances data on 100m freestyle events — swimmers","text":"","code":"swimmers"},{"path":[]},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/swimmers.html","id":"swimmers","dir":"Reference","previous_headings":"","what":"swimmers","title":"French swimmers performances data on 100m freestyle events — swimmers","text":"data frame 76,832 rows 4 columns: ID Indentifying number associated swimmer Input Age years Output Performance seconds 100m freestyle event Gender Competition gender","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/swimmers.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"French swimmers performances data on 100m freestyle events — swimmers","text":"https://ffn.extranat.fr/webffn/competitions.php?idact=nat","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/train_gp.html","id":null,"dir":"Reference","previous_headings":"","what":"Learning hyper-parameters of a Gaussian Process — train_gp","title":"Learning hyper-parameters of a Gaussian Process — train_gp","text":"Learning hyper-parameters new individual/task Magma required prediction procedure. function can also used learn hyper-parameters simple GP (just let hyperpost argument set NULL, use prior_mean instead). using within Magma, providing data new individual/task, hyper-posterior mean covariance parameters, initialisation values hyper-parameters, function computes maximum likelihood estimates hyper-parameters.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/train_gp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Learning hyper-parameters of a Gaussian Process — train_gp","text":"","code":"train_gp(   data,   prior_mean = NULL,   ini_hp = NULL,   kern = \"SE\",   hyperpost = NULL,   pen_diag = 1e-10 )"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/train_gp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Learning hyper-parameters of a Gaussian Process — train_gp","text":"data tibble data frame. Required columns: Input, Output. Additional columns covariates can specified. Input column define variable used reference observations (e.g. time longitudinal data). Output column specifies observed values (response variable). data frame can also provide many covariates desired, constraints column names. covariates additional inputs (explanatory variables) models also observed reference Input. prior_mean Mean parameter GP. argument can specified various formats, : NULL (default). hyper-posterior mean set 0 everywhere. number. hyper-posterior mean constant function. vector length distinct Input values data argument. vector considered evaluation hyper-posterior mean function training Inputs. function. function defined hyper-posterior mean. tibble data frame. Required columns: Input, Output. Input values include least values data argument. ini_hp named vector, tibble data frame hyper-parameters associated kern new individual/task. columns named according hyper-parameters used kern. cases model includes noise term, ini_hp contain additional 'noise' column. NULL (default), random values used initialisation. kern kernel function, defining covariance structure GP. Several popular kernels (see Kernel Cookbook) already implemented can selected within following list: \"SE\": (default value) Squared Exponential Kernel (also called Radial Basis Function Gaussian kernel), \"LIN\": Linear kernel, \"PERIO\": Periodic kernel, \"RQ\": Rational Quadratic kernel. Compound kernels can created sums products kernels. combining kernels, simply provide formula character string elements separated whitespaces (e.g. \"SE + PERIO\"). ² elements treated sequentially left right, product operator '*' shall always used '+' operators (e.g. 'SE * LIN + RQ' valid whereas 'RQ + SE * LIN'  ). hyperpost list, containing elements 'mean' 'cov', parameters hyper-posterior distribution mean process. Typically, argument come previous learning using train_magma, hyperposterior function. hyperpost provided, likelihood maximised one involved Magma's prediction step, prior_mean argument ignored. classic GP training, leave hyperpost NULL. pen_diag number. jitter term, added diagonal prevent numerical issues inverting nearly singular matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/train_gp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Learning hyper-parameters of a Gaussian Process — train_gp","text":"tibble, containing trained hyper-parameters kernel new individual/task.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/train_gp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Learning hyper-parameters of a Gaussian Process — train_gp","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/train_gp_clust.html","id":null,"dir":"Reference","previous_headings":"","what":"Prediction in MagmaClust: learning new HPs and mixture probabilities — train_gp_clust","title":"Prediction in MagmaClust: learning new HPs and mixture probabilities — train_gp_clust","text":"Learning hyper-parameters mixture probabilities new individual/task required MagmaClust prediction procedure. providing data new individual/task, hyper-posterior mean covariance parameters, mixture proportions, initialisation values hyper-parameters, train_gp_clust uses EM algorithm compute maximum likelihood estimates hyper-parameters hyper-posterior mixture probabilities new individual/task.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/train_gp_clust.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prediction in MagmaClust: learning new HPs and mixture probabilities — train_gp_clust","text":"","code":"train_gp_clust(   data,   prop_mixture = NULL,   ini_hp = NULL,   kern = \"SE\",   hyperpost = NULL,   pen_diag = 1e-10,   n_iter_max = 25,   cv_threshold = 0.001 )"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/train_gp_clust.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prediction in MagmaClust: learning new HPs and mixture probabilities — train_gp_clust","text":"data tibble data frame. Required columns: Input, Output. Additional columns covariates can specified. Input column define variable used reference observations (e.g. time longitudinal data). Output column specifies observed values (response variable). data frame can also provide many covariates desired, constraints column names. covariates additional inputs (explanatory variables) models also observed reference Input. prop_mixture tibble named vector. name column element refer cluster. value associated cluster number 0 1, corresponding mixture proportions. ini_hp tibble data frame hyper-parameters associated kern, individual process kernel. kern kernel function, defining covariance structure GP. Several popular kernels (see Kernel Cookbook) already implemented can selected within following list: \"SE\": (default value) Squared Exponential Kernel (also called Radial Basis Function Gaussian kernel), \"LIN\": Linear kernel, \"PERIO\": Periodic kernel, \"RQ\": Rational Quadratic kernel. Compound kernels can created sums products kernels. combining kernels, simply provide formula character string elements separated whitespaces (e.g. \"SE + PERIO\"). ² elements treated sequentially left right, product operator '*' shall always used '+' operators (e.g. 'SE * LIN + RQ' valid whereas 'RQ + SE * LIN'  ). hyperpost list, containing elements mean, cov mixture parameters hyper-posterior distributions mean processes. Typically, argument come previous learning using train_magmaclust, previous prediction pred_magmaclust, argument get_hyperpost set TRUE. pen_diag number. jitter term, added diagonal prevent numerical issues inverting nearly singular matrices. n_iter_max number, indicating maximum number iterations EM algorithm proceed reaching convergence. cv_threshold number, indicating threshold likelihood gain EM algorithm stop.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/train_gp_clust.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prediction in MagmaClust: learning new HPs and mixture probabilities — train_gp_clust","text":"list, containing results EM algorithm used prediction step MagmaClust. elements list : hp: tibble optimal hyper-parameters new individual's GP. mixture: tibble mixture probabilities new individual.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/train_gp_clust.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Prediction in MagmaClust: learning new HPs and mixture probabilities — train_gp_clust","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/train_magma.html","id":null,"dir":"Reference","previous_headings":"","what":"Training Magma with an EM algorithm — train_magma","title":"Training Magma with an EM algorithm — train_magma","text":"hyper-parameters hyper-posterior distribution involved Magma can learned thanks EM algorithm implemented train_magma. providing dataset, model hypotheses (hyper-prior mean parameter covariance kernels) initialisation values hyper-parameters, function computes maximum likelihood estimates HPs well mean covariance parameters Gaussian hyper-posterior distribution mean process.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/train_magma.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Training Magma with an EM algorithm — train_magma","text":"","code":"train_magma(   data,   prior_mean = NULL,   ini_hp_0 = NULL,   ini_hp_i = NULL,   kern_0 = \"SE\",   kern_i = \"SE\",   common_hp = TRUE,   grid_inputs = NULL,   pen_diag = 1e-10,   n_iter_max = 25,   cv_threshold = 0.001,   fast_approx = FALSE )"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/train_magma.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Training Magma with an EM algorithm — train_magma","text":"data tibble data frame. Required columns: ID, Input , Output. Additional columns covariates can specified. ID column contains unique names/codes used identify individual/task (batch data). Input column define variable used reference observations (e.g. time longitudinal data). Output column specifies observed values (response variable). data frame can also provide many covariates desired, constraints column names. covariates additional inputs (explanatory variables) models also observed reference Input. prior_mean Hyper-prior mean parameter (m_0) mean GP. argument can specified various formats, : NULL (default). hyper-prior mean set 0 everywhere. number. hyper-prior mean constant function. vector length distinct Input values data argument. vector considered evaluation hyper-prior mean function training Inputs. function. function defined hyper_prior mean. tibble data frame. Required columns: Input, Output. Input values include least values data argument. ini_hp_0 named vector, tibble data frame hyper-parameters associated kern_0, mean process' kernel. columns/elements named according hyper-parameters used kern_0. NULL (default), random values used initialisation. ini_hp_i tibble data frame hyper-parameters associated kern_i, individual processes' kernel. Required column : ID. ID column contains unique names/codes used identify individual/task. columns named according hyper-parameters used kern_i. Compared ini_hp_0 contain additional 'noise' column initialise noise hyper-parameter model. NULL (default), random values used initialisation. kern_0 kernel function, associated mean GP. Several popular kernels (see Kernel Cookbook) already implemented can selected within following list: \"SE\": (default value) Squared Exponential Kernel (also called Radial Basis Function Gaussian kernel), \"LIN\": Linear kernel, \"PERIO\": Periodic kernel, \"RQ\": Rational Quadratic kernel. Compound kernels can created sums products kernels. combining kernels, simply provide formula character string elements separated whitespaces (e.g. \"SE + PERIO\"). elements treated sequentially left right, product operator '*' shall always used '+' operators (e.g. 'SE * LIN + RQ' valid whereas 'RQ + SE * LIN'  ). kern_i kernel function, associated individual GPs. (\"SE\", \"PERIO\" \"RQ\" also available ). common_hp logical value, indicating whether set hyper-parameters assumed common individuals. grid_inputs vector, indicating grid additional reference inputs mean process' hyper-posterior evaluated. pen_diag number. jitter term, added diagonal prevent numerical issues inverting nearly singular matrices. n_iter_max number, indicating maximum number iterations EM algorithm proceed reaching convergence. cv_threshold number, indicating threshold likelihood gain EM algorithm stop. convergence condition defined difference likelihoods two consecutive steps, divided absolute value last one ( \\((LL_n - LL_n-1) / |LL_n|\\) ). fast_approx boolean, indicating whether EM algorithm stop one iteration E-step. advanced feature mainly used provide faster approximation model selection procedure, preventing optimisation hyper-parameters.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/train_magma.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Training Magma with an EM algorithm — train_magma","text":"list, gathering results EM algorithm used training Magma. elements list : hp_0: tibble trained hyper-parameters mean process' kernel. hp_i: tibble trained hyper-parameters individual processes' kernels. hyperpost: sub-list gathering parameters mean processes' hyper-posterior distributions, namely: mean: tibble, hyper-posterior mean parameter (Output) evaluated training reference Input. cov: matrix, covariance parameter hyper-posterior distribution mean process. pred: tibble, predicted mean variance Input mean process' hyper-posterior distribution format allows direct visualisation GP prediction. ini_args: list containing initial function arguments values hyper-prior mean, hyper-parameters. particular, arguments set NULL, ini_args allows us retrieve (randomly chosen) initialisations used training. seq_loglikelihood: vector, containing sequence log-likelihood values associated iteration. converged: logical value indicated whether EM algorithm converged . training_time: Total running time complete training.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/train_magma.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Training Magma with an EM algorithm — train_magma","text":"user can specify custom kernel functions argument kern_0 kern_i. hyper-parameters used kernel explicit names, contained within hp argument. hp typically defined named vector data frame. Although mandatory train_magma function run, gradients can provided within kernel function definition. See example se_kernel create custom kernel function displaying adequate format used Magma.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/train_magma.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Training Magma with an EM algorithm — train_magma","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/train_magmaclust.html","id":null,"dir":"Reference","previous_headings":"","what":"Training MagmaClust with a Variational EM algorithm — train_magmaclust","title":"Training MagmaClust with a Variational EM algorithm — train_magmaclust","text":"hyper-parameters hyper-posterior distributions involved MagmaClust can learned thanks VEM algorithm implemented train_magmaclust. providing dataset, model hypotheses (hyper-prior mean parameters, covariance kernels number clusters) initialisation values hyper-parameters, function computes maximum likelihood estimates HPs well mean covariance parameters Gaussian hyper-posterior distributions mean processes.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/train_magmaclust.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Training MagmaClust with a Variational EM algorithm — train_magmaclust","text":"","code":"train_magmaclust(   data,   nb_cluster = NULL,   prior_mean_k = NULL,   ini_hp_k = NULL,   ini_hp_i = NULL,   kern_k = \"SE\",   kern_i = \"SE\",   ini_mixture = NULL,   common_hp_k = TRUE,   common_hp_i = TRUE,   grid_inputs = NULL,   pen_diag = 1e-10,   n_iter_max = 25,   cv_threshold = 0.001,   fast_approx = FALSE )"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/train_magmaclust.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Training MagmaClust with a Variational EM algorithm — train_magmaclust","text":"data tibble data frame. Columns required: ID, Input , Output. Additional columns covariates can specified. ID column contains unique names/codes used identify individual/task (batch data). Input column define variable used reference observations (e.g. time longitudinal data). Output column specifies observed values (response variable). data frame can also provide many covariates desired, constraints column names. covariates additional inputs (explanatory variables) models also observed reference Input. nb_cluster number, indicating number clusters individuals/tasks assumed exist among dataset. prior_mean_k set hyper-prior mean parameters (m_k) K mean GPs, one value cluster. cluster. argument can specified various formats, : NULL (default). hyper-prior means set 0 everywhere. numerical vector length number clusters. number associated one cluster, considered hyper-prior mean parameter cluster (.e. constant function Input). list functions. function associated one cluster. functions evaluated Input values, provide specific hyper-prior mean vectors cluster. ini_hp_k tibble data frame hyper-parameters associated kern_k, mean process' kernel. Required column : ID. ID column contains unique names/codes used identify cluster. columns named according hyper-parameters used kern_k. ini_hp_i tibble data frame hyper-parameters associated kern_i, individual processes' kernel. Required column : ID. ID column contains unique names/codes used identify individual/task. columns named according hyper-parameters used kern_i. kern_k kernel function, associated mean GPs. Several popular kernels (see Kernel Cookbook) already implemented can selected within following list: \"SE\": (default value) Squared Exponential Kernel (also called Radial Basis Function Gaussian kernel), \"LIN\": Linear kernel, \"PERIO\": Periodic kernel, \"RQ\": Rational Quadratic kernel. Compound kernels can created sums products kernels. combining kernels, simply provide formula character string elements separated whitespaces (e.g. \"SE + PERIO\"). elements treated sequentially left right, product operator '*' shall always used '+' operators (e.g. 'SE * LIN + RQ' valid whereas 'RQ + SE * LIN'  ). kern_i kernel function, associated individual GPs. (See details kern_k). ini_mixture Initial values probability belong cluster individual (ini_mixture can used k-means initialisation. Used default NULL). common_hp_k boolean indicating whether hyper-parameters common among mean GPs. common_hp_i boolean indicating whether hyper-parameters common among individual GPs. grid_inputs vector, indicating grid additional reference inputs mean processes' hyper-posteriors evaluated. pen_diag number. jitter term, added diagonal prevent numerical issues inverting nearly singular matrices. n_iter_max number, indicating maximum number iterations VEM algorithm proceed reaching convergence. cv_threshold number, indicating threshold likelihood gain VEM algorithm stop. convergence condition defined difference elbo two consecutive steps, divided absolute value last one ( \\((ELBO_n - ELBO_{n-1}) / |ELBO_n| \\) ). fast_approx boolean, indicating whether VEM algorithm stop one iteration VE-step. advanced feature mainly used provide faster approximation model selection procedure, preventing optimisation hyper-parameters.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/train_magmaclust.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Training MagmaClust with a Variational EM algorithm — train_magmaclust","text":"list, containing results VEM algorithm used training step MagmaClust. elements list : hp_k: tibble containing trained hyper-parameters mean process' kernel mixture proportions cluster. hp_i: tibble containing trained hyper-parameters individual processes' kernels. hyperpost: sub-list containing parameters mean processes' hyper-posterior distribution, namely: mean: list tibbles containing, cluster, hyper-posterior mean parameters evaluated Input. cov: list matrices containing, cluster, hyper-posterior covariance parameter mean process. mixture: tibble, indicating mixture probabilities cluster individual. ini_args: list containing initial function arguments values hyper-prior means, hyper-parameters. particular, arguments set NULL, ini_args allows us retrieve (randomly chosen) initialisations used training. seq_elbo: vector, containing sequence ELBO values associated iteration. converged: logical value indicated whether algorithm converged. training_time: Total running time complete training.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/train_magmaclust.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Training MagmaClust with a Variational EM algorithm — train_magmaclust","text":"user can specify custom kernel functions argument kern_k kern_i. hyper-parameters used kernel explicit names, contained within hp argument. hp typically defined named vector data frame. Although mandatory train_magmaclust function run, gradients can provided within kernel function definition. See example se_kernel create custom kernel function displaying adequate format used MagmaClust.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/train_magmaclust.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Training MagmaClust with a Variational EM algorithm — train_magmaclust","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/update_mixture.html","id":null,"dir":"Reference","previous_headings":"","what":"Update the mixture probabilities for each individual and each cluster — update_mixture","title":"Update the mixture probabilities for each individual and each cluster — update_mixture","text":"Update mixture probabilities individual cluster","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/update_mixture.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update the mixture probabilities for each individual and each cluster — update_mixture","text":"","code":"update_mixture(db, mean_k, cov_k, hp, kern, prop_mixture, pen_diag)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/update_mixture.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update the mixture probabilities for each individual and each cluster — update_mixture","text":"db tibble data frame. Columns required: ID, Input, Output. Additional columns covariates can specified. mean_k list K hyper-posterior mean parameters. cov_k list K hyper-posterior covariance matrices. hp named vector, tibble data frame hyper-parameters associated kern, individual process' kernel. columns/elements named according hyper-parameters used kern. kern kernel function, defining covariance structure individual GPs. prop_mixture tibble containing hyper-parameters associated individual, indicating cluster belongs. pen_diag number. jitter term, added diagonal prevent numerical issues inverting nearly singular matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/update_mixture.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Update the mixture probabilities for each individual and each cluster — update_mixture","text":"Compute hyper-posterior multinomial distributions updating mixture probabilities.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/update_mixture.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Update the mixture probabilities for each individual and each cluster — update_mixture","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/ve_step.html","id":null,"dir":"Reference","previous_headings":"","what":"E-Step of the VEM algorithm — ve_step","title":"E-Step of the VEM algorithm — ve_step","text":"Expectation step Variational EM algorithm used compute parameters hyper-posteriors distributions mean processes mixture variables involved MagmaClust.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/ve_step.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"E-Step of the VEM algorithm — ve_step","text":"","code":"ve_step(db, m_k, kern_k, kern_i, hp_k, hp_i, old_mixture, iter, pen_diag)"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/ve_step.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"E-Step of the VEM algorithm — ve_step","text":"db tibble data frame. Columns required: ID, Input, Output. Additional columns covariates can specified. m_k named list vectors, corresponding prior mean parameters K mean GPs. kern_k kernel function, associated K mean GPs. kern_i kernel function, associated M individual GPs. hp_k named vector, tibble data frame hyper-parameters associated kern_k. hp_i named vector, tibble data frame hyper-parameters associated kern_i. old_mixture list mixture values previous iteration. iter number, indicating current iteration VEM algorithm. pen_diag number. jitter term, added diagonal prevent numerical issues inverting nearly singular matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/ve_step.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"E-Step of the VEM algorithm — ve_step","text":"named list, containing elements mean, tibble containing Input associated Output hyper-posterior mean parameters, cov, hyper-posterior covariance matrices, mixture, probabilities belong cluster individual.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/ve_step.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"E-Step of the VEM algorithm — ve_step","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/vm_step.html","id":null,"dir":"Reference","previous_headings":"","what":"V-Step of the VEM algorithm — vm_step","title":"V-Step of the VEM algorithm — vm_step","text":"Maximization step Variational EM algorithm used compute hyper-parameters kernels involved MagmaClust.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/vm_step.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"V-Step of the VEM algorithm — vm_step","text":"","code":"vm_step(   db,   old_hp_k,   old_hp_i,   list_mu_param,   kern_k,   kern_i,   m_k,   common_hp_k,   common_hp_i,   pen_diag )"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/vm_step.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"V-Step of the VEM algorithm — vm_step","text":"db tibble data frame. Columns required: ID, Input, Output. Additional columns covariates can specified. old_hp_k named vector, tibble data frame, containing hyper-parameters previous M-step (initialisation) associated mean GPs. old_hp_i named vector, tibble data frame, containing hyper-parameters previous  M-step (initialisation) associated individual GPs. list_mu_param List parameters K mean GPs. kern_k kernel used compute covariance matrix mean GP corresponding timestamps. kern_i kernel used compute covariance matrix individuals GP corresponding timestamps. m_k named list prior mean parameters K mean GPs. Length = 1 nrow(unique(db$Input)) common_hp_k boolean indicating whether hp common among mean GPs (mu_k) common_hp_i boolean indicating whether hp common among individual GPs (y_i) pen_diag number. jitter term, added diagonal prevent numerical issues inverting nearly singular matrices.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/vm_step.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"V-Step of the VEM algorithm — vm_step","text":"named list, containing elements hp_k, tibble containing hyper-parameters associated cluster, hp_i, tibble containing hyper-parameters associated individual GPs, prop_mixture_k, tibble containing hyper-parameters associated individual, indicating probabilities belong cluster.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/vm_step.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"V-Step of the VEM algorithm — vm_step","text":"","code":"TRUE #> [1] TRUE"},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/weight.html","id":null,"dir":"Reference","previous_headings":"","what":"Weight follow-up data of children in Singapore — weight","title":"Weight follow-up data of children in Singapore — weight","text":"subset data GUSTO project (https://www.gusto.sg/) collecting weight time several children Singapore. See https://arxiv.org/abs/2011.07866 dedicated description analysis.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/weight.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Weight follow-up data of children in Singapore — weight","text":"","code":"weight"},{"path":[]},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/weight.html","id":"weight","dir":"Reference","previous_headings":"","what":"weight","title":"Weight follow-up data of children in Singapore — weight","text":"data frame 3,629 rows 4 columns: ID Indentifying number associated child sex Biological gender Input Age months Output Weight kilograms","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/reference/weight.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Weight follow-up data of children in Singapore — weight","text":"https://www.gusto.sg/","code":""},{"path":[]},{"path":"https://arthurleroy.github.io/MagmaClustR/news/index.html","id":"minor-development-version","dir":"Changelog","previous_headings":"","what":"Minor","title":"MagmaClustR (development version)","text":"Add option generate multiple curves sample_gp() Fix bug ‘Reference’ column present using plot_gp()","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/news/index.html","id":"magmaclustr-112","dir":"Changelog","previous_headings":"","what":"MagmaClustR 1.1.2","title":"MagmaClustR 1.1.2","text":"CRAN release: 2023-05-23","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/news/index.html","id":"minor-1-1-2","dir":"Changelog","previous_headings":"","what":"Minor","title":"MagmaClustR 1.1.2","text":"Fix bug occurring pred_magmaclust() ‘trained_model’ hp_i = FALSE Simplify use hyperposterior() hyperposterior_clust() providing ‘trained_model’ argument.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/news/index.html","id":"magmaclustr-111","dir":"Changelog","previous_headings":"","what":"MagmaClustR 1.1.1","title":"MagmaClustR 1.1.1","text":"CRAN release: 2023-01-17","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/news/index.html","id":"minor-1-1-1","dir":"Changelog","previous_headings":"","what":"Minor","title":"MagmaClustR 1.1.1","text":"Fix issue regarding deprecation .data ‘tidyselect’ Fix unit testing issue","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/news/index.html","id":"magmaclustr-110","dir":"Changelog","previous_headings":"","what":"MagmaClustR 1.1.0","title":"MagmaClustR 1.1.0","text":"CRAN release: 2022-11-01","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/news/index.html","id":"major-1-1-0","dir":"Changelog","previous_headings":"","what":"Major","title":"MagmaClustR 1.1.0","text":"Provide 4 vignettes explaining detail different features MagmaClustR work practical examples. Implement expand_grid_inputs() help create customised n-dimensional input grids evaluate GP. Implement regularize_data() project dataset specific input grid, (possibly control size resulting covariance matrices associated running time). Add internal ‘Reference’ column datasets, provide adequate identifier multidimensional inputs. Implement new version simu_db() generate realistic 2-D datasets.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/news/index.html","id":"minor-1-1-0","dir":"Changelog","previous_headings":"","what":"Minor","title":"MagmaClustR 1.1.0","text":"Round inputs 6 significant digits avoid numerical errors. Generalise creation grid dimension ‘grid_inputs’ specified prediction functions.","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/news/index.html","id":"magmaclustr-101","dir":"Changelog","previous_headings":"","what":"MagmaClustR 1.0.1","title":"MagmaClustR 1.0.1","text":"CRAN release: 2022-08-29","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/news/index.html","id":"major-1-0-1","dir":"Changelog","previous_headings":"","what":"Major","title":"MagmaClustR 1.0.1","text":"Remove package ‘optimr’ dependency switch base ‘optim()’ function Increase convergence tolerance ‘optim()’, slow","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/news/index.html","id":"minor-1-0-1","dir":"Changelog","previous_headings":"","what":"Minor","title":"MagmaClustR 1.0.1","text":"Fix warnings absolute value function Cpp code Remove error message ‘train_magmaclust()’ common_hp_k = FALSE Change default intervals hyper-parameters ‘simu_db()’ Automatically remove rows missing data Change position ‘grid_inputs’ argument prediction functions Remove internal functions index documentation *Fix ‘ID’ hyperposterior() hyperposterior_clust() character","code":""},{"path":"https://arthurleroy.github.io/MagmaClustR/news/index.html","id":"magmaclustr-100","dir":"Changelog","previous_headings":"","what":"MagmaClustR 1.0.0","title":"MagmaClustR 1.0.0","text":"CRAN release: 2022-06-06 Initial release","code":""}]
