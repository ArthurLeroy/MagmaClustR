% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/V-training.R
\name{train_magma_VEM}
\alias{train_magma_VEM}
\title{Training Magma with a Variation of the EM algorithm}
\usage{
train_magma_VEM(
  data,
  nb_cluster = NULL,
  prior_mean_k = NULL,
  ini_hp_k = NULL,
  ini_hp_i = NULL,
  kern_k = "SE",
  kern_i = "SE",
  ini_hp_mixture = NULL,
  common_hp_k = F,
  common_hp_i = F,
  n_iter_max = 25,
  pen_diag = 0.01,
  cv_threshold = 0.001
)
}
\arguments{
\item{data}{A tibble or data frame. Columns required: \code{ID}, \code{Input}
, \code{Output}.
Additional columns for covariates can be specified.
The \code{ID} column contains the unique names/codes used to identify each
individual/task (or batch of data).
The \code{Input} column should define the variable that is used as
reference for the observations (e.g. time for longitudinal data). The
\code{Output} column specifies the observed values (the response
variable). The data frame can also provide as many covariates as desired,
with no constraints on the column names. These covariates are additional
inputs (explanatory variables) of the models that are also observed at each
reference \code{Input}.}

\item{nb_cluster}{The number of clusters wanted.}

\item{prior_mean_k}{prior mean parameter of the K mean GPs (mu_k)}

\item{ini_hp_k}{named vector, tibble or data frame of hyper-parameters
associated with \code{kern_k}, the mean process' kernel. The
columns/elements should be named according to the hyper-parameters
that are used in \code{kern_k}.}

\item{ini_hp_i}{A tibble or data frame of hyper-parameters
associated with \code{kern_i}, the individual processes' kernel.
Required column : \code{ID}. The \code{ID} column contains the unique
names/codes used to identify each individual/task. The other columns
should be named according to the hyper-parameters that are used in
\code{kern_i}.}

\item{kern_k}{A kernel function, associated with the mean GP.
Several popular kernels
(see \href{https://www.cs.toronto.edu/~duvenaud/cookbook/}{The Kernel
Cookbook}) are already implemented and can be selected within the
following list:
\itemize{
\item "SE": (default value) the Squared Exponential Kernel (also called
Radial Basis Function or Gaussian kernel),
\item "LIN": the Linear kernel,
\item "PERIO": the Periodic kernel,
\item "RQ": the Rational Quadratic kernel.
Compound kernels can be created as sums or products of the above kernels.
For combining kernels, simply provide a formula as a character string
where elements are separated by whitespaces (e.g. "SE + PERIO"). As the
elements are treated sequentially from the left to the right, the product
operator '*' shall always be used before the '+' operators (e.g.
'SE * LIN + RQ' is valid whereas 'RQ + SE * LIN' is  not).
}}

\item{kern_i}{A kernel function, associated with the individual GPs. ("SE",
"PERIO" and "RQ" are also available here)}

\item{ini_hp_mixture}{initial values of probabiliy to belong to each cluster for each individuals.}

\item{common_hp_k}{A boolean indicating whether hp are common among mean GPs (for each mu_k).}

\item{common_hp_i}{A boolean indicating whether hp are common among individual GPs (for each y_i).}

\item{n_iter_max}{A number, indicating the maximum number of iterations of
the EM algorithm to proceed while not reaching convergence.}

\item{pen_diag}{A number. A jitter term, added on the diagonal to prevent
numerical issues when inverting nearly singular matrices.}

\item{cv_threshold}{A number, indicating the threshold of the likelihood gain
under which the EM algorithm will stop. The convergence condition is
defined as the difference of likelihoods between two consecutive steps,
divided by the absolute value of the last one
( (LL_n - LL_n-1) / |LL_n| ).}
}
\value{
A list, containing the results of a variation of the EM algorithm used for training
in MagmaClust. The elements of the list are:
\itemize{
\item hp_k: A tibble containing the trained hyper-parameters for the mean
process' kernel.
\item hp_i: A tibble containing all the trained hyper-parameters for the
individual processes' kernels.
\item prop_mixture_k : A tibble containing the hyper-parameters associated with each individual,
indicating in which cluster it belongs.
\item param : A list 3 containing  The mean, the cov and the hp_mixture.
-> mean : A tibble containing the values of hyper-posterior's mean
parameter (\code{Output}) evaluated at each training reference
-> cov : A matrix, covariance parameter of the hyper-posterior
distribution of the mean process.
-> hp_mixture : the probability to belong to a cluster for an individual.
\code{Input}.
\item ini_args: A list containing the initial values for the hyper-prior mean,
the hyper-parameters, and the kernels that have been defined and used
during the learning procedure.
\item Convergence: A logical value indicated whether the EM algorithm converged
or not.
\item Training_time: Total running time of the complete training.
}
}
\description{
The hyper-parameters and the hyper-posterior distribution involved in MagmaClust
can be learned thanks to an EM algorithm implemented in \code{train_magma_VEM}.
By providing a dataset, the model hypotheses (hyper-prior mean parameter and
covariance kernels) and initialisation values for the hyper-parameters, the
function computes maximum likelihood estimates of the HPs as well as the
mean and covariance parameters of the Gaussian hyper-posterior distribution
of the mean process.
}
\examples{
\donttest{
k = seq_len(3)
m_k <- c("K1" = 0, "K2" = 0, "K3" = 0)

db <- simu_db(N = 10, common_input = TRUE)
hp_k <- MagmaClustR:::hp("SE", list_ID = names(m_k))
hp_i <- MagmaClustR:::hp("SE", list_ID = unique(db$ID))
old_hp_mixture = MagmaClustR:::ini_hp_mixture(db = db, k = length(k), nstart = 50)

train_magma_VEM(db, length(k), m_k, hp_k, hp_i,
"SE", "SE", old_hp_mixture, FALSE, FALSE, 25, 0.1, 1e-3)

###############################

db <- simu_db()
train_magma_VEM(db)
}
}
