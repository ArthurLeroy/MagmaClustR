---
title: "Introducing MagmaClustR"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Introducing MagmaClustR}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

<div style="text-align: justify"> 


```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)

```

```{r include = FALSE}
library(MagmaClustR)
options(scipen = 3)
knitr::opts_chunk$set(comment = "#>", collapse = TRUE)
```

## Abstract

The package *MagmaClustR* is based on the algorithms **MAGMA** and **MAGMACLUST**  presented in the paper 'MAGMA: Inference and Prediction with Multi-Task Gaussian Processes' and 'Cluster-Specific Predictions with Multi-Task Gaussian Processes' that you can find respectivly at the addresses : 

* https://arxiv.org/pdf/2007.10731.pdf 

* https://arxiv.org/pdf/2011.07866.pdf 


Thus, the package has two part, the inference and prediction with a multi-task Gaussian process framework and a clustering, and prediction for multiple functional data. 


This vignette will serve to introduce you the main features of MagmaClustR and how to use it. 

## Introduction 

The algorithm **MAGMA** use a common mean function and a specific covariance structure. This common mean is defined as a Gaussian process for which the hyper-posterior distribution is tractable. Therefore an EM algorithm can be derived for simultaneous hyper-parameters optimization and hyper-posterior computation. 

**MAGMACLUST** differs by using more than one common mean processes, and a variational EM algorithm is derived for dealing with the optimization of the hyper-parameters along with the hyper-posteriorsâ€™ estimation of latent variables and processes.
 
Before testing the algorithms you should have your data as a tibble or data frame, with 3 columns required: 'Input', 'Output'. Additional columns for covariates can be specified. The 'Input' column should define the variable that is used as reference for the observations (e.g. time for longitudinal data). The 'Output' column specifies the observed values (the response variable). The data frame can also provide as many covariates as desired, with no constraints on the column names. These covariates are additional inputs (explanatory variables) of the models that are also observed at each reference 'Input'.

## MAGMA

```{r}
db = simu_db()
db
```
We do above a simulation of a database, we get a tibble of 100 lines with 4 columns (ID, Output, Input, Covariate). Then with the function *train_magma* we train our model with the EM algorithm. We can just put the database as below, or changes the others parameters. The parameters by default are in the helper.  

```{r}
train_magma(db)
```

The function return us a list, containing the results of the EM algorithm used for training in Magma. The elements of the list are:

- hp_0: A tibble containing the trained hyper-parameters for the mean process' kernel.

- hp_i: A tibble containing all the trained hyper-parameters for the individual processes' kernels.

- post_mean: A tibble containing the values of hyper-posterior's mean parameter (Output) evaluated at each training reference Input.

- post_cov: A matrix, covariance parameter of the hyper-posterior distribution of the mean process.

- pred_post: A tibble, gathering mean and covariance parameters of the mean process' hyper-posterior distribution under a format that allows direct visualisation as a GP prediction.

- ini_args: A list containing the initial values for the hyper-prior mean, the hyper-parameters, and the kernels that have been defined and used during the learning procedure.

- Converged: A logical value indicated whether the EM algorithm converged or not.

- Training_time: Total running time of the complete training.


## MAGMACLUST


</div>

